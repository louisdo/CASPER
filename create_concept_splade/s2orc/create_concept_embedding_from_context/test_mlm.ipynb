{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "21bcfc65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: [MASK] is the task of identifying and retrieving information that are relevant to an information need\n",
      "identification, retrieval, metadata, verification, sorting, screening, analysis, it, processing, classification, validation, discovery, searching, this, tracking, documentation, evaluation, scanning, reporting, assessment, research, authentication, coordination, search, recognition, mapping, preservation, coding, information, interpretation, investigation, diagnosis, detection, filtering, registration, retention, tracing, accounting, relevance, monitoring, recall, translation, sampling, transparency, forensic, persistence, prevention, framing, interviewing, standardization\n",
      "\n",
      "Input: [MASK] is essential for the future.\n",
      "education, sustainability, cooperation, knowledge, it, this, integrity, conservation, democracy, freedom, stability, happiness, biodiversity, equality, peace, diversity, progress, survival, equity, growth, innovation, development, safety, energy, transparency, care, technology, mobility, health, communication, honesty, prevention, leadership, morality, citizenship, preservation, information, creativity, governance, unity, evolution, religion, planning, simplicity, protection, privacy, justice, spirituality, research, optimism\n",
      "\n",
      "Input: The quick brown fox jumps over the [MASK] dog.\n",
      "shaggy, barking, little, stray, startled, puppy, sleeping, frightened, wild, big, lost, spotted, prairie, brown, lazy, laughing, injured, hound, wounded, pet, tiny, runaway, charging, feral, cute, bunny, small, yellow, hunting, other, running, missing, hot, dog, barked, old, flying, naughty, fleeing, dumb, stuffed, fat, dead, black, giant, young, panting, mad, growling, squirrel\n",
      "\n",
      "Input: In computing, a [MASK] is an organized collection of data or a type of data store\n",
      "database, collection, file, repository, cache, storage, directory, disk, record, heap, list, metadata, container, data, table, cluster, catalog, library, document, warehouse, network, grid, memory, folder, stack, node, compilation, package, query, registry, catalogue, queue, system, resource, store, set, graph, dump, map, format, transaction, reference, partition, server, archive, packet, block, header, hierarchy, register\n",
      "\n",
      "Input: [MASK] are phrases that represent the most relevant information contained in the document\n",
      "these, here, there, below, tags, examples, following, they, italics, citations, links, phrases, sentences, this, parentheses, categories, those, terms, words, some, brackets, pronouns, titles, definitions, names, articles, bold, and, included, references, lists, thus, labels, clauses, meanings, quotes, nouns, symbols, descriptions, highlighted, others, contents, followed, entries, which, exceptions, follows, marks, items, such\n",
      "\n",
      "Input: A [MASK] task requires the detection and classification of semantic relationship mentions within a set of artifacts, typically from text or XML documents\n",
      "semantic, retrieval, mapping, validation, particular, similar, specific, classification, typical, reference, translation, comparison, collaborative, computational, query, cognitive, matching, relational, conceptual, metadata, descriptive, tracking, functional, simple, search, formal, related, database, dictionary, single, citation, structured, learning, generic, communication, verification, specialized, software, modeling, procedural, multimedia, common, research, collaboration, navigation, persistence, visual, description, forensic, statistical\n",
      "\n",
      "Input: [MASK] comprise two or more homopolymer subunits linked by covalent bonds\n",
      "they, molecules, proteins, these, ions, complexes, electrons, atoms, polymers, clusters, bonds, substrates, rings, antibodies, membranes, can, bacteria, both, chromosomes, particles, nuclei, enzymes, salts, residues, fragments, domains, compounds, chains, viruses, products, genes, components, cells, metals, pairs, groups, may, those, colonies, elements, rods, species, acids, loops, antibiotics, interactions, matrices, strands, structures, frames\n",
      "\n",
      "Input: A [MASK] occurs when a baby is born before 37 weeks of pregnancy\n",
      "pregnancy, maternity, ##carriage, childbirth, baby, divorce, crisis, birth, delay, abortion, rape, deficiency, fever, newborn, death, miracle, conception, defect, pregnant, premature, seizure, reversal, shock, vacancy, dowry, shortage, womb, bore, delivery, syndrome, milestone, clutch, contraction, child, panic, blackout, spike, fracture, hiatus, rash, disaster, mortality, termination, mother, reverse, kidnapping, separation, failure, diagnosis, loss\n",
      "\n",
      "Input: Supplementing remote sensing of Ice: Deep Learning-Based [MASK] System for Automatic Detection and Localization of Sea-ice Formations From Close-Range Optical Images. This paper presents a three-stage approach for the automated analysis of close-range optical images containing ice objects. The proposed system is based on an ensemble of deep learning models and conditional random field postprocessing. The following surface ice formations were considered: Icebergs, Deformed ice, Level ice, Broken ice, Ice floes, Floebergs, Floebits, Pancake ice, and Brash ice. Additionally, five non-surface ice categories were considered: Sky, Open water, Shore, Underwater ice, and Melt ponds. To find input parameters for the approach, the performance of 12 different neural network architectures was explored and evaluated using a 5-fold cross-validation scheme. The best performance was achieved using an ensemble of models having pyramid pooling layers (PSPNet, PSPDenseNet, DeepLabV3+, and UPerNet) and convolutional conditional random field postprocessing with a mean intersection over union score of 0.799, and this outperformed the best single-model approach. The results of this study show that when per-class performance was considered, the Sky was the easiest class to predict, followed by Deformed ice and Open water. Melt pond was the most challenging class to predict. Furthermore, we have extensively explored the strengths and weaknesses of our approach and, in the process, discovered the types of scenes that pose a more significant challenge to the underlying neural networks. When coupled with optical sensors and AIS, the proposed approach can serve as a supplementary source of large-scale ‘ground truth’ data for validation of satellite-based sea-ice products. We have provided an implementation of the approach at https://github.com/panchinabil/sea_ice_segmentation .\n",
      "validation, prediction, verification, evaluation, scoring, analysis, assessment, test, testing, statistical, classification, modeling, grading, simulation, experimental, estimation, sampling, measurement, inference, detection, monitoring, retrieval, regression, comparison, feedback, rating, training, performance, numerical, calculation, selection, elimination, diagnostic, observation, checking, model, modelling, composite, screening, matching, forecast, reinforcement, data, optimization, inspection, correlation, reconstruction, labeling, score, confirmation\n",
      "\n",
      "Input: The best performing models also connect the encoder and decoder through an [MASK]. We propose a new simple network architecture, the Transformer, based solely on attention mechanisms, dispensing with recurrence and convolutions entirely. Experiments on two machine translation tasks show these models to be superior in quality while being more parallelizable and requiring significantly less time to train. Our model achieves 28.4 BLEU on the WMT 2014 English-to-German translation task, improving over the existing best results, including ensembles by over 2 BLEU. On the WMT 2014 English-to-French translation task, our model establishes a new single-model state-of-the-art BLEU score of 41.8 after training for 3.5 days on eight GPUs, a small fraction of the training costs of the best models from the literature. We show that the Transformer generalizes well to other tasks by applying it successfully to English constituency parsing both with large and limited training data.\n",
      "algorithm, amplifier, interaction, interpreter, ensemble, interface, analogy, experiment, array, alphabet, integration, assembly, instruction, input, acronym, implementation, operator, engine, abstraction, argument, api, analysis, overlap, approximation, inversion, assumption, output, apparatus, encoding, intermediate, illusion, instrument, agent, equation, assignment, optimization, interchange, event, interval, environment, accelerator, image, application, explanation, animation, error, improvement, exchange, actor, integral\n",
      "\n",
      "Input: [MASK] have emerged as a powerful new family of deep generative models with record-breaking performance in many applications, including image synthesis, video generation, and molecule design\n",
      "they, these, algorithms, models, applications, tools, others, simulations, ideas, prototypes, technologies, examples, techniques, cds, solutions, innovations, synthesizers, insights, robots, clusters, systems, both, dynamics, designs, products, patents, graphics, hybrids, networks, methods, derivatives, devices, projects, implementations, libraries, we, extensions, variants, polymers, modules, crystals, developers, designers, such, researchers, computers, theories, chips, cores, many\n",
      "\n",
      "Input: Real world [MASK] (BCI): Cross-Domain Learning and Practical Applications\n",
      "/, +, _, or, &, =, -, versus, :, @, vs, and, ., by, to, –, !, for, ,, ?, ^, |, n, on, #, \\, with, …, ##2, via, —, *, using, e, →, (, in, x, means, {, through, into, plus, against, ##1, ;, net, without, %, of\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch, os\n",
    "from transformers import AutoModelForMaskedLM, AutoTokenizer, TrainingArguments\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\"\n",
    "\n",
    "# Paths to checkpoint files\n",
    "checkpoint_dir = \"model_gitig_\"\n",
    "\n",
    "# Load the tokenizer and model\n",
    "model = AutoModelForMaskedLM.from_pretrained(checkpoint_dir)\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint_dir)\n",
    "\n",
    "vocab = tokenizer.vocab\n",
    "reverse_voc = {v:k for k,v in vocab.items()}\n",
    "\n",
    "# Define test sentences with [MASK] token\n",
    "test_sentences = [\n",
    "    \"[MASK] is the task of identifying and retrieving information that are relevant to an information need\",\n",
    "    \"[MASK] is essential for the future.\",\n",
    "    \"The quick brown fox jumps over the [MASK] dog.\",\n",
    "    \"In computing, a [MASK] is an organized collection of data or a type of data store\",\n",
    "    \"[MASK] are phrases that represent the most relevant information contained in the document\",\n",
    "    \"A [MASK] task requires the detection and classification of semantic relationship mentions within a set of artifacts, typically from text or XML documents\",\n",
    "    \"[MASK] comprise two or more homopolymer subunits linked by covalent bonds\",\n",
    "    \"A [MASK] occurs when a baby is born before 37 weeks of pregnancy\",\n",
    "    \"\"\"Supplementing remote sensing of Ice: Deep Learning-Based [MASK] System for Automatic Detection and Localization of Sea-ice Formations From Close-Range Optical Images. This paper presents a three-stage approach for the automated analysis of close-range optical images containing ice objects. The proposed system is based on an ensemble of deep learning models and conditional random field postprocessing. The following surface ice formations were considered: Icebergs, Deformed ice, Level ice, Broken ice, Ice floes, Floebergs, Floebits, Pancake ice, and Brash ice. Additionally, five non-surface ice categories were considered: Sky, Open water, Shore, Underwater ice, and Melt ponds. To find input parameters for the approach, the performance of 12 different neural network architectures was explored and evaluated using a 5-fold cross-validation scheme. The best performance was achieved using an ensemble of models having pyramid pooling layers (PSPNet, PSPDenseNet, DeepLabV3+, and UPerNet) and convolutional conditional random field postprocessing with a mean intersection over union score of 0.799, and this outperformed the best single-model approach. The results of this study show that when per-class performance was considered, the Sky was the easiest class to predict, followed by Deformed ice and Open water. Melt pond was the most challenging class to predict. Furthermore, we have extensively explored the strengths and weaknesses of our approach and, in the process, discovered the types of scenes that pose a more significant challenge to the underlying neural networks. When coupled with optical sensors and AIS, the proposed approach can serve as a supplementary source of large-scale ‘ground truth’ data for validation of satellite-based sea-ice products. We have provided an implementation of the approach at https://github.com/panchinabil/sea_ice_segmentation .\"\"\",\n",
    "    \"\"\"The best performing models also connect the encoder and decoder through an [MASK]. We propose a new simple network architecture, the Transformer, based solely on attention mechanisms, dispensing with recurrence and convolutions entirely. Experiments on two machine translation tasks show these models to be superior in quality while being more parallelizable and requiring significantly less time to train. Our model achieves 28.4 BLEU on the WMT 2014 English-to-German translation task, improving over the existing best results, including ensembles by over 2 BLEU. On the WMT 2014 English-to-French translation task, our model establishes a new single-model state-of-the-art BLEU score of 41.8 after training for 3.5 days on eight GPUs, a small fraction of the training costs of the best models from the literature. We show that the Transformer generalizes well to other tasks by applying it successfully to English constituency parsing both with large and limited training data.\"\"\",\n",
    "    \"\"\"[MASK] have emerged as a powerful new family of deep generative models with record-breaking performance in many applications, including image synthesis, video generation, and molecule design\"\"\",\n",
    "    \"\"\"Real world [MASK] (BCI): Cross-Domain Learning and Practical Applications\"\"\"\n",
    "]\n",
    "\n",
    "# Perform predictions\n",
    "model.eval()\n",
    "for sentence in test_sentences:\n",
    "    inputs = tokenizer(sentence, return_tensors=\"pt\")\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.logits\n",
    "\n",
    "    # Get top predictions for masked token\n",
    "    masked_index = (inputs[\"input_ids\"] == tokenizer.mask_token_id).nonzero(as_tuple=True)[1]\n",
    "    # print(logits)\n",
    "    predictions = logits[0, masked_index].topk(50)\n",
    "\n",
    "    print(f\"Input: {sentence}\")\n",
    "    for idx, score in zip(predictions.indices.tolist(), predictions.values.tolist()):\n",
    "        predicted_token = [reverse_voc[item] for item in idx]\n",
    "        print(\", \".join(predicted_token))\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "59db5be7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(37.1301)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.max(logits[...,30522:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "63aeaeab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(21.4729)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.max(logits[...,:30522])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8f7e264a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DistilBertForMaskedLM(\n",
       "  (activation): GELUActivation()\n",
       "  (distilbert): DistilBertModel(\n",
       "    (embeddings): Embeddings(\n",
       "      (word_embeddings): Embedding(41657, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (transformer): Transformer(\n",
       "      (layer): ModuleList(\n",
       "        (0-5): 6 x TransformerBlock(\n",
       "          (attention): DistilBertSdpaAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (vocab_transform): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (vocab_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "  (vocab_projector): Linear(in_features=768, out_features=41657, bias=True)\n",
       "  (mlm_loss_fct): CrossEntropyLoss()\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "591d92d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0166, -0.0666, -0.0163,  ..., -0.0200, -0.0514, -0.0264],\n",
       "        [-0.0132, -0.0673, -0.0161,  ..., -0.0227, -0.0554, -0.0260],\n",
       "        [-0.0176, -0.0709, -0.0144,  ..., -0.0246, -0.0596, -0.0232],\n",
       "        ...,\n",
       "        [ 0.0267, -0.0407,  0.2724,  ...,  0.0286,  0.0342,  0.1492],\n",
       "        [ 0.0524,  0.2483,  0.1334,  ..., -0.2215, -0.0739,  0.0652],\n",
       "        [ 0.2415,  0.1530,  0.3405,  ..., -0.1294, -0.1256,  0.0224]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.distilbert.embeddings.word_embeddings.weight.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "64df5796",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0166, -0.0666, -0.0163,  ..., -0.0200, -0.0514, -0.0264],\n",
       "        [-0.0132, -0.0673, -0.0161,  ..., -0.0227, -0.0554, -0.0260],\n",
       "        [-0.0176, -0.0709, -0.0144,  ..., -0.0246, -0.0596, -0.0232],\n",
       "        ...,\n",
       "        [ 0.0267, -0.0407,  0.2724,  ...,  0.0286,  0.0342,  0.1492],\n",
       "        [ 0.0524,  0.2483,  0.1334,  ..., -0.2215, -0.0739,  0.0652],\n",
       "        [ 0.2415,  0.1530,  0.3405,  ..., -0.1294, -0.1256,  0.0224]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.vocab_projector.weight.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "470fadb8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
