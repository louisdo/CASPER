{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "expired-priority",
   "metadata": {},
   "source": [
    "# CASPER Quick test run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "tight-milton",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, os, string\n",
    "from transformers import AutoModelForMaskedLM, AutoTokenizer\n",
    "from splade.models.transformer_rep import PhraseSpladev3 as CASPER\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8bbbeba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "mighty-invention",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the dir for trained weights\n",
    "model_type_or_dir = \"lamdo/casper\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "centered-watershed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "59419"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loading model and tokenizer\n",
    "\n",
    "model = CASPER(model_type_or_dir, agg=\"max\", original_bert_vocab_size=30522)\n",
    "# model = Splade(model_type_or_dir, agg = \"max\")\n",
    "model.eval()\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_type_or_dir)\n",
    "reverse_voc = {v: k for k, v in tokenizer.vocab.items()}\n",
    "\n",
    "len(reverse_voc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "forward-movement",
   "metadata": {},
   "outputs": [],
   "source": [
    "# doc = \"\"\"ColBERTv2: Effective and Efficient Retrieval via Lightweight Late Interaction. Neural information retrieval (IR) has greatly advanced search and other knowledge-intensive language tasks. While many neural IR methods encode queries and documents into single-vector representations, late interaction models produce multi-vector representations at the granularity of each token and decompose relevance modeling into scalable token-level computations. This decomposition has been shown to make late interaction more effective, but it inflates the space footprint of these models by an order of magnitude. In this work, we introduce ColBERTv2, a retriever that couples an aggressive residual compression mechanism with a denoised supervision strategy to simultaneously improve the quality and space footprint of late interaction. We evaluate ColBERTv2 across a wide range of benchmarks, establishing state-of-the-art quality within and outside the training domain while reducing the space footprint of late interaction models by 6--10×.\"\"\"\n",
    "\n",
    "# doc = \"\"\"Supplementing Remote Sensing of Ice: Deep Learning-Based Image Segmentation System for Automatic Detection and Localization of Sea-ice Formations From Close-Range Optical Images. This paper presents a three-stage approach for the automated analysis of close-range optical images containing ice objects. The proposed system is based on an ensemble of deep learning models and conditional random field postprocessing. The following surface ice formations were considered: Icebergs, Deformed ice, Level ice, Broken ice, Ice floes, Floebergs, Floebits, Pancake ice, and Brash ice. Additionally, five non-surface ice categories were considered: Sky, Open water, Shore, Underwater ice, and Melt ponds. To find input parameters for the approach, the performance of 12 different neural network architectures was explored and evaluated using a 5-fold cross-validation scheme. The best performance was achieved using an ensemble of models having pyramid pooling layers (PSPNet, PSPDenseNet, DeepLabV3+, and UPerNet) and convolutional conditional random field postprocessing with a mean intersection over union score of 0.799, and this outperformed the best single-model approach. The results of this study show that when per-class performance was considered, the Sky was the easiest class to predict, followed by Deformed ice and Open water. Melt pond was the most challenging class to predict. Furthermore, we have extensively explored the strengths and weaknesses of our approach and, in the process, discovered the types of scenes that pose a more significant challenge to the underlying neural networks. When coupled with optical sensors and AIS, the proposed approach can serve as a supplementary source of large-scale ‘ground truth’ data for validation of satellite-based sea-ice products. We have provided an implementation of the approach at https://github.com/panchinabil/sea_ice_segmentation .\"\"\"\n",
    "\n",
    "doc = \"deep transfer learning in neural networks\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c66d32d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([59419])\n",
      "number of actual dimensions:  181\n",
      "deep transfer learning in neural networks\n",
      "('deep learning', 2.26)\n",
      "('deep', 1.43)\n",
      "('knowledge transfer', 1.36)\n",
      "('transfer learning', 1.25)\n",
      "('soap', 1.24)\n",
      "('neural network', 1.15)\n",
      "('learning algorithm', 1.09)\n",
      "('ann', 1.05)\n",
      "('training', 1.03)\n",
      "('casper', 1.02)\n",
      "('neural networks', 1.02)\n",
      "('learning', 0.93)\n",
      "('embedding', 0.9)\n",
      "('in', 0.89)\n",
      "('language', 0.86)\n",
      "('e-learning', 0.83)\n",
      "('network', 0.81)\n",
      "('image', 0.8)\n",
      "('transfer', 0.78)\n",
      "('knowledge management', 0.78)\n",
      "('depth', 0.77)\n",
      "('knowledge sharing', 0.75)\n",
      "('magic', 0.74)\n",
      "('brain', 0.72)\n",
      "('spillover', 0.72)\n",
      "('the', 0.7)\n",
      "('.', 0.69)\n",
      "('language learning', 0.69)\n",
      "('machine translation', 0.67)\n",
      "('mapping', 0.63)\n",
      "('specialisation', 0.59)\n",
      "(',', 0.57)\n",
      "('neurons', 0.57)\n",
      "('reinforcement learning', 0.56)\n",
      "('domain adaptation', 0.55)\n",
      "('back propagation', 0.55)\n",
      "('deeper', 0.52)\n",
      "('people', 0.52)\n",
      "('km', 0.51)\n",
      "('fox', 0.5)\n",
      "('cascades', 0.49)\n",
      "('semi-supervised learning', 0.48)\n",
      "('cross', 0.48)\n",
      "('habituation', 0.47)\n",
      "('foster', 0.46)\n",
      "('mentorship', 0.46)\n",
      "('motor', 0.45)\n",
      "('new models', 0.43)\n",
      "('motor learning', 0.43)\n",
      "('cloud', 0.42)\n",
      "('transformation process', 0.42)\n",
      "('knowledge innovation', 0.42)\n",
      "('emotions', 0.41)\n",
      "('artificial intelligence', 0.41)\n",
      "('tacit knowledge', 0.41)\n",
      "('generalization', 0.41)\n",
      "('injections', 0.39)\n",
      "('company', 0.39)\n",
      "('training method', 0.39)\n",
      "('mechanical activation', 0.38)\n",
      "('synergy', 0.38)\n",
      "('collaboration', 0.36)\n",
      "('transformation', 0.36)\n",
      "('artificial neural networks', 0.35)\n",
      "('word', 0.34)\n",
      "('fusion', 0.34)\n",
      "('memory', 0.33)\n",
      "('artificial neural network', 0.33)\n",
      "('discrimination learning', 0.33)\n",
      "('prediction', 0.33)\n",
      "('ai', 0.32)\n",
      "('lever', 0.32)\n",
      "('embeddings', 0.32)\n",
      "('sift', 0.31)\n",
      "('chip', 0.31)\n",
      "('synapse', 0.3)\n",
      "('convolution', 0.3)\n",
      "('glide', 0.3)\n",
      "('new insights', 0.29)\n",
      "('bn', 0.29)\n",
      "('algorithm', 0.29)\n",
      "('mt', 0.28)\n",
      "('english', 0.28)\n",
      "('classification', 0.27)\n",
      "('training model', 0.27)\n",
      "('object manipulation', 0.25)\n",
      "('mutual information', 0.25)\n",
      "('mappings', 0.25)\n",
      "('translation', 0.25)\n",
      "('twinning', 0.25)\n",
      "('multilayer', 0.24)\n",
      "('scrapie', 0.24)\n",
      "('dependencies', 0.24)\n",
      "('injection', 0.24)\n",
      "('huang', 0.24)\n",
      "('multilingualism', 0.23)\n",
      "('gene transfer', 0.23)\n",
      "('teacher development', 0.23)\n",
      "('diffusion', 0.23)\n",
      "('collaborative learning', 0.23)\n",
      "('later', 0.23)\n",
      "('machine learning', 0.22)\n",
      "('cooperation', 0.22)\n",
      "('moss', 0.22)\n",
      "('acquisition', 0.21)\n",
      "('education', 0.2)\n",
      "('human capital', 0.2)\n",
      "('automatic extraction', 0.2)\n",
      "('p300', 0.2)\n",
      "('tunnel', 0.2)\n",
      "('haptic feedback', 0.2)\n",
      "('mapping method', 0.19)\n",
      "('layer', 0.18)\n",
      "('prune', 0.18)\n",
      "('perceptual learning', 0.17)\n",
      "('price', 0.17)\n",
      "('knowledge', 0.17)\n",
      "('knowledge acquisition', 0.16)\n",
      "('new research', 0.16)\n",
      "('networks', 0.15)\n",
      "('cultural', 0.15)\n",
      "('normal', 0.14)\n",
      "('biofeedback', 0.14)\n",
      "('ax', 0.13)\n",
      "('central', 0.13)\n",
      "('expert knowledge', 0.13)\n",
      "('hidden', 0.13)\n",
      "('silk', 0.12)\n",
      "('wireless networks', 0.12)\n",
      "('fmri', 0.11)\n",
      "('transfer process', 0.11)\n",
      "('cross-linking', 0.11)\n",
      "('learned', 0.11)\n",
      "('semantic similarity', 0.11)\n",
      "('model', 0.11)\n",
      "('hybridization', 0.11)\n",
      "('data', 0.1)\n",
      "('regularization', 0.1)\n",
      "('discovery', 0.1)\n",
      "('lab', 0.1)\n",
      "('absorptive capacity', 0.1)\n",
      "('logic', 0.09)\n",
      "('feedback information', 0.09)\n",
      "('cells', 0.09)\n",
      "('adaptivity', 0.08)\n",
      "('capsaicin', 0.08)\n",
      "('ki', 0.08)\n",
      "('negative transfer', 0.08)\n",
      "('remote control', 0.08)\n",
      "('cultural adaptation', 0.08)\n",
      "('localization', 0.07)\n",
      "('sci', 0.07)\n",
      "('online', 0.06)\n",
      "('central nervous system', 0.06)\n",
      "('augmentation', 0.06)\n",
      "('penetration depth', 0.06)\n",
      "('histamine release', 0.06)\n",
      "('model transformation', 0.05)\n",
      "('learns', 0.05)\n",
      "('leverage', 0.05)\n",
      "('new knowledge', 0.04)\n",
      "('functional connectivity', 0.04)\n",
      "('strain relaxation', 0.04)\n",
      "('ge', 0.04)\n",
      "('kit', 0.04)\n",
      "('directly', 0.04)\n",
      "('family', 0.03)\n",
      "('school', 0.03)\n",
      "('integration', 0.03)\n",
      "('recurrent neural networks', 0.03)\n",
      "('process', 0.02)\n",
      "('independent innovation', 0.02)\n",
      "('collaborative approach', 0.01)\n",
      "('transduction', 0.01)\n",
      "('collaborative work', 0.01)\n",
      "('entanglement', 0.01)\n",
      "('and', 0.01)\n",
      "('foreign language learning', 0.0)\n",
      "('power system', 0.0)\n",
      "('transferability', 0.0)\n",
      "('gradient', 0.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lamdo/splade/splade/models/transformer_rep.py:566: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast() if self.fp16 else NullContextManager():\n",
      "/home/lamdo/splade/splade/models/transformer_rep.py:32: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast() if self.fp16 else NullContextManager():\n"
     ]
    }
   ],
   "source": [
    "# # now compute the document representation\n",
    "# for punc in string.punctuation:\n",
    "#     doc = doc.replace(punc, \" \")\n",
    "    \n",
    "doc_tokens = tokenizer(doc, max_length = 256, return_tensors=\"pt\")\n",
    "with torch.no_grad():\n",
    "    doc_rep = model(d_kwargs=doc_tokens)[\"d_rep\"].squeeze()  # (sparse) doc rep in voc space, shape (30522,)\n",
    "    # print(torch.sum(doc_rep))\n",
    "    # doc_rep = encode_custom_mask_punc(doc_tokens, model).squeeze()\n",
    "print(doc_rep.shape)\n",
    "# get the number of non-zero dimensions in the rep:\n",
    "col = torch.nonzero(doc_rep).squeeze().cpu().tolist()\n",
    "print(\"number of actual dimensions: \", len(col))\n",
    "\n",
    "# now let's inspect the bow representation:\n",
    "weights = doc_rep[col].cpu().tolist()\n",
    "d = {k: v for k, v in zip(col, weights)} #if k >= model.original_bert_vocab_size}\n",
    "sorted_d = {k: v for k, v in sorted(d.items(), key=lambda item: item[1], reverse=True)}\n",
    "bow_rep = []\n",
    "\n",
    "print(doc)\n",
    "for k, v in sorted_d.items():\n",
    "    print((reverse_voc[k], round(v, 2)))\n",
    "    bow_rep.append((reverse_voc[k], round(v, 2)))\n",
    "# print(\"SPLADE BOW rep:\\n\", bow_rep)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
