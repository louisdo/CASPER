{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "308157it [00:00, 448725.71it/s]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from tqdm import tqdm\n",
    "with open(\"/scratch/lamdo/s2orc/processed/citation_contexts_triplets/triplets_intermediate_cs.tsv\") as f:\n",
    "    intermediate = []\n",
    "    for line in tqdm(f):\n",
    "        splitted_line = line.strip().split(\"\\t\")\n",
    "        intermediate.append(splitted_line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['In local studies, the use of vector data types is easier .',\n",
       "  '4541949',\n",
       "  '125325689'],\n",
       " ['All arrays were + using the NumPy package .', '16907816', '4541949'],\n",
       " ['Recall is the fraction of the total amount of relevant instances that were actually retrieved .',\n",
       "  '14081058',\n",
       "  '125325689'],\n",
       " ['PCA analysis of replicates from sample A and B The relationships among spectra can be visualized by an unsupervised pattern recognition algorithm PCA .',\n",
       "  '25253360',\n",
       "  '17900407'],\n",
       " ['Phylogenetic and mutational analysis The full length genomes were annotated using VIGOR software available at VIPR server (https://www.viprbrc.org/brc/vigorAnnotator.s pg?method¼ShowCleanInputPage&amp;decorator¼toga) .',\n",
       "  '9194300',\n",
       "  '18902297'],\n",
       " ['NTN Use Cases Non-terrestrial systems have been proposed to enable several applications, including weather forecasting, video surveillance, TV broadcast, remote sensing, and navigation, for several years.On the other hand, recent technological advances in the aerial/space sector have enabled the implementation of more sophisticated use cases, such as distributed computing and content broadcasting, service boosting for users in congested areas, eMBB in underserved areas, and multi-connectivity for service continuity via cellular networks .',\n",
       "  '235829846',\n",
       "  '226486759'],\n",
       " ['Non-terrestrial technology has long been thought to support operations such as home delivery, weather forecasting, video surveillance, television transmission, remote sensing, and navigation.To enable more advanced use cases, such as Communication Resilience and Service Continuity, Global Satellite Overlay, Ubiquitous Internet of Things (IoT) Broadcasting, Advanced Backhauling, and Energy-Efficient Hybrid Multiplay, the recent technological advancements in the aerial/space industry have however made it possible for integration between terrestrial and non-terrestrial technologies.The few enabling technologies to support NTN in 6G for architecture, spectrum, antenna, and higher layers advancements, respectively, include gallium nitride (GaN), cognitive spectrum, multi-beam structures, and TCP spoofing and multiplexing .',\n",
       "  '220055483',\n",
       "  '220259280'],\n",
       " ['Data collection A case study investigates a contemporary phenomenon in depth and within its real-world context, focusing on answering how and why questions .',\n",
       "  '964694',\n",
       "  '7635031'],\n",
       " ['Secondly, from the early 2010s, questions related to the underlying causes of barriers, their short-and long-term consequences, and internal dynamics have been raised, but they remain unanswered .',\n",
       "  '7635031',\n",
       "  '964694'],\n",
       " ['Distribution test based methods have proven to be computationally efficient in SISO systems , - .',\n",
       "  '29473817',\n",
       "  '201069399'],\n",
       " ['Kanterakis and Su tried to reduce the computational complexity of the likelihood based classifier by modifying the likelihood function .',\n",
       "  '9204371',\n",
       "  '3501374'],\n",
       " ['A combination of moment features and likelihood maximization has been experimented for a balance between classification accuracy and computational complexity in .',\n",
       "  '13706276',\n",
       "  '29473817'],\n",
       " ['Dulek proposed a likelihood based method in combination with an online channel estimator .',\n",
       "  '11640841',\n",
       "  '2405012'],\n",
       " ['In , the authors tried to predict volume using Partial Least Squares (PLS) and Support Vector Regression (SVR).',\n",
       "  '89615068',\n",
       "  '52874011'],\n",
       " ['One example is , where the authors predicted future options prices using conventional pricing techniques combined with two learning models: Neural Networks and Support Vector Regression.',\n",
       "  '32320813',\n",
       "  '206457500'],\n",
       " [\"), Lipinski's Rule violations (Lipinski..violations), Ghose Filter violations (Ghose..violations), Veber Rule violations (Veber.violations),Egan Rule violations (Egan..violations), Muegge's Rule violations (Muegge..violations), bioavailability score (bioavailability.score),molecular weight (molweight), P: conc (octanol)/conc (water) (cLogP), S: water solubility in mol/L (cLogS), hydrogen acceptor (H.acceptors), hydrogen donors (H.donors), total surface area (total.surface.area),polar surface area (polar.surface.area),drug likeness (drug likeness), shape index (shape.index),molecular flexibility (molecular.flexibility),electronegative atoms (electronegative.atoms),rotatable bonds (rotatable.bonds),aromatic rings (aromatic.rings),aromatic atoms (aromatic.atoms),sp3 atoms (sp3 atoms), and symmetric atoms (symmetric.atoms)already reported .\",\n",
       "  '30840645',\n",
       "  '7719725'],\n",
       " ['Once a particle was detected, a discriminative correlation filter with channel and spatial reliability (CSR-DCF) was used to track particles between frames .',\n",
       "  '59222267',\n",
       "  '52197168'],\n",
       " ['Custom-fabricated imagers with nanostructures/microstructures designs have been investigated to improve the resolution of fluorescence lensless imaging .',\n",
       "  '52197168',\n",
       "  '59222267'],\n",
       " ['To test and evaluate our approach, we focus on the subpart of KB BIO 101 isolated for the KBGEN surface realisation shared task by .',\n",
       "  '5617711',\n",
       "  '16640049'],\n",
       " ['While offering more flexibility and expressiveness, these systems are difficult to adapt by non-NLG experts because they require the user to understand the architecture of the NLG systems .',\n",
       "  '5475067',\n",
       "  '9500998'],\n",
       " ['Another trend of work relevant to this paper is generation from databases using parallel corpora of data and text.',\n",
       "  '13402912',\n",
       "  '15118849'],\n",
       " ['Finally, recent work by the SWAT project 1 has focused on pro-ducing descriptions of ontologies that are both coherent and efficient .',\n",
       "  '9613237',\n",
       "  '504909'],\n",
       " ['Statistics for our dataset is presented in Table 1.Each abstract was annotated by two annotators.The task was to classify the relations between each possible pair of terms in each sentence in the abstract.The terms in the texts were already extracted.During the annotation, we followed the instructions proposed in .',\n",
       "  '227053552',\n",
       "  '190000105'],\n",
       " ['proposed to create a template for each relation type and then compute increased log probability of the sentences from these templates with the use of BERT as in .For example, a template for the relation \"LOCATED-IN\" might look like this -\"the <e1> is in the <e2>\".So if the first entity is \"toothbrush\" and the second is \"bathroom\", the sentence from the template will be \"the toothbrush is in the bathroom\".With the selected threshold of probability, it will be possible to separate the presence or absence of relation between two entities and also its type.',\n",
       "  '190000105',\n",
       "  '52118895'],\n",
       " ['With the introduction of large language models their use became one of the main methods of solving this problem.However, such methods require a lot of well-annotated data for training.Currently there are no datasets available for this task in a scientific field in Russian, and manual annotation takes a long time and requires the efforts of more than one person to objectively label the relations.Therefore, in this paper we decided to pay our special attention to zero-shot and few-shot approaches that do not require a lot of annotated data.There are some examples of them.',\n",
       "  '52967399',\n",
       "  '160025533'],\n",
       " ['Then we got an estimate of the probability of each sentence using the model GPT2 .After choosing the most probable pattern for each relation, we again compared the probability of sentences from these best templates.The most likely sentence would reflect the true relation between the terms.The schematic work of the method is presented in the Figure 1.To measure the probability we used the perplexity score.In general, this value can be described as the model uncertainty measure when predicting each of the next token, hence the lower the perplexity, the more certain the model in predicting this sequence.',\n",
       "  '160025533',\n",
       "  '160009395'],\n",
       " ['Using prototype vectors of relations The second approach for relation identification that we tried is based on the usage of the prototype vectors of relations.It can be attributed to few-shot approaches.First of all, we manually chose 138 best examples from the train part of the dataset to create a prototype vectors for each type of relations.In selecting the best examples we were guided by the following criterion: the example shows only one type of relations and has short context which includes only two terms of interest.Then we got the vectors of these of sentences.Vectors of sentences are the embeddings of CLS token from BERT .Each prototype vector is an average of the vectors of sentences reflecting each relation.Once these prototype vectors are obtained, they can be used to classify test examples.By computing the value of the cosine similarity of the example and the prototypes, we can determine which relation is most similar to this example.Schematic graphics that reflect the work of this method can be seen in Figure 2.',\n",
       "  '52967399',\n",
       "  '227053552'],\n",
       " ['* files released with previous versions of SCOP and SCOPe .',\n",
       "  '6829315',\n",
       "  '54466991'],\n",
       " ['Hundreds of additional entries are added to SCOPe each month, because after at least one structure from a SCOPe family has been classified by a human curator, most other structures from that family may be added automatically by our rigorously validated software pipeline .',\n",
       "  '14864309',\n",
       "  '16369816'],\n",
       " ['Tags were identified using PDB metadata (SE-QADV records) referring to cloning, expression, or purification tags at the N-or C-terminal of each chain, as described in more detail elsewhere .',\n",
       "  '12866879',\n",
       "  '226207258'],\n",
       " ['To facilitate automated algorithms developed or trained on the SCOPe database, we provide machineparseable annotations of the extent of a single repeat unit for all families of repeats in classes a to g. Tandem repeats are often also annotated in other databases, such as Pfam .',\n",
       "  '226207258',\n",
       "  '11078775'],\n",
       " ['Behavioural intention 3 The intention to use BOPIS continuously .',\n",
       "  '13954684',\n",
       "  '4080949'],\n",
       " ['To create this model, Venkatesh et al reviewed and synthesised aspects of the following models: the theory of reasoned action (TRA), the technology acceptance model (TAM), the motivational model, the theory of planned behaviour (TPB), the decomposed theory of planned behaviour, the combined TAM-TBP model (OTAM-CBT), the model of personal computer utilisation (MPCU), the innovation diffusion theory (IDT), and the social cognitive theory (SCT).',\n",
       "  '13954684',\n",
       "  '6928807'],\n",
       " ['Apart from these constructs, previous studies also found that innovativeness and trust have an effect .',\n",
       "  '12476939',\n",
       "  '18173161'],\n",
       " ['AXIN2 itself is a major target gene of WNT signalling.It acts in a negative feedback loop to limit and finetune the canonical WNT-signaling .The human AXIN2 gene is located on chromosome 17q24.1 and encompasses 10 coding exons that generate a protein of 843 amino acids (Fig.',\n",
       "  '16190212',\n",
       "  '6908182'],\n",
       " ['The implementation of Naïve Bayes in WEKA is based on the work of .',\n",
       "  '667586',\n",
       "  '17438917'],\n",
       " ['The set of people detected in the scene is then tracked over the space and time by the algorithm of .',\n",
       "  '16028462',\n",
       "  '2674272'],\n",
       " ['This conclusion is in agreement with recent intracranial EEG results showing similar object selective (including word selective) response dynamics in the human occipito-temporal cortex during a free viewing visual search task and static visual stimulation.',\n",
       "  '9607522',\n",
       "  '1225535'],\n",
       " ['The authors suggest that there are many areas where we are unlikely to find fundamental principles and that we should consider phenomenological, data-driven models that have practical value to be genuine intellectual accomplishments worthy of our satisfaction.',\n",
       "  '14300215',\n",
       "  '8179293'],\n",
       " ['Depth cameras have become an invaluable source of such reconstructions, and while the raw data from a RGB-D camera is typically a point cloud, voxels are used as intermediate representations in systems such as KinectFusion .',\n",
       "  '11830123',\n",
       "  '42427078'],\n",
       " ['Co-presence was measured by choosing the three co-presence items of BAIL , and we added two items asking about the believability of objects and characters in the voxel-based MR system (BoOC).',\n",
       "  '7367266',\n",
       "  '205045003'],\n",
       " ['The first eight items were chosen from the igroup presence questionnaire IPQ .',\n",
       "  '7480416',\n",
       "  '207424665'],\n",
       " ['Capture An earlier version of the system only supported co-located (not networked) users and used only one Kinect camera ; here the real environment is captured with three Kinect cameras (Figure 5).',\n",
       "  '4704820',\n",
       "  '18030939'],\n",
       " ['Interactive labeling is also supported via voxels, as in Semantic Paint where users can provide labels through gestures and voice.',\n",
       "  '9568132',\n",
       "  '37768224'],\n",
       " ['3.17 ED @ λ = 390nm 3 (Al) 1 (Ag) 0 (none) 18.67 26.',\n",
       "  '44095317',\n",
       "  '75139001'],\n",
       " ['With the rapid development of the inertial sensor technology, numerous researchers have applied sensors based on microelectromechanical systems (MEMS) to measure gait motions .',\n",
       "  '22663276',\n",
       "  '3107404'],\n",
       " ['Estos factores se han estudiado mediante diversas teorías o modelos provenientes de la psicología social, las ciencias de la información y las ciencias sociales (como la administración, la sociología o la economía), lo que ha permitido el desarrollo de modelos interdisciplinarios y modelos de implementación .',\n",
       "  '3138489',\n",
       "  '3468380'],\n",
       " ['Phylogenetic and Clade Analysis of the Citrus NBS Genes To avoid mutation saturation effects in nucleotide sequences over time which can lead to an underestimation of the number of mutation events due to higher substitution rates versus proteins, we used the protein sequences of NBS domains, which are the most conserved part of NBS genes, to construct a phylogenetic tree of NBS genes.We only selected NBS domain sequences longer than 200 amino acid residues and contain both P-loop and MHDV motifs.Finally, 442 C. clementina, 393 C. sinensis China, and 264 C. sinensis USA NBS domain sequences were used for phylogenetic analysis (S2 Table ).A Maximum Likelihood (ML) phylogenetic tree of these 1,099 NBS genes was then constructed using FastTree .As shown in Fig.',\n",
       "  '2854174',\n",
       "  '1246355'],\n",
       " ['Three Groups of Citrus NBS Genes We identified 442, 393 and 264 genes with full length NBS domains from C. clementina, C. sinensis China and C. sinensis USA reference genomes, respectively.There are also many genes with short NBS domains in three Citrus genomes.The Citrus NBS genes can be divided into three groups according to the phylogenetic tree of NBS domains: two of them without TIR domain (CC1 and CC2 groups) and the other group with TIR domain (TIR group).The number of non-TIR NBS genes is three times of the number of TIR NBS genes.In most of the TIR NBS genes, we can find the LRR domains defined in Pfam database .We only can identify LRR domains in small part of non-TIR NBS genes using Pfam LRR domain definition.However, we can find the LxxLs repeats in most of the non-TIR NBS genes as shown in motifs from MEME.This implied that there may be other types of LRR domain in Citrus non-TIR NBS genes.',\n",
       "  '1246355',\n",
       "  '47209500'],\n",
       " ['Transposon Identification All long terminal repeat (LTR) retrotransponsons in each Citrus genome were identified using LTR finder with default parameters (-o 3 -t 1 -e 1 -m 2 -u -2).Then, we used a script program to match the location of the LTR transposons to the NBS-LRR genes in each Citrus genome.',\n",
       "  '47209500',\n",
       "  '1387956'],\n",
       " ['We identified 20 motifs amongst the NBS genes in each of the three main phylogenetic groups separately using MEME SUITE .The motif width was set to between 6 and 50 for MEME.Then, we searched the motif structure of all genes in each group using MAST with default parameters (-ev 10-mt 0.0001).',\n",
       "  '3041302',\n",
       "  '13391175'],\n",
       " ['If Mode sel is set high, the counters will operate normally from 0 10 to 63 .',\n",
       "  '4612570',\n",
       "  '32845648'],\n",
       " ['The MSSIM can be calculated using the equations presented in .',\n",
       "  '231915596',\n",
       "  '115443863'],\n",
       " ['The Huffman encoder is used in the JPEG standard and it can provide good compression results, however the RLE is more suitable for real-time applications .',\n",
       "  '358483',\n",
       "  '67873234'],\n",
       " ['The compression is unacceptable if the PSNR is below 20dB .',\n",
       "  '213795298',\n",
       "  '21689319'],\n",
       " [\"In , the output of Tong et al 's algorithm was considered the best performing feature that can be used for image quality assessment using neural networks.\",\n",
       "  '49885649',\n",
       "  '14484920'],\n",
       " ['The mini-app or dwarf approach we describe above is also starting to become more widely prevalent, mainly because it provides a tractable route to both predict performance and develop and test performance optimisations for new hardware.Its applicability to weather and climate modelling follows directly from the fact that the source of the methodology was in disciplines for which similar flat multiphysics profiles were involved.The concept of attempting to represent a cross section of applications or application characteristics is becoming well recognised (e.g.',\n",
       "  '15525086',\n",
       "  '51903739'],\n",
       " ['In most codes now we see one of two strategies: either MPI is still used across both nodes and node-local cores, or MPI is used in conjunction with OpenMP .In the latter case OpenMP is used to run some parallel threads on a core (\"hyper threading\") or parallel threads on a socket, but the threads are sharing memory, and directives are used to identify where this can occur.However, this strategy of mixing explicit library calls (MPI) and compiler directives (OpenMP) does not always work better than MPI alone, not least because vendor implementations of MPI can implement on-node \"messages\" with highly optimised libraries exploiting shared memory with performance that can be hard to beat.Conversely, MPI decomposition cannot be changed without paying a synchronisation and data movement penalty, whereas OpenMP can exploit the dynamic scheduling of work and better handle load balancing around (for example) physics parameterisations such as precipitation.Hence, the modeller following a hybrid approach has many issues to consider: how many parallel threads per node (between zero and the number of hyper-threads supportable on the node) and what parts of the code can take advantage of this technique?There is a balance to be struck which depends on knowledge of the code, the hardware, and the quality of the vendor-supplied compilers and libraries, and this balance needs to be re-evaluated for each architecture and model version.',\n",
       "  '8975400',\n",
       "  '16648176'],\n",
       " ['Requirements Existing models are known to have high levels of software quality , and maintaining quality models in the face of increasing scientific demands on what is simulated, ensemble size, and resolution will be crucial.It is these that define scientific quality -a model could be very high performance and portable, but not be suitable for the scientific objectives, and there is a spectrum between \"not suitable\" and \"ideal\".In fact, some level of model quality is often compromised for performance; for example, resolution and complexity are routinely sacrificed to fit weather forecasts in a particular time window or to reach a requisite number of simulated years per day for climate.',\n",
       "  '18043249',\n",
       "  '27643723'],\n",
       " ['and .The latter rewrote (in another language) the radiation code in a widely used fast low-resolution climate model for a custom chip -an effort which took 2.5 person years and delivered a significant speed-up on the new processor over the original version.However, although this rewrite achieved significant speed-ups even in the CPU version, it is no longer being actively used, primarily because of the downstream technical and scientific burden associated with assimilating and maintaining (both technically and scientifically) a rewrite in another language.This downstream burden is one of the main issues associated with re-engineering code: if the code \"owner\" is not engaged, then rewrites are unlikely to survive.',\n",
       "  '16648176',\n",
       "  '16027141'],\n",
       " ['Thus, CL-MRSC schemes allowing for multiple receivers of a single message have been proposed by Selvi et al and others, who focused on various security requirements [27]- Fig.',\n",
       "  '19596897',\n",
       "  '212646785'],\n",
       " ['Ming et al developed multi-message MRSC for healthcare IoT environments.',\n",
       "  '221386341',\n",
       "  '212646785'],\n",
       " ['Taking the smart metering environment as an example, leakage of sensitive information, such as personal power usage, may make it possible to cut off power to the home by executing a command that stops the power supply , .',\n",
       "  '41726504',\n",
       "  '26538884'],\n",
       " ['Computation Cost The Wang et al satisfies the security requirements, but as signcryption can be used to generate only single messages, the number of messages is high.',\n",
       "  '218971095',\n",
       "  '13900209'],\n",
       " ['Specifically, the transformed features with relatively low dimensionality of an input sample is calculated based on the distance between itself and all the other samples using .',\n",
       "  '15895606',\n",
       "  '212819545'],\n",
       " ['Motivated by , a relative-feature representation for input samples is applied to reduce the dimensionality of original features.',\n",
       "  '209202120',\n",
       "  '118717396'],\n",
       " ['The losses generated during relative-feature representation, CNN encoding, and prediction process, are calculated using the designed cost function as addressed by (5), (7), and .',\n",
       "  '212819545',\n",
       "  '198179736'],\n",
       " ['(9) 15: end for 16: end for 17: end while 18: return M public dataset UNSW-NB15, generated by the Australian security laboratory for CPS , is applied to evaluate the general prediction performance of the proposed method.',\n",
       "  '27653988',\n",
       "  '2829149'],\n",
       " ['Li et al built a dual deep learning (DL) model with an energy auditing mechanism, to monitor and identify cyber and physical attacks in IoT environments.',\n",
       "  '86650353',\n",
       "  '15895606'],\n",
       " ['In recent years, network-based ITS has become a hot topic of scientific research, such as the ELM-ART system developed by Yang et al .',\n",
       "  '46064641',\n",
       "  '3663262'],\n",
       " ['Learners can solve many problems through computer-based dialogue counseling .',\n",
       "  '3663262',\n",
       "  '63382381'],\n",
       " ['Lemma 4 If the input noise meets |υ − υ 0 | ≤ ι, the following inequalities can be obtained in a finite time: |ϑ 1 − υ 0 | ≤ a 1 ι =l |ϱ 1 −υ 0 | ≤ b 1 ι 1 2 =ε wherel andε are both positive constants exclusively depended on the design constants of the FOSMD.',\n",
       "  '4892587',\n",
       "  '198135450'],\n",
       " ['For example, the dynamic surface control (DSC) method was employed to estimate the derivative of the virtual controller in .',\n",
       "  '67872788',\n",
       "  '204832856'],\n",
       " ['And then, the finite-time consensus tracking control was handled in for multi agent systems with prescribed performance and mismatched uncertainties.',\n",
       "  '216047760',\n",
       "  '203089131'],\n",
       " ['In the case of K computer, it is reported that better communication performance is obtained when using larger message size .',\n",
       "  '64085782',\n",
       "  '222133'],\n",
       " ['Actually, 6 measurements have been executed for each image resolution and number of composition nodes, however as similar to we ignored the first measurement which can have higher initialization overhead and might produce biased results.',\n",
       "  '4983155',\n",
       "  '64085782'],\n",
       " ['The performance evaluation graph presented in shows that Binary-Swap and some versions of Radix-k time almost doubled from 512 to 65,536 composition nodes, and in the case of Radix-k with k value equal to 32 the time almost tripled.',\n",
       "  '4983155',\n",
       "  '18188187'],\n",
       " ['2-3 Swap can be considered an extension for Binary-Swap to provide image composition of non-power of two number of composition nodes.',\n",
       "  '5875143',\n",
       "  '144322'],\n",
       " ['3 and Table 1, we see that the proposed method has an accuracy of linearization similar to the previous method , but the running time for the linearization is much shorten.',\n",
       "  '126925572',\n",
       "  '206593680'],\n",
       " ['This method has been expanded into a pseudoformal linearization method by using an automatic choosing function and Chebyshev expansion .',\n",
       "  '126925572',\n",
       "  '206593680'],\n",
       " ['Numerical experiments indicate that the performance of the proposed method is superior to that of the previous method .',\n",
       "  '126925572',\n",
       "  '206593680'],\n",
       " ['The second baseline is an encoder-decoder Transformer model , where the input sequence is the individual words in g added with their 1D positional encodings, and the output sequence is the 2D encoded observation s added with their 2D positional encodings.',\n",
       "  '13756489',\n",
       "  '67856232'],\n",
       " ['To study this, we separate goals into G ID and G OOD following the principle of leaving one attribute combination out (shown in Table 1 and similar to the \"visual\" split in ).',\n",
       "  '212658007',\n",
       "  '216868834'],\n",
       " ['This has led to an interest in whether this aspect can be leveraged to get better generalization on unseen goals made up of familiar terms .',\n",
       "  '11974467',\n",
       "  '237353084'],\n",
       " ['The metric is described in more detail in Appendix G Each architecture for S(s, g) was trained using D train for 200,000 iterations with the parameters in Appendix F. The IQM and 95% confidence interval across seeds and top-10 checkpoints are reported in Table 2 using the package and method provided by .',\n",
       "  '237353084',\n",
       "  '237257594'],\n",
       " ['Hence, the cooperation within NOMA users is proposed in and the outage probability of cooperative-NOMA (C-NOMA) is analyzed.',\n",
       "  '60846036',\n",
       "  '8021083'],\n",
       " ['Since NOMA provides a spectral efficient communication, the potential of NOMA for massive machine type communication (MMTC) led researchers to investigate NOMA involved systems and tremendous effort has been devoted to integrate NOMA in future wireless networks , .',\n",
       "  '13746058',\n",
       "  '60846036'],\n",
       " ['It is given for BPSK in , by utilizing [5, eq.', '57762457', '553424'],\n",
       " ['Then, the error probability of C-NOMA within two users is derived for quadrature phase shift keying (QPSK) and binary phase shift keying (BPSK) modulations .',\n",
       "  '57762457',\n",
       "  '553424'],\n",
       " ['INTRODUCTION N ON-orthogonal multiple access (NOMA) is introduced to serve multiple users on the same resource block by implementing superposition coding (SC) at transmitter and iterative successive interference canceler (SIC) at receivers .',\n",
       "  '26735476',\n",
       "  '1682687'],\n",
       " ['One (relatively minor) issue with solving d uncoupled problems is that one subsequently needs to reconcile the solutions to obtain a coherent global model over all the variables, although there are several ways to accomplish this .',\n",
       "  '12155197',\n",
       "  '88524020'],\n",
       " ['If a data analyst has access to additional information about potential latent variables (e.g., the latent variables take on non-negative or categorical values) or wishes to fit to models in which the latent variables have additional structure, one can design tighter convex regularizers than the nuclear norm .',\n",
       "  '51052',\n",
       "  '301178'],\n",
       " ['These are perhaps to be expected based on the theoretical analyses in , and it would be useful to combine and formalize these results in our context by showing that the Type-I and Type-II errors can be provably controlled under appropriate assumptions.',\n",
       "  '88524020',\n",
       "  '301178'],\n",
       " ['Now he will hire the machines on rent with the objective to complete the task with minimum total rental cost and zero idle time of machines .',\n",
       "  '407581',\n",
       "  '225717887'],\n",
       " ['Some situations come from sectors where machines used in production are less expensive but these cannot be stopped and restarted easily .',\n",
       "  '14201587',\n",
       "  '69302663'],\n",
       " ['Let C1 ij and C2 be the renting cost for one unit time of machines η and μ respectively .',\n",
       "  '14201587',\n",
       "  '62580144'],\n",
       " ['Indeed, the path length of the near infrared light and the NIRS sensitivity are both dependent on the scalp-to-cortex distance .',\n",
       "  '34111654',\n",
       "  '26721537'],\n",
       " ['The PFC is of particular interest since it plays a significant role in social interaction .',\n",
       "  '945353',\n",
       "  '15627151'],\n",
       " ['Besides these English data sets, we also obtained doubly-annotated POS data from the French Social Media Bank project .',\n",
       "  '7811096',\n",
       "  '855546'],\n",
       " ['If we pre-filter the data via Wiktionary and use an itemresponse model rather than majority voting, the agreement rises to 80.58%.',\n",
       "  '6617574',\n",
       "  '7811096']]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intermediate[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2521441it [00:38, 64763.71it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "data = []\n",
    "with open('/scratch/lamdo/s2orc/processed/citation_contexts_triplets/raw.tsv') as f:\n",
    "    for i, line in enumerate(tqdm(f)):\n",
    "        splitted_line = line.strip().split(\"\\t\")\n",
    "        data.append(splitted_line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Recall is the fraction of the total amount of relevant instances that were actually retrieved .',\n",
       "  \"The Precision-Recall Plot Is More Informative than the ROC Plot When Evaluating Binary Classifiers on Imbalanced Datasets. Binary classifiers are routinely evaluated with performance measures such as sensitivity and specificity, and performance is frequently illustrated with Receiver Operating Characteristics (ROC) plots. Alternative measures such as positive predictive value (PPV) and the associated Precision/Recall (PRC) plots are used less frequently. Many bioinformatics studies develop and evaluate classifiers that are to be applied to strongly imbalanced datasets in which the number of negatives outweighs the number of positives significantly. While ROC plots are visually appealing and provide an overview of a classifier's performance across a wide range of specificities, one can ask whether ROC plots could be misleading when applied in imbalanced classification scenarios. We show here that the visual interpretability of ROC plots in the context of imbalanced datasets can be deceptive with respect to conclusions about the reliability of classification performance, owing to an intuitive but wrong interpretation of specificity. PRC plots, on the other hand, can provide the viewer with an accurate prediction of future classification performance due to the fact that they evaluate the fraction of true positives among positive predictions. Our findings have potential implications for the interpretation of a large number of studies that use ROC plots on imbalanced datasets.\",\n",
       "  'Urban Structure and Urban Growth. Abstract Urban structure is construed here as the result of a community effort to overcome distance between residents and required facilities. The elements of structure are identified, the mutual influences of urban structure and urban growth are considered, and there is an effort made to demonstrate the dynamic inter dependency of various urban structural phenomena by analyzing the effects of a change in transportation efficiency. However, the relationships presumed to hold here are as yet largely hypothetical and require further investigation. This article is timely in view of the current crisis in metropolitan structure occasioned mainly by rising automobile ownership.'],\n",
       " ['This grid structure is aligned with National Land Cover Database (NLCD) products (projected using Albers Equal Area Conic system), enabling researchers to combine or compare our products with standard national-scale datasets such as land cover, tree canopy cover, and urban imperviousness .',\n",
       "  'A new generation of the United States National Land Cover Database: Requirements, research priorities, design, and implementation strategies. ',\n",
       "  'Multi-scale solution for building extraction from LiDAR and image data.'],\n",
       " ['PCA analysis of replicates from sample A and B The relationships among spectra can be visualized by an unsupervised pattern recognition algorithm PCA .',\n",
       "  'Megavariate data analysis of mass spectrometric proteomics data using latent variable projection method. ',\n",
       "  'A comparison of two algorithms for warping of analytical signals.'],\n",
       " ['Two μL of cDNA was used as input for subsequent multiplex-PCR amplification of the CHIKV genome performed using a tiled-amplicon approach .',\n",
       "  'Multiplex PCR method for MinION and Illumina sequencing of Zika and other virus genomes directly from clinical samples. ',\n",
       "  'MEGA7: Molecular Evolutionary Genetics Analysis Version 7.0 for Bigger Datasets. We present the latest version of the Molecular Evolutionary Genetics Analysis (Mega) software, which contains many sophisticated methods and tools for phylogenomics and phylomedicine. In this major upgrade, Mega has been optimized for use on 64-bit computing systems for analyzing larger datasets. Researchers can now explore and analyze tens of thousands of sequences in Mega The new version also provides an advanced wizard for building timetrees and includes a new functionality to automatically predict gene duplication events in gene family trees. The 64-bit Mega is made available in two interfaces: graphical and command line. The graphical user interface (GUI) is a native Microsoft Windows application that can also be used on Mac OS X. The command line Mega is available as native applications for Windows, Linux, and Mac OS X. They are intended for use in high-throughput and scripted analysis. Both versions are available from www.megasoftware.net free of charge.'],\n",
       " ['NTN Use Cases Non-terrestrial systems have been proposed to enable several applications, including weather forecasting, video surveillance, TV broadcast, remote sensing, and navigation, for several years.On the other hand, recent technological advances in the aerial/space sector have enabled the implementation of more sophisticated use cases, such as distributed computing and content broadcasting, service boosting for users in congested areas, eMBB in underserved areas, and multi-connectivity for service continuity via cellular networks .',\n",
       "  'Evolution of Non-Terrestrial Networks From 5G to 6G: A Survey. Non-terrestrial networks (NTNs) traditionally have certain limited applications. However, the recent technological advancements and manufacturing cost reduction opened up myriad applications of NTNs for 5G and beyond networks, especially when integrated into terrestrial networks (TNs). This article comprehensively surveys the evolution of NTNs highlighting their relevance to 5G networks and essentially, how it will play a pivotal role in the development of 6G ecosystem. We discuss important features of NTNs integration into TNs and the synergies by delving into the new range of services and use cases, various architectures, technological enablers, and higher layer aspects pertinent to NTNs integration. Moreover, we review the corresponding challenges arising from the technical peculiarities and the new approaches being adopted to develop efficient integrated ground-air-space (GAS) networks. Our survey further includes the major progress and outcomes from academic research as well as industrial efforts representing the main industrial trends, field trials, and prototyping towards the 6G networks.',\n",
       "  'New Radio Numerology and Waveform Evaluation for Satellite Integration into 5G Terrestrial Network. This paper analyses the New Radio (NR) air interface waveforms and numerologies in the context of current activities and studies of 3GPP related to the feasibility and standardisation of necessary adaptations for the 5G NR to support integrated-satellite-terrestrial networks with low earth orbit (LEO) satellites. Frequency-localized orthogonal frequency division multiplexing (OFDM)-based candidate waveforms are recommended by 3GPP as the waveforms for the NR in order to preserve the advantages of OFDM as well as maintain backward compatibility. 5G New Radio enables diverse service support, efficient synchronization and channel adaptability using a multinumerology concept, which defines a family of parameters of the parent waveform, that are related to each other by scaling. The major design challenges in the LEO satellite scenario are power limited link budget and high Doppler effects which can be addressed by choosing waveforms with small peak to average power ratio (PAPR) and sub-carrier bandwidth adaptation respectively. Hence, the selection of the right waveform and numerology is of prime relevance for the proper adaptation of 5G NR for LEO satellite terrestrial integration. The performance evaluation of the new air interface waveforms, with different numerologies, are carried out under the effect of carrier frequency offset (CFO), multipath effects, non-linearity, phase noise and additive white Gaussian noise (AWGN).'],\n",
       " ['Non-terrestrial technology has long been thought to support operations such as home delivery, weather forecasting, video surveillance, television transmission, remote sensing, and navigation.To enable more advanced use cases, such as Communication Resilience and Service Continuity, Global Satellite Overlay, Ubiquitous Internet of Things (IoT) Broadcasting, Advanced Backhauling, and Energy-Efficient Hybrid Multiplay, the recent technological advancements in the aerial/space industry have however made it possible for integration between terrestrial and non-terrestrial technologies.The few enabling technologies to support NTN in 6G for architecture, spectrum, antenna, and higher layers advancements, respectively, include gallium nitride (GaN), cognitive spectrum, multi-beam structures, and TCP spoofing and multiplexing .',\n",
       "  'Non-Terrestrial Networks in the 6G Era: Challenges and Opportunities. Many organizations recognize non-terrestrial networks (NTNs) as a key component to provide cost-effective and high-capacity connectivity in future 6th generation (6G) wireless networks. Despite this premise, there are still many questions to be answered for proper network design, including those associated to latency and coverage constraints. In this article, after reviewing research activities on NTNs, we present the characteristics and enabling technologies of NTNs in the 6G landscape and shed light on the challenges in the field that are still open for future research. As a case study, we evaluate the performance of an NTN scenario in which aerial/space vehicles use millimeter wave (mmWave) frequencies to provide access connectivity to on-the-ground mobile terminals as a function of different networking configurations.',\n",
       "  'Nanosatellite-5G Integration in the Millimeter Wave Domain: A Full Top-Down Approach. This paper presents a novel network architecture for an integrated nanosatellite (nSAT)-5G system operating in the millimeter-wave (mmWave) domain. The architecture is realized adopting a delay/disruption tolerant networking (DTN) approach allowing end users to adopt standard devices. A buffer aware contact graph routing algorithm is designed to account for the buffer occupancy of the nSATs and for the connection planning derived from their visibility periods. At the terrestrial uplink, a coded random access is employed to realize a high-capacity interface for the typically irregular traffic of 5G users, while, at the space uplink, the DTN architecture is combined with the contention resolution diversity slotted Aloha protocol to match the recent update of the DVB-RCS2 standard. To achieve a reliable testing of the introduced functionalities, an accurate analysis of the statistic of the signal to interference-plus-noise ratio and of the capture probability at each mmWave link is developed by including interference, shadowing, fading, and noise. The application of the designed architecture to data transfer services in conjunction with possible delay reduction strategies, and an extension to inter-satellite communication, are finally presented by estimating the resulting loss/delay performance through a discrete-time discrete-event platform based on the integration of Matlab with Network Simulator 3.'],\n",
       " ['Similar approaches have been adopted in modulation classification with good effect , .',\n",
       "  'Automatic digital modulation recognition using artificial neural network and genetic algorithm. ',\n",
       "  'Modulation Classification Using Received Signal’s Amplitude Distribution for Coherent Receivers. In this letter, we propose a modulation classification algorithm, which is based on the received signal’s amplitude for coherent optical receivers. The proposed algorithm classifies the modulation format from several possible candidates by differentiating the cumulative distribution function (cdf) curves of their normalized amplitudes. The candidate with the most similar cdf to the received signal is selected. The measure of similarity is the minimum average distance between these cdfs. Five commonly used quadrature amplitude modulation formats in digital coherent optical systems are employed. Optical back-to-back experiments and extended simulations are carried out to investigate the performance of the proposed algorithm. Results show that the proposed algorithm achieves accurate classification at optical signal-to-noise ratios of interest. Furthermore, it does not require carrier recovery.'],\n",
       " ['Kanterakis and Su tried to reduce the computational complexity of the likelihood based classifier by modifying the likelihood function .',\n",
       "  'Modulation Classification in MIMO Systems. ',\n",
       "  'Fast and Robust Modulation Classification via Kolmogorov-Smirnov Test.'],\n",
       " ['One example is , where the authors predicted future options prices using conventional pricing techniques combined with two learning models: Neural Networks and Support Vector Regression.',\n",
       "  'Improving option price forecasts with neural networks and support vector regressions. ',\n",
       "  'Heteroskedasticity in Stock Return Data: Volume versus GARCH Effects. This paper provides empirical support for the notion that autoregressive conditional heteroskedasticity in daily stock return data reflects time dependence in the process generating information flow to the market. Daily trading volume, used as a proxy for information arrival time, is shown to have significant explanatory power regarding the variance of daily returns, which is an implication of the assumption that daily returns are subordinated to intraday equilibrium returns. Furthermore, autoregressive conditional heteroskedasticity effects tend to disappear when volume is included in the variance equation. Copyright 1990 by American Finance Association.'],\n",
       " ['Lensless imaging provides an alternative microscopic approach, in which the shadow of a sample is recorded on an image sensor directly .',\n",
       "  'A review of recent progress in lens-free imaging and sensing. ',\n",
       "  'THE ACTION SPECTRUM, ABSORPTANCE AND QUANTUM YIELD OF PHOTOSYNTHESIS IN CROP PLANTS.'],\n",
       " ['Recently, several techniques have been investigated to improve the resolution of fluorescence lensless imaging including hardware designs and computational algorithms .',\n",
       "  'Lensless Imaging and Sensing. High-resolution optical microscopy has traditionally relied on high-magnification and high-numerical aperture objective lenses. In contrast, lensless microscopy can provide high-resolution images without the use of any focusing lenses, offering the advantages of a large field of view, high resolution, cost-effectiveness, portability, and depth-resolved three-dimensional (3D) imaging. Here we review various approaches to lensless imaging, as well as its applications in biosensing, diagnostics, and cytometry. These approaches include shadow imaging, fluorescence, holography, superresolution 3D imaging, iterative phase recovery, and color imaging. These approaches share a reliance on computational techniques, which are typically necessary to reconstruct meaningful images from the raw data captured by digital image sensors. When these approaches are combined with physical innovations in sample preparation and fabrication, lensless imaging can be used to image and sense cells, viruses, nanoparticles, and biomolecules. We conclude by discussing several ways in which lensless imaging and sensing might develop in the near future.',\n",
       "  'Primary production of the biosphere: integrating terrestrial and oceanic components. Integrating conceptually similar models of the growth of marine and terrestrial primary producers yielded an estimated global net primary production (NPP) of 104.9 petagrams of carbon per year, with roughly equal contributions from land and oceans. Approaches based on satellite indices of absorbed solar radiation indicate marked heterogeneity in NPP for both land and oceans, reflecting the influence of physical and ecological processes. The spatial and temporal distributions of ocean NPP are consistent with primary limitation by light, nutrients, and temperature. On land, water limitation imposes additional constraints. On land and ocean, progressive changes in NPP can result in altered carbon storage, although contrasts in mechanisms of carbon storage and rates of organic matter turnover result in a range of relations between carbon storage and changes in NPP.'],\n",
       " ['Histogram of oriented gradients (HOG) and support vector machine (SVM) were used to detect particles in the lensless imaging mode .',\n",
       "  'Improved Face Recognition Rate Using HOG Features and SVM Classifier. A novel face recognition algorithm is presented in this paper. Histogram of Oriented Gradient features are extracted both for the test image and also for the training images and given to the Support Vector Machine classifier. The detailed steps of HOG feature extraction and the classification using SVM is presented. The algorithm is compared with the Eigen feature based face recognition algorithm. The proposed algorithm and PCA are verified using 8 different datasets. Results show that in all the face datasets the proposed algorithm shows higher face recognition rate when compared with the traditional Eigen feature based face recognition algorithm. There is an improvement of 8.75% face recognition rate when compared with PCA based face recognition algorithm. The experiment is conducted on ORL database with 2 face images for testing and 8 face images for training for each person. Three performance curves namely CMC, EPC and ROC are considered. The curves show that the proposed algorithm outperforms when compared with PCA algorithm. IndexTerms: Facial features, Histogram of Oriented Gradients, Support Vector Machine, Principle Component Analysis.',\n",
       "  'Growth promotion of three microalgae, Chlamydomonas reinhardtii, Chlorella vulgaris and Euglena gracilis, by in situ indigenous bacteria in wastewater effluent. BackgroundMicroalgae are a promising biomass feedstock for biofuels production. The use of wastewater effluent as a nutrient medium would improve the economics of microalgal biofuels production. Bacterial communities in aquatic environments may either stimulate or inhibit microalgal growth. Microalgal productivity could be enhanced if the positive effects of indigenous bacteria could be exploited. However, much is unknown about the effects of indigenous bacteria on microalgal growth and the characteristics of bacterial communities associated with microalgae in microalgae–effluent culture. To assess the effects of the indigenous bacteria in wastewater effluent on microalgal growth, three microalgae, Chlamydomonas reinhardtii, Chlorella vulgaris, and Euglena gracilis, were cultured in two municipal wastewater effluents and one swine wastewater effluent with and without indigenous bacteria for 7\\xa0days.ResultsAll microalgae grew better in all effluents with indigenous bacteria than without bacteria. Biomass production of C. reinhardtii, C. vulgaris, and E. gracilis increased\\u2009>\\u20091.5, 1.8–2.8, and >\\u20092.1-fold, respectively, compared to the axenic cultures of each microalga. The in situ indigenous bacterial communities in the effluents therefore promoted the growth of the three microalgae during 7-day cultures. Furthermore, the total numbers of bacterial 16S rRNA genes in the 7-day microalgae–effluent cultures were 109‒793 times the initial numbers. These results suggest that the three microalgae produced and supplied organic carbon that supported bacterial growth in the effluent. At the phylum and class levels, Proteobacteria (Alphaproteobacteria and Betaproteobacteria) and Bacteroidetes (Sphingobacteriia and Saprospirae) were selectively enriched in all microalgae–effluent cultures. The enriched core bacterial families and genera were functions of the microalgal species and effluents. These results suggest that certain members of the bacterial community promote the growth of their “host” microalgal species.ConclusionTo enhance their own growth, microalgae may be able to selectively stimulate specific bacterial groups from among the in situ indigenous bacterial community found in wastewater effluent (i.e., microalgae growth-promoting bacteria: MGPB). The MGPB from effluent cultures could be used as “probiotics” to enhance microalgal growth in effluent culture. Wastewater effluent may therefore be a valuable resource, not only of nutrients, but also of MGPB to enable more efficient microalgal biomass production.'],\n",
       " ['train a sequence of discriminative models to predict data selection, ordering and realisation.',\n",
       "  'Generation by Inverting a Semantic Parser that Uses Statistical Machine Translation. ',\n",
       "  'ONTOGENERATION: Reusing Domain and Linguistic Ontologies for Spanish Text Generation.'],\n",
       " ['KB Bio 101 The foundational component of the KB is the Component Library (CLIB), an upper ontology which is linguistically motivated and designed to support the representation of knowledge for automated reasoning .',\n",
       "  'Project Halo Update - Progress Toward Digital Aristotle. In the winter, 2004 issue of AI Magazine, we reported Vulcan Inc.\\'s first step toward creating a question-answering system called \"Digital Aristotle.\" The goal of that first step was to assess the state of the art in applied Knowledge Representation and Reasoning (KRR) by asking AI experts to represent 70 pages from the advanced placement (AP) chemistry syllabus and to deliver knowledge-based systems capable of answering questions from that syllabus. This paper reports the next step toward realizing a Digital Aristotle: we present the design and evaluation results for a system called AURA, which enables domain experts in physics, chemistry, and biology to author a knowledge base and that then allows a different set of users to ask novel questions against that knowledge base. These results represent a substantial advance over what we reported in 2004, both in the breadth of covered subjects and in the provision of sophisticated technologies in knowledge representation and reasoning, natural language processing, and question answering to domain experts and novice users.',\n",
       "  'The KBGen Challenge.'],\n",
       " ['Another trend of work relevant to this paper is generation from databases using parallel corpora of data and text.',\n",
       "  'A Simple Domain-Independent Probabilistic Approach to Generation. ',\n",
       "  'Generating Natural Language from Linked Data: Unsupervised template extraction.'],\n",
       " ['Finally, recent work by the SWAT project 1 has focused on pro-ducing descriptions of ontologies that are both coherent and efficient .',\n",
       "  'Grouping Axioms for More Coherent Ontology Descriptions. ',\n",
       "  'Expanding the Scope of the ATIS Task: The ATIS-3 Corpus. The Air Travel Information System (ATIS) domain serves as the common evaluation task for ARPA spoken language system developers. To support this task, the Multi-Site ATIS Data COllection Working group (MADCOW) coordinates data collection activities. This paper describes recent MADCOW activities. In particular, this paper describes the migration of the ATIS task to a richer relational database and development corpus (ATIS-3) and describes the ATIS-3 corpus. The expanded database, which includes information on 46 US and Canadian cities and 23,457 flights, was released in the fall of 1992, and data collection for the ATIS-3 corpus began shortly thereafter. The ATIS-3 corpus now consists of a total of 8297 released training utterances and 3211 utterances reserved for testing, collected at BBN, CMU, MIT, NIST and SRI. 2906 of the training utterances have been annotated with the correct information from the database. This paper describes the ATIS-3 corpus in detail, including breakdowns of data by type (e.g. context-independent, context-dependent, and unevaluable)and variations in the data collected at different sites. This paper also includes a description of the ATIS-3 database. Finally, we discuss future data collection and evaluation plans.'],\n",
       " ['proposed to create a template for each relation type and then compute increased log probability of the sentences from these templates with the use of BERT as in .For example, a template for the relation \"LOCATED-IN\" might look like this -\"the <e1> is in the <e2>\".So if the first entity is \"toothbrush\" and the second is \"bathroom\", the sentence from the template will be \"the toothbrush is in the bathroom\".With the selected threshold of probability, it will be possible to separate the presence or absence of relation between two entities and also its type.',\n",
       "  'Measuring Bias in Contextualized Word Representations. Contextual word embeddings such as BERT have achieved state of the art performance in numerous NLP tasks. Since they are optimized to capture the statistical properties of training data, they tend to pick up on and amplify social stereotypes present in the data as well. In this study, we (1) propose a template-based method to quantify bias in BERT; (2) show that this method obtains more consistent results in capturing social biases than the traditional cosine based method; and (3) conduct a case study, evaluating gender bias in a downstream task of Gender Pronoun Resolution. Although our case study focuses on gender bias, the proposed technique is generalizable to unveiling other biases, including in multiclass settings, such as racial and religious biases.',\n",
       "  'Multi-Task Identification of Entities, Relations, and Coreference for Scientific Knowledge Graph Construction. We introduce a multi-task setup of identifying entities, relations, and coreference clusters in scientific articles. We create SciERC, a dataset that includes annotations for all three tasks and develop a unified framework called SciIE with shared span representations. The multi-task setup reduces cascading errors between tasks and leverages cross-sentence relations through coreference links. Experiments show that our multi-task model outperforms previous models in scientific information extraction without using any domain-specific features. We further show that the framework supports construction of a scientific knowledge graph, which we use to analyze information in scientific literature.'],\n",
       " ['Then we got an estimate of the probability of each sentence using the model GPT2 .After choosing the most probable pattern for each relation, we again compared the probability of sentences from these best templates.The most likely sentence would reflect the true relation between the terms.The schematic work of the method is presented in the Figure 1.To measure the probability we used the perplexity score.In general, this value can be described as the model uncertainty measure when predicting each of the next token, hence the lower the perplexity, the more certain the model in predicting this sequence.',\n",
       "  'Language Models are Unsupervised Multitask Learners. ',\n",
       "  'Measuring Bias in Contextualized Word Representations. Contextual word embeddings such as BERT have achieved state of the art performance in numerous NLP tasks. Since they are optimized to capture the statistical properties of training data, they tend to pick up on and amplify social stereotypes present in the data as well. In this study, we (1) propose a template-based method to quantify bias in BERT; (2) show that this method obtains more consistent results in capturing social biases than the traditional cosine based method; and (3) conduct a case study, evaluating gender bias in a downstream task of Gender Pronoun Resolution. Although our case study focuses on gender bias, the proposed technique is generalizable to unveiling other biases, including in multiclass settings, such as racial and religious biases.'],\n",
       " ['Using prototype vectors of relations The second approach for relation identification that we tried is based on the usage of the prototype vectors of relations.It can be attributed to few-shot approaches.First of all, we manually chose 138 best examples from the train part of the dataset to create a prototype vectors for each type of relations.In selecting the best examples we were guided by the following criterion: the example shows only one type of relations and has short context which includes only two terms of interest.Then we got the vectors of these of sentences.Vectors of sentences are the embeddings of CLS token from BERT .Each prototype vector is an average of the vectors of sentences reflecting each relation.Once these prototype vectors are obtained, they can be used to classify test examples.By computing the value of the cosine similarity of the example and the prototypes, we can determine which relation is most similar to this example.Schematic graphics that reflect the work of this method can be seen in Figure 2.',\n",
       "  'BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding. We introduce a new language representation model called BERT, which stands for Bidirectional Encoder Representations from Transformers. Unlike recent language representation models (Peters et al., 2018a; Radford et al., 2018), BERT is designed to pre-train deep bidirectional representations from unlabeled text by jointly conditioning on both left and right context in all layers. As a result, the pre-trained BERT model can be fine-tuned with just one additional output layer to create state-of-the-art models for a wide range of tasks, such as question answering and language inference, without substantial task-specific architecture modifications. BERT is conceptually simple and empirically powerful. It obtains new state-of-the-art results on eleven natural language processing tasks, including pushing the GLUE score to 80.5 (7.7 point absolute improvement), MultiNLI accuracy to 86.7% (4.6% absolute improvement), SQuAD v1.1 question answering Test F1 to 93.2 (1.5 point absolute improvement) and SQuAD v2.0 Test F1 to 83.1 (5.1 point absolute improvement).',\n",
       "  'A New Entity Salience Task with Millions of Training Examples. Although many NLP systems are moving toward entity-based processing, most still identify important phrases using classical keyword-based approaches. To bridge this gap, we introduce the task of entity salience: assigning a relevance score to each entity in a document. We demonstrate how a labeled corpus for the task can be automatically generated from a corpus of documents and accompanying abstracts. We then show how a classifier with features derived from a standard NLP pipeline outperforms a strong baseline by 34%. Finally, we outline initial experiments on further improving accuracy by leveraging background knowledge about the relationships between entities.'],\n",
       " ['With the introduction of large language models their use became one of the main methods of solving this problem.However, such methods require a lot of well-annotated data for training.Currently there are no datasets available for this task in a scientific field in Russian, and manual annotation takes a long time and requires the efforts of more than one person to objectively label the relations.Therefore, in this paper we decided to pay our special attention to zero-shot and few-shot approaches that do not require a lot of annotated data.There are some examples of them.',\n",
       "  'BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding. We introduce a new language representation model called BERT, which stands for Bidirectional Encoder Representations from Transformers. Unlike recent language representation models (Peters et al., 2018a; Radford et al., 2018), BERT is designed to pre-train deep bidirectional representations from unlabeled text by jointly conditioning on both left and right context in all layers. As a result, the pre-trained BERT model can be fine-tuned with just one additional output layer to create state-of-the-art models for a wide range of tasks, such as question answering and language inference, without substantial task-specific architecture modifications. BERT is conceptually simple and empirically powerful. It obtains new state-of-the-art results on eleven natural language processing tasks, including pushing the GLUE score to 80.5 (7.7 point absolute improvement), MultiNLI accuracy to 86.7% (4.6% absolute improvement), SQuAD v1.1 question answering Test F1 to 93.2 (1.5 point absolute improvement) and SQuAD v2.0 Test F1 to 83.1 (5.1 point absolute improvement).',\n",
       "  'Language Models are Unsupervised Multitask Learners.'],\n",
       " ['Statistics for our dataset is presented in Table 1.Each abstract was annotated by two annotators.The task was to classify the relations between each possible pair of terms in each sentence in the abstract.The terms in the texts were already extracted.During the annotation, we followed the instructions proposed in .',\n",
       "  'Entity Recognition and Relation Extraction from Scientific and Technical Texts in Russian. This paper is devoted to the study of methods for information extraction (entity recognition and relation classification) from scientific texts on information technology. Scientific publications provide valuable information into cutting-edge scientific advances, but efficient processing of increasing amounts of data is a time-consuming task. In this paper, several modifications of methods for the Russian language are proposed. It also includes the results of experiments comparing a keyword extraction method, vocabulary method, and some methods based on neural networks. Text collections for these tasks exist for the English language and are actively used by the scientific community, but at present, such datasets in Russian are not publicly available. In this paper, we present a corpus of scientific texts in Russian, RuSERRC. This dataset consists of 1600 unlabeled documents and 80 labeled with entities and semantic relations (6 relation types were considered). The dataset and models are available at https://github.com/iis-research-team. We hope they can be useful for research purposes and development of information extraction systems.',\n",
       "  'A New Entity Salience Task with Millions of Training Examples. Although many NLP systems are moving toward entity-based processing, most still identify important phrases using classical keyword-based approaches. To bridge this gap, we introduce the task of entity salience: assigning a relevance score to each entity in a document. We demonstrate how a labeled corpus for the task can be automatically generated from a corpus of documents and accompanying abstracts. We then show how a classifier with features derived from a standard NLP pipeline outperforms a strong baseline by 34%. Finally, we outline initial experiments on further improving accuracy by leveraging background knowledge about the relationships between entities.'],\n",
       " ['Hundreds of additional entries are added to SCOPe each month, because after at least one structure from a SCOPe family has been classified by a human curator, most other structures from that family may be added automatically by our rigorously validated software pipeline .',\n",
       "  'SCOPe: Structural Classification of Proteins—extended, integrating SCOP and ASTRAL data and classification of new structures. Structural Classification of Proteins—extended (SCOPe, http://scop.berkeley.edu) is a database of protein structural relationships that extends the SCOP database. SCOP is a manually curated ordering of domains from the majority of proteins of known structure in a hierarchy according to structural and evolutionary relationships. Development of the SCOP 1.x series concluded with SCOP 1.75. The ASTRAL compendium provides several databases and tools to aid in the analysis of the protein structures classified in SCOP, particularly through the use of their sequences. SCOPe extends version 1.75 of the SCOP database, using automated curation methods to classify many structures released since SCOP 1.75. We have rigorously benchmarked our automated methods to ensure that they are as accurate as manual curation, though there are many proteins to which our methods cannot be applied. SCOPe is also partially manually curated to correct some errors in SCOP. SCOPe aims to be backward compatible with SCOP, providing the same parseable files and a history of changes between all stable SCOP and SCOPe releases. SCOPe also incorporates and updates the ASTRAL database. The latest release of SCOPe, 2.03, contains 59 514 Protein Data Bank (PDB) entries, increasing the number of structures classified in SCOP by 55% and including more than 65% of the protein structures in the PDB.',\n",
       "  'Pfam: The protein families database in 2021. Abstract The Pfam database is a widely used resource for classifying protein sequences into families and domains. Since Pfam was last described in this journal, over 350 new families have been added in Pfam 33.1 and numerous improvements have been made to existing entries. To facilitate research on COVID-19, we have revised the Pfam entries that cover the SARS-CoV-2 proteome, and built new entries for regions that were not covered by Pfam. We have reintroduced Pfam-B which provides an automatically generated supplement to Pfam and contains 136 730 novel clusters of sequences that are not yet matched by a Pfam family. The new Pfam-B is based on a clustering by the MMseqs2 software. We have compared all of the regions in the RepeatsDB to those in Pfam and have started to use the results to build and refine Pfam repeat families. Pfam is freely available for browsing and download at http://pfam.xfam.org/.'],\n",
       " ['These results are similar to the novelty of newly classified structures in SCOP and SCOPe, as we previously reported .',\n",
       "  'SCOPe: Manual Curation and Artifact Removal in the Structural Classification of Proteins - extended Database. ',\n",
       "  '3DSwap: curated knowledgebase of proteins involved in 3D domain swapping. Three-dimensional domain swapping is a unique protein structural phenomenon where two or more protein chains in a protein oligomer share a common structural segment between individual chains. This phenomenon is observed in an array of protein structures in oligomeric conformation. Protein structures in swapped conformations perform diverse functional roles and are also associated with deposition diseases in humans. We have performed in-depth literature curation and structural bioinformatics analyses to develop an integrated knowledgebase of proteins involved in 3D domain swapping. The hallmark of 3D domain swapping is the presence of distinct structural segments such as the hinge and swapped regions. We have curated the literature to delineate the boundaries of these regions. In addition, we have defined several new concepts like ‘secondary major interface’ to represent the interface properties arising as a result of 3D domain swapping, and a new quantitative measure for the ‘extent of swapping’ in structures. The catalog of proteins reported in 3DSwap knowledgebase has been generated using an integrated structural bioinformatics workflow of database searches, literature curation, by structure visualization and sequence–structure–function analyses. The current version of the 3DSwap knowledgebase reports 293 protein structures, the analysis of such a compendium of protein structures will further the understanding molecular factors driving 3D domain swapping. Database URL: http://caps.ncbs.res.in/3dswap'],\n",
       " ['Apart from these constructs, previous studies also found that innovativeness and trust have an effect .',\n",
       "  'Perceived Usefulness, Perceived Ease of Use, and User Acceptance of Information Technology. Valid measurement scales for predicting user acceptance of computers are in short supply. Most subjective measures used in practice are unvalidated, and their relationship to system usage is unknown. The present research develops and validates new scales for two specific variables, perceived usefulness and perceived ease of use, which are hypothesized to be fundamental determinants of user acceptance. Definitions of these two variables were used to develop scale items that were pretested for content validity and then tested for reliability and construct validity in two studies involving a total of 152 users and four application programs. The measures were refined and streamlined, resulting in two six-item scales with reliabilities of .98 for usefulness and .94 for ease of use. The scales exhibited hgih convergent, discriminant, and factorial validity. Perceived usefulness was significnatly correlated with both self-reported current usage r = .63, Study 1) and self-predicted future usage r = .85, Study 2). Perceived ease of use was also significantly correlated with current usage r = .45, Study 1) and future usage r = .59, Study 2). In both studies, usefulness had a signficnatly greater correaltion with usage behavior than did ease of use. Regression analyses suggest that perceived ease of use may actually be a causal antecdent to perceived usefulness, as opposed to a parallel, direct determinant of system usage. Implications are drawn for future research on user acceptance.',\n",
       "  'Factors influencing adoption of mobile banking by Jordanian bank customers: Extending UTAUT2 with trust.'],\n",
       " ['Thus, we reconfigured and applied UTAUT2, a model borrowed from Venkatesh et al .',\n",
       "  'Consumer Acceptance and Use of Information Technology: Extending the Unified Theory of Acceptance and Use of Technology. This paper extends the unified theory of acceptance and use of technology (UTAUT) to study acceptance and use of technology in a consumer context. Our proposed UTAUT2 incorporates three constructs into UTAUT: hedonic motivation, price value, and habit. Individual differences--namely, age, gender, and experience--are hypothesized to moderate the effects of these constructs on behavioral intention and technology use. Results from a two-stage online survey, with technology use data collected four months after the first survey, of 1,512 mobile Internet consumers supported our model. Compared to UTAUT, the extensions proposed in UTAUT2 produced a substantial improvement in the variance explained in behavioral intention (56 percent to 74 percent) and technology use (40 percent to 52 percent). The theoretical and managerial implications of these results are discussed.',\n",
       "  'Online and offline cooperation under buy-online, pick-up-in-store: Pricing and inventory decisions. This study considered the problem of pricing and inventory decision-making where an online retailer and an offline retailer cooperate in a setting where buy-online, pick-up-in-store (BOPS) is implemented. Given the extra revenue generated from additional sales by BOPS customers who purchase additional products at the offline outlet, we considered revenue sharing, service subsidy, and inventory subsidy contracts among the coordinating supply chain partners. Optimization models under centralized and decentralized decision-making structures were established, and the solution was found for the equilibrium states of these optimization models. The results from numerical experiments were examined. We found that (1) the optimal stocking factor had different variation trends with the increase in additional sales under a centralized structure and under the three contracts in decentralized scenarios; (2) the revenue sharing contract was the most effective among the three contracts for coordinating online and offline retailers, and it was optimal for both retailers if the additional sales parameter was relatively low and offline cost share was small; and (3) an inventory subsidy contract had strong operability and steadiness under different product characteristics.'],\n",
       " ['AXIN2 itself is a major target gene of WNT signalling.It acts in a negative feedback loop to limit and finetune the canonical WNT-signaling .The human AXIN2 gene is located on chromosome 17q24.1 and encompasses 10 coding exons that generate a protein of 843 amino acids (Fig.',\n",
       "  'Negative Feedback Loop of Wnt Signaling through Upregulation of Conductin/Axin2 in Colorectal and Liver Tumors. ',\n",
       "  'The mutational constraint spectrum quantified from variation in 141,456 humans. Genetic variants that inactivate protein-coding genes are a powerful source of information about the phenotypic consequences of gene disruption: genes that are crucial for the function of an organism will be depleted of such variants in natural populations, whereas non-essential genes will tolerate their accumulation. However, predicted loss-of-function variants are enriched for annotation errors, and tend to be found at extremely low frequencies, so their analysis requires careful variant annotation and very large sample sizes1. Here we describe the aggregation of 125,748 exomes and 15,708 genomes from human sequencing studies into the Genome Aggregation Database (gnomAD). We identify 443,769 high-confidence predicted loss-of-function variants in this cohort after filtering for artefacts caused by sequencing and annotation errors. Using an improved model of human mutation rates, we classify human protein-coding genes along a spectrum that represents tolerance to inactivation, validate this classification using data from model organisms and engineered human cells, and show that it can be used to improve the power of gene discovery for both common and rare diseases. A catalogue of predicted loss-of-function variants in 125,748 whole-exome and 15,708 whole-genome sequencing datasets from the Genome Aggregation Database (gnomAD) reveals the spectrum of mutational constraints that affect these human protein-coding genes.'],\n",
       " ['The set of people detected in the scene is then tracked over the space and time by the algorithm of .',\n",
       "  'A multi-feature tracking algorithm enabling adaptation to context variations. We propose in this paper a tracking algorithm which is able to adapt itself to different scene contexts. A feature pool is used to compute the matching score between two detected objects. This feature pool includes 2D, 3D displacement distances, 2D sizes, color histogram, histogram of oriented gradient (HOG), color covariance and dominant color. An offline learning process is proposed to search for useful features and to estimate their weights for each context. In the online tracking process, a temporal window is defined to establish the links between the detected objects. This enables to find the object trajectories even if the objects are misdetected in some frames. A trajectory filter is proposed to remove noisy trajectories. Experimentation on different contexts is shown. The proposed tracker has been tested in videos belonging to three public datasets and to the Caretaker European project. The experimental results prove the effect of the proposed feature weight learning, and the robustness of the proposed tracker compared to some methods in the state of the art. The contributions of our approach over the state of the art trackers are: (i) a robust tracking algorithm based on a feature pool, (ii) a supervised learning scheme to learn feature weights for each context, (iii) a new method to quantify the reliability of HOG descriptor, (iv) a combination of color covariance and dominant color features with spatial pyramid distance to manage the case of object occlusion.',\n",
       "  'Comparing naive Bayes, decision trees, and SVM with AUC and accuracy.'],\n",
       " ['Hierarchical linear modelling of FOREA was performed in order to reveal the neural signatures of expertise-driven configural and visual processing load effects while controlling for eye-tracking variables that could also contribute to the variance of brain activity at single-trial level.',\n",
       "  'LIMO EEG: A Toolbox for Hierarchical LInear MOdeling of ElectroEncephaloGraphic Data. Magnetic- and electric-evoked brain responses have traditionally been analyzed by comparing the peaks or mean amplitudes of signals from selected channels and averaged across trials. More recently, tools have been developed to investigate single trial response variability (e.g., EEGLAB) and to test differences between averaged evoked responses over the entire scalp and time dimensions (e.g., SPM, Fieldtrip). LIMO EEG is a Matlab toolbox (EEGLAB compatible) to analyse evoked responses over all space and time dimensions, while accounting for single trial variability using a simple hierarchical linear modelling of the data. In addition, LIMO EEG provides robust parametric tests, therefore providing a new and complementary tool in the analysis of neural evoked responses.',\n",
       "  'Expertise Training with Novel Objects Leads to Left-Lateralized Facelike Electrophysiological Responses.'],\n",
       " ['In order to increase the sensitivity of statistical analyses, β coefficient maps were pre-processed with threshold-free cluster enhancement (TFCE) .',\n",
       "  'Advanced EEG analysis using threshold-free cluster-enhancement and non-parametric statistics. ',\n",
       "  'Naming Fluency in Dyslexic and Nondyslexic Readers: Differential Effects of Visual Crowding in Foveal, Parafoveal, and Peripheral Vision.'],\n",
       " ['In recent years, a powerful set of tools has emerged that allow for practical physical modeling to be carried out with a formalism that is a precise, non-commutative generalization of classical stochastic calculus .',\n",
       "  'An Introduction to Quantum Filtering. This paper provides an introduction to quantum filtering theory. An introduction to quantum probability theory is given, focusing on the spectral theorem and the conditional expectation as a least squares estimate, and culminating in the construction of Wiener and Poisson processes on the Fock space. We describe the quantum Ito calculus and its use in the modeling of physical systems. We use both reference probability and innovations methods to obtain quantum filtering equations for system-probe models from quantum optics.',\n",
       "  'Abstraction and its Limits: Finding Space for Novel Explanation. Several modern accounts of explanation acknowledge the importance of abstraction and idealization for our explanatory practice. However, once we allow a role for abstraction, questions remain. I ask whether the relation between explanations at different theoretical levels should be thought of wholly in terms of abstraction, and argue that changes of the quantities in terms of which we describe a system can lead to novel explanations that are not merely abstractions of some more detailed picture. I use the example of phase transitions as described by statistical mechanics and thermodynamics to illustrate this, and to demonstrate some details of the relationship between abstraction, idealization, and novel explanation.'],\n",
       " ['The regular voxel grid also provides an ideal basis for deep convolutional neural networks (CNNs), as has been recently demonstrated by , who converted 3D point clouds to a voxel-based representation before applying a CNN to detect pedestrians, cars, and cyclists in data captured from a moving vehicle.',\n",
       "  \"VoxelNet: End-to-End Learning for Point Cloud Based 3D Object Detection. Accurate detection of objects in 3D point clouds is a central problem in many applications, such as autonomous navigation, housekeeping robots, and augmented/virtual reality. To interface a highly sparse LiDAR point cloud with a region proposal network (RPN), most existing efforts have focused on hand-crafted feature representations, for example, a bird's eye view projection. In this work, we remove the need of manual feature engineering for 3D point clouds and propose VoxelNet, a generic 3D detection network that unifies feature extraction and bounding box prediction into a single stage, end-to-end trainable deep network. Specifically, VoxelNet divides a point cloud into equally spaced 3D voxels and transforms a group of points within each voxel into a unified feature representation through the newly introduced voxel feature encoding (VFE) layer. In this way, the point cloud is encoded as a descriptive volumetric representation, which is then connected to a RPN to generate detections. Experiments on the KITTI car detection benchmark show that VoxelNet outperforms the state-of-the-art LiDAR based 3D detection methods by a large margin. Furthermore, our network learns an effective discriminative representation of objects with various geometries, leading to encouraging results in 3D detection of pedestrians and cyclists, based on only LiDAR.\",\n",
       "  'Photorealistic rendering of mixed reality scenes.'],\n",
       " ['Visual Occlusion, Interaction, and Collisions While traditionally occlusion handling in virtual reality, and particularly mixed reality , is a challenging research topic, a voxel-based mixed reality approach solves this inherently.',\n",
       "  'Visual Coherence in Mixed Reality: A Systematic Enquiry. ',\n",
       "  'The Independent and Interactive Effects of Embodied-Agent Appearance and Behavior on Self-Report, Cognitive, and Behavioral Markers of Copresence in Immersive Virtual Environments.'],\n",
       " ['Depth cameras have become an invaluable source of such reconstructions, and while the raw data from a RGB-D camera is typically a point cloud, voxels are used as intermediate representations in systems such as KinectFusion .',\n",
       "  'KinectFusion: Real-time dense surface mapping and tracking. ',\n",
       "  'The Independent and Interactive Effects of Embodied-Agent Appearance and Behavior on Self-Report, Cognitive, and Behavioral Markers of Copresence in Immersive Virtual Environments.'],\n",
       " ['While their method is limited in the number of labels it can assign, this can be extended somewhat trough a block-based subdivision of the voxel space .',\n",
       "  'Multi-Label Semantic 3D Reconstruction Using Voxel Blocks. ',\n",
       "  'Dense Semantic 3D Reconstruction.'],\n",
       " ['For video see-through AR it is often desirable to model the noise characteristics of the physical camera when rendering objects .',\n",
       "  'Simulating Low-Cost Cameras for Augmented Reality Compositing. ',\n",
       "  'Fast, Memory-Efficient Construction of Voxelized Shadows.'],\n",
       " ['3.17 ED @ λ = 390nm 3 (Al) 1 (Ag) 0 (none) 18.67 26.',\n",
       "  'Nanophotonic particle simulation and inverse design using artificial neural networks. New deep learning techniques may hold the key to solving intractable photonics problems. We propose a method to use artificial neural networks to approximate light scattering by multilayer nanoparticles. We find that the network needs to be trained on only a small sampling of the data to approximate the simulation to high precision. Once the neural network is trained, it can simulate such optical processes orders of magnitude faster than conventional simulations. Furthermore, the trained neural network can be used to solve nanophotonic inverse design problems by using back propagation, where the gradient is analytical, not numerical.',\n",
       "  'Torque and force on a magnetic dipole. Recent controversies about torque and force on a magnetic dipole are discussed. Three essentially different current loop models are analyzed. Although all models yield the same expression for the torque, N=m×B, the detailed mechanisms that give rise to the torque in each case are very different. The expression for the force on a magnetic dipole is derived and analyzed for all models. The force expression is the same for all current loop models but it differs from the force on a magnetic charge dipole. The expression, obtained for the force on a current loop magnetic dipole, FCL=■(m⋅B)−(d/dt)(m×E/c), differs from what usually appears in the educational literature. The standard ‘‘naive’’ calculation of the force yields the correct expression for the rate of change of the total momentum, dP/dt=∇(m⋅B). However, the current loop in an externa l electric field has an internal ‘‘hidden momentum’’ m×E/c, which is not related to the motion of the center of mass of the dipole. Thus, for the force, defined as mass t...'],\n",
       " ['Another mobility test, stair-walking, is also a crucial functional motor evaluation for children and adolescents with ID .',\n",
       "  'Gait Event Detection during Stair Walking Using a Rate Gyroscope. Gyroscopes have been proposed as sensors for ambulatory gait analysis and functional electrical stimulation systems. These applications often require detection of the initial contact (IC) of the foot with the floor and/or final contact or foot off (FO) from the floor during outdoor walking. Previous investigations have reported the use of a single gyroscope placed on the shank for detection of IC and FO on level ground and incline walking. This paper describes the evaluation of a gyroscope placed on the shank for determination of IC and FO in subjects ascending and descending a set of stairs. Performance was compared with a reference pressure measurement system. The absolute mean difference between the gyroscope and the reference was less than 45 ms for IC and better than 135 ms for FO for both activities. Detection success was over 93%. These results provide preliminary evidence supporting the use of a gyroscope for gait event detection when walking up and down stairs.',\n",
       "  'A complementary filter for attitude estimation of a fixed-wing UAV.'],\n",
       " ['Identification of Orthologous NBS genes in C. clementina and C. sinensis Orthologous NBS genes of C. clementina and C. sinensis were identified using the reciprocal best blast method .We used NBS genes of C. clementina as query sequences to search against the NBS genes of C. sinensis and vice versa.Protein pairs with reciprocal best hits of evalue < 1E-20 were defined as orthologs.',\n",
       "  'Choosing BLAST options for better detection of orthologs as reciprocal best hits. MOTIVATION The analyses of the increasing number of genome sequences requires shortcuts for the detection of orthologs, such as Reciprocal Best Hits (RBH), where orthologs are assumed if two genes each in a different genome find each other as the best hit in the other genome. Two BLAST options seem to affect alignment scores the most, and thus the choice of a best hit: the filtering of low information sequence segments and the algorithm used to produce the final alignment. Thus, we decided to test whether such options would help better detect orthologs.   RESULTS Using Escherichia coli K12 as an example, we compared the number and quality of orthologs detected as RBH. We tested four different conditions derived from two options: filtering of low-information segments, hard (default) versus soft; and alignment algorithm, default (based on matching words) versus Smith-Waterman. All options resulted in significant differences in the number of orthologs detected, with the highest numbers obtained with the combination of soft filtering with Smith-Waterman alignments. We compared these results with those of Reciprocal Shortest Distances (RSD), supposed to be superior to RBH because it uses an evolutionary measure of distance, rather than BLAST statistics, to rank homologs and thus detect orthologs. RSD barely increased the number of orthologs detected over those found with RBH. Error estimates, based on analyses of conservation of gene order, found small differences in the quality of orthologs detected using RBH. However, RSD showed the highest error rates. Thus, RSD have no advantages over RBH.   AVAILABILITY Orthologs detected as Reciprocal Best Hits using soft masking and Smith-Waterman alignments can be downloaded from http://popolvuh.wlu.ca/Orthologs.',\n",
       "  'Phylogenetic and evolutionary analysis of NBS-encoding genes in Rutaceae fruit crops.'],\n",
       " ['Three Groups of Citrus NBS Genes We identified 442, 393 and 264 genes with full length NBS domains from C. clementina, C. sinensis China and C. sinensis USA reference genomes, respectively.There are also many genes with short NBS domains in three Citrus genomes.The Citrus NBS genes can be divided into three groups according to the phylogenetic tree of NBS domains: two of them without TIR domain (CC1 and CC2 groups) and the other group with TIR domain (TIR group).The number of non-TIR NBS genes is three times of the number of TIR NBS genes.In most of the TIR NBS genes, we can find the LRR domains defined in Pfam database .We only can identify LRR domains in small part of non-TIR NBS genes using Pfam LRR domain definition.However, we can find the LxxLs repeats in most of the non-TIR NBS genes as shown in motifs from MEME.This implied that there may be other types of LRR domain in Citrus non-TIR NBS genes.',\n",
       "  'The Pfam protein families database. Pfam is a widely used database of protein families and domains. This article describes a set of major updates that we have implemented in the latest release (version 24.0). The most important change is that we now use HMMER3, the latest version of the popular profile hidden Markov model package. This software is ∼100 times faster than HMMER2 and is more sensitive due to the routine use of the forward algorithm. The move to HMMER3 has necessitated numerous changes to Pfam that are described in detail. Pfam release 24.0 contains 11 912 families, of which a large number have been significantly updated during the past two years. Pfam is available via servers in the UK (http://pfam.sanger.ac.uk/), the USA (http://pfam.janelia.org/) and Sweden (http://pfam.sbc.su.se/).',\n",
       "  \"Sequencing of diverse mandarin, pummelo and orange genomes reveals complex history of admixture during citrus domestication. Cultivated citrus are selections from, or hybrids of, wild progenitor species whose identities and contributions to citrus domestication remain controversial. Here we sequence and compare citrus genomes—a high-quality reference haploid clementine genome and mandarin, pummelo, sweet-orange and sour-orange genomes—and show that cultivated types derive from two progenitor species. Although cultivated pummelos represent selections from one progenitor species, Citrus maxima, cultivated mandarins are introgressions of C. maxima into the ancestral mandarin species Citrus reticulata. The most widely cultivated citrus, sweet orange, is the offspring of previously admixed individuals, but sour orange is an F1 hybrid of pure C. maxima and C. reticulata parents, thus implying that wild mandarins were part of the early breeding germplasm. A Chinese wild 'mandarin' diverges substantially from C. reticulata, thus suggesting the possibility of other unrecognized wild citrus species. Understanding citrus phylogeny through genome analysis clarifies taxonomic relationships and facilitates sequence-directed genetic improvement.\"],\n",
       " ['Table 4 compares the MSSIM of the proposed system with one of the most recent compression-encryption systems at 25% CR.',\n",
       "  'An Image Compression and Encryption Algorithm Based on the Fractional-Order Simplest Chaotic Circuit. Based on compressive sensing and fractional-order simplest memristive chaotic system, this paper proposes an image compression and encryption scheme. First, a fractional-order simplest memristive chaotic circuit system is designed. The dynamic characteristics of the chaotic system are analyzed by the phase diagram, the Lyapunov exponent’s spectrum, and the bifurcation diagram to determine the parameters and pseudo-random sequences used in the encryption scheme. Secondly, an encryption scheme based on compressive sensing is designed. This scheme compresses the image twice to fully reduce the storage cost, and scrambles the pixel matrix twice through block scrambling and zigzag transformation, and then uses chaotic pseudo-random sequence and GF (17) domain diffusion image matrix to obtain the final cipher image. Finally, simulation results and performances analysis indicate that the scheme still has good reconstruction performance, even when the compression ratio is 0.25, and the security analysis shows that it can resist various attacks and has high security.',\n",
       "  'Chaotic oscillator configuration using a frequency dependent negative resistor.'],\n",
       " ['To emphasize this point, consider one of the most powerful FPGAs, the Xilinx Virtex 7 XC7V2000T, which includes only 46512kb Block Random Access-Memory (BRAM) .',\n",
       "  'DeepX: Deep Learning Accelerator for Restricted Boltzmann Machine Artificial Neural Networks. ',\n",
       "  'An image compression and encryption algorithm based on chaotic system and compressive sensing.'],\n",
       " ['Moreover, the fractional wavelet packet transform can be used with signals that contain high fractional frequency components, but its computational cost is also higher than the DWT .',\n",
       "  'Novel Fractional Wavelet Packet Transform: Theory, Implementation, and Applications. The fractional wavelet transform (FRWT), which generalizes the classical wavelet transform and the well-known fractional Fourier transform, has recently been demonstrated as a powerful analytical tool for signal and image processing. However, this transform suffers from a relatively poor resolution in the high fractional frequency region, which results in difficulties in discriminating signals containing close high fractional frequency components. A simple but effective method to overcome this deficiency is the fractional wavelet packet transform (FRWPT). There exist several different definitions of the FRWPT in the literature. Unfortunately, these existing definitions do not generalize well the classical results for the conventional wavelet packet transform. The objective of this paper is to obtain a novel FRWPT that preserves the properties of its conventional counterpart. We first define the novel FRWPT and then discuss its related properties. Fractional wavelet packet subspaces are also constructed. Moreover, a recursive algorithm for implementing the proposed FRWPT is presented. Finally, we discuss potential applications of the proposed FRWPT.',\n",
       "  'Hybrid No-Reference Natural Image Quality Assessment of Noisy, Blurry, JPEG2000, and JPEG Images.'],\n",
       " ['The MSSIM can be calculated using the equations presented in .',\n",
       "  'An Image Compression and Encryption Algorithm Based on the Fractional-Order Simplest Chaotic Circuit. Based on compressive sensing and fractional-order simplest memristive chaotic system, this paper proposes an image compression and encryption scheme. First, a fractional-order simplest memristive chaotic circuit system is designed. The dynamic characteristics of the chaotic system are analyzed by the phase diagram, the Lyapunov exponent’s spectrum, and the bifurcation diagram to determine the parameters and pseudo-random sequences used in the encryption scheme. Secondly, an encryption scheme based on compressive sensing is designed. This scheme compresses the image twice to fully reduce the storage cost, and scrambles the pixel matrix twice through block scrambling and zigzag transformation, and then uses chaotic pseudo-random sequence and GF (17) domain diffusion image matrix to obtain the final cipher image. Finally, simulation results and performances analysis indicate that the scheme still has good reconstruction performance, even when the compression ratio is 0.25, and the security analysis shows that it can resist various attacks and has high security.',\n",
       "  'Haar-Wavelet-Based Just Noticeable Distortion Model for Transparent Watermark. Watermark transparency is required mainly for copyright protection. Based on the characteristics of human visual system, the just noticeable distortion (JND) can be used to verify the transparency requirement. More specifically, any watermarks whose intensities are less than the JND values of an image can be added without degrading the visual quality. It takes extensive experimentations for an appropriate JND model. Motivated by the texture masking effect and the spatial masking effect, which are key factors of JND, Chou and Li (1995) proposed the well-known full-band JND model for the transparent watermark applications. In this paper, we propose a novel JND model based on discrete wavelet transform. Experimental results show that the performance of the proposed JND model is comparable to that of the full-band JND model. However, it has the advantage of saving a lot of computation time; the speed is about 6 times faster than that of the full-band JND model.'],\n",
       " ['If Mode sel is set high, the counters will operate normally from 0 10 to 63 .',\n",
       "  'Chaotic oscillator configuration using a frequency dependent negative resistor. ',\n",
       "  \"Construction of classes of circuit-independent chaotic oscillators using passive-only nonlinear devices. Two generic classes of chaotic oscillators comprising four different configurations are constructed. The proposed structures are based on the simplest possible abstract models of generic second-order RC sinusoidal oscillators that satisfy the basic condition for oscillation and the frequency of oscillation formulas. By linking these sinusoidal oscillator engines to simple passive first-order or second-order nonlinear composites, chaos is generated and the evolution of the two-dimensional sinusoidal oscillator dynamics into a higher dimensional state space is clearly recognized. We further discuss three architectures into which autonomous chaotic oscillators can be decomposed. Based on one of these architectures we classify a large number of the available chaotic oscillators and propose a novel reconstruction of the classical Chua's circuit. The well-known Lorenz system of equations is also studied and a simplified model with equivalent dynamics, but containing no multipliers, is introduced.\"],\n",
       " ['A NodeColumns FunctionSpace is available to describe for every node of a horizontal mesh a contiguous-in-memory structured vertical column.A Spectral FunctionSpace describes a field with spectral coefficients.Additional Func-tionSpace types can be created to describe discretisation for continuous or discontinuous spectral element methods (e.g.',\n",
       "  'A Review of Element-Based Galerkin Methods for Numerical Weather Prediction: Finite Elements, Spectral Elements, and Discontinuous Galerkin. ',\n",
       "  'Parallelization and Performance of the NIM Weather Model on CPU, GPU, and MIC Processors. AbstractThe design and performance of the Non-Hydrostatic Icosahedral Model (NIM) global weather prediction model is described. NIM is a dynamical core designed to run on central processing unit (CPU), graphics processing unit (GPU), and Many Integrated Core (MIC) processors. It demonstrates efficient parallel performance and scalability to tens of thousands of compute nodes and has been an effective way to make comparisons between traditional CPU and emerging fine-grain processors. The design of the NIM also serves as a useful guide in the fine-grain parallelization of the finite volume cubed (FV3) model recently chosen by the National Weather Service (NWS) to become its next operational global weather prediction model.This paper describes the code structure and parallelization of NIM using standards-compliant open multiprocessing (OpenMP) and open accelerator (OpenACC) directives. NIM uses the directives to support a single, performance-portable code that runs on CPU, GPU, and MIC systems. Performance r...'],\n",
       " ['In most codes now we see one of two strategies: either MPI is still used across both nodes and node-local cores, or MPI is used in conjunction with OpenMP .In the latter case OpenMP is used to run some parallel threads on a core (\"hyper threading\") or parallel threads on a socket, but the threads are sharing memory, and directives are used to identify where this can occur.However, this strategy of mixing explicit library calls (MPI) and compiler directives (OpenMP) does not always work better than MPI alone, not least because vendor implementations of MPI can implement on-node \"messages\" with highly optimised libraries exploiting shared memory with performance that can be hard to beat.Conversely, MPI decomposition cannot be changed without paying a synchronisation and data movement penalty, whereas OpenMP can exploit the dynamic scheduling of work and better handle load balancing around (for example) physics parameterisations such as precipitation.Hence, the modeller following a hybrid approach has many issues to consider: how many parallel threads per node (between zero and the number of hyper-threads supportable on the node) and what parts of the code can take advantage of this technique?There is a balance to be struck which depends on knowledge of the code, the hardware, and the quality of the vendor-supplied compilers and libraries, and this balance needs to be re-evaluated for each architecture and model version.',\n",
       "  'OpenMP: an industry standard API for shared-memory programming. At its most elemental level, OpenMP is a set of compiler directives and callable runtime library routines that extend Fortran (and separately, C and C++ to express shared memory parallelism. It leaves the base language unspecified, and vendors can implement OpenMP in any Fortran compiler. Naturally, to support pointers and allocatables, Fortran 90 and Fortran 95 require the OpenMP implementation to include additional semantics over Fortran 77. OpenMP leverages many of the X3H5 concepts while extending them to support coarse grain parallelism. The standard also includes a callable runtime library with accompanying environment variables.',\n",
       "  'A Review of Element-Based Galerkin Methods for Numerical Weather Prediction: Finite Elements, Spectral Elements, and Discontinuous Galerkin.'],\n",
       " ['The interconnection between all the large-scale components requires a specialised framework and/or coupler to provide methods for exchanging fields between components.',\n",
       "  'Coupling technologies for Earth System Modelling. Abstract. This paper presents a review of the software currently used in climate modelling in general and in CMIP5 in particular to couple the numerical codes representing the different components of the Earth System. The coupling technologies presented show common features, such as the ability to communicate and regrid data, and also offer different functions and implementations. Design characteristics of the different approaches are discussed as well as future challenges arising from the increasing complexity of scientific problems and computing platforms.',\n",
       "  'Simulating Whole Supercomputer Applications.'],\n",
       " ['I/O parallelism (using an I/O server such as XML I/O Server, XIOS, or a parallel I/O library such as parallel NetCDF; .',\n",
       "  'Parallel netCDF: A High-Performance Scientific I/O Interface. ',\n",
       "  'A finite-volume module for simulating global all-scale atmospheric flows.'],\n",
       " ['Requirements Existing models are known to have high levels of software quality , and maintaining quality models in the face of increasing scientific demands on what is simulated, ensemble size, and resolution will be crucial.It is these that define scientific quality -a model could be very high performance and portable, but not be suitable for the scientific objectives, and there is a spectrum between \"not suitable\" and \"ideal\".In fact, some level of model quality is often compromised for performance; for example, resolution and complexity are routinely sacrificed to fit weather forecasts in a particular time window or to reach a requisite number of simulated years per day for climate.',\n",
       "  'Assessing climate model software quality: a defect density analysis of three models. Abstract. A climate model is an executable theory of the climate; the model encapsulates climatological theories in software so that they can be simulated and their implications investigated. Thus, in order to trust a climate model, one must trust that the software it is built from is built correctly. Our study explores the nature of software quality in the context of climate modelling. We performed an analysis of defect reports and defect fixes in several versions of leading global climate models by collecting defect data from bug tracking systems and version control repository comments. We found that the climate models all have very low defect densities compared to well-known, similarly sized open-source projects. We discuss the implications of our findings for the assessment of climate model software trustworthiness.',\n",
       "  'Parallelization and Performance of the NIM Weather Model on CPU, GPU, and MIC Processors. AbstractThe design and performance of the Non-Hydrostatic Icosahedral Model (NIM) global weather prediction model is described. NIM is a dynamical core designed to run on central processing unit (CPU), graphics processing unit (GPU), and Many Integrated Core (MIC) processors. It demonstrates efficient parallel performance and scalability to tens of thousands of compute nodes and has been an effective way to make comparisons between traditional CPU and emerging fine-grain processors. The design of the NIM also serves as a useful guide in the fine-grain parallelization of the finite volume cubed (FV3) model recently chosen by the National Weather Service (NWS) to become its next operational global weather prediction model.This paper describes the code structure and parallelization of NIM using standards-compliant open multiprocessing (OpenMP) and open accelerator (OpenACC) directives. NIM uses the directives to support a single, performance-portable code that runs on CPU, GPU, and MIC systems. Performance r...'],\n",
       " ['In Pang et al , an anonymous identifier was used to ensure sender anonymity.',\n",
       "  'Anonymous Certificateless Multi-Receiver Signcryption Scheme Without Secure Channel. The certificateless multi-receiver signcryption scheme provides the sender with the ability to send the same message to multiple authorized receivers contemporaneously, and at the same time, it can avoid the key escrow problem in the existing identity-based multi-receiver signcryption schemes, which makes it to get great attention in the field of one-to-many communication. However, in the existing certificateless multi-receiver signcryption schemes, a secure channel is essential for their key extract algorithm, which brings some troubles in practical applications. On one hand, the security of the partial private key depends on the secure channel. Once the secure channel is broken by an attacker, the user’s partial private key may be leaked. On the other hand, maintaining the secure channel increases the economic cost and implementation complexity of the application systems. Motivated by these concerns, we propose a new anonymous certificateless multi-receiver signcryption scheme, in which the key generation center only utilizes a public channel to send the pseudo partial private key to the user during the key extract algorithm, and the designated user can work out the real partial private key from the pseudo partial private key while others cannot. The avoidance of the secure channel improves the security of the proposed scheme and makes the communication system much lighter.',\n",
       "  'A Cyberphysical System Based Mass-Customization Approach with Integration of Industry 4.0 and Smart City. Smart city is a city which is designed to meet the people’s demands. In addition to use of sources efficiently, trends of people are also a need that smart city should meet. Buying personalized products in a cheap and fast way is a demand of people of today. Mass customization, which is defined as the personalization of products, achieves making the tailor-made products cheaper. In this study, we propose a new approach for mass customization with the integration of smart retail and smart production. With removing the operators and actualizing the progress autonomously, it is aimed to reduce the waiting time of customers. Because less waiting time means that there are more mass-customization customers, and this is expected to increase the popularity of mass customization. Thus, reducing wastes and increasing productivity are aimed. This study also constitutes the infrastructure that enables a production system to autonomously perform all stages from order to delivery. With the given scenarios, challenges and advantages of desired approach are discussed.'],\n",
       " ['However, in some environments, it is necessary to ensure public verifiability because if signcryption messages are forwarded at some stage, it is essential to be able to check the validity of messages transmitted by the intermediate object to improve service reliability .',\n",
       "  'Identity Based Public Verifiable Signcryption Scheme. ',\n",
       "  'Efficient Anonymous Certificateless Multi-Receiver Signcryption Scheme Without Bilinear Pairings. Certificateless multi-receiver encryption/signcryption (CLME/CLMS) has become a research hotspot in the field of information security. Almost all of the existing CLME/CLMS schemes are constructed based on the bilinear pairing computation, a time-consuming operation, which makes their computational efficiency relatively low. Although there are some CLME schemes constructed on scalar point multiplications on elliptic curve cryptography (ECC) instead of the bilinear pairing computation, too many scalar point multiplications involved still lead to the low computational efficiency. Therefore, there is still room for the CLME/CLMS schemes in efficiency. Motivated by these concerns, an efficient anonymous certificateless multi-receiver signcryption scheme is proposed with its security proved under the random oracle model. The proposed scheme is improved largely in computational efficiency by the idea that it is designed based on scalar point multiplications on ECC instead of the bilinear pairing and the number of scalar point multiplications on ECC is reduced as small as possible.'],\n",
       " ['Thus, CL-MRSC schemes allowing for multiple receivers of a single message have been proposed by Selvi et al and others, who focused on various security requirements [27]- Fig.',\n",
       "  'Efficient and Provably Secure Certificateless Multi-receiver Signcryption. ',\n",
       "  'Iot-based smart cities: A survey.'],\n",
       " ['A recent study suggested that intermediate objects or third parties should be able to check the validity of transmitted messages, to improve the reliability of services in environments where data are received and then forwarded - .',\n",
       "  'Identity Based Public Verifiable Signcryption Scheme. ',\n",
       "  'Generic Construction of Certificateless Signature.'],\n",
       " ['Specifically, the transformed features with relatively low dimensionality of an input sample is calculated based on the distance between itself and all the other samples using .',\n",
       "  'Cyber-Physical Systems Security—A Survey. With the exponential growth of cyber-physical systems (CPSs), new security challenges have emerged. Various vulnerabilities, threats, attacks, and controls have been introduced for the new generation of CPS. However, there lacks a systematic review of the CPS security literature. In particular, the heterogeneity of CPS components and the diversity of CPS systems have made it difficult to study the problem with one generalized model. In this paper, we study and systematize existing research on CPS security under a unified framework. The framework consists of three orthogonal coordinates: 1) from the security perspective, we follow the well-known taxonomy of threats, vulnerabilities, attacks and controls; 2) from the CPS components perspective, we focus on cyber, physical, and cyber-physical components; and 3) from the CPS systems perspective, we explore general CPS features as well as representative systems (e.g., smart grids, medical CPS, and smart cars). The model can be both abstract to show general interactions of components in a CPS application, and specific to capture any details when needed. By doing so, we aim to build a model that is abstract enough to be applicable to various heterogeneous CPS applications; and to gain a modular view of the tightly coupled CPS components. Such abstract decoupling makes it possible to gain a systematic understanding of CPS security, and to highlight the potential sources of attacks and ways of protection. With this intensive literature review, we attempt to summarize the state-of-the-art on CPS security, provide researchers with a comprehensive list of references, and also encourage the audience to further explore this emerging field.',\n",
       "  'Survey of Security and Privacy Issues of Internet of Things. This paper is a general survey of all the security issues existing in the Internet of Things (IoT) along with an analysis of the privacy issues that an end-user may face as a consequence of the spread of IoT. The majority of the survey is focused on the security loopholes arising out of the information exchange technologies used in Internet of Things. No countermeasure to the security drawbacks has been analyzed in the paper.'],\n",
       " ['The losses generated during relative-feature representation, CNN encoding, and prediction process, are calculated using the designed cost function as addressed by (5), (7), and .',\n",
       "  'Resilient Model Predictive Control of Cyber–Physical Systems Under DoS Attacks. This article presents a resilient model predictive control (MPC) framework to attenuate adverse effects of denial-of-service (DoS) attacks for cyber–physical systems (CPSs), where the system dynamics is modeled by a linear time-invariant system. A DoS attacker targets at blocking the controller to actuator (C–A) communication channel by launching adversarial jamming signals. We show that, in order to guarantee exponential stability of the closed-loop system, several conditions for resilient MPC should be satisfied. And these established conditions are explicitly related to the duration of DoS attacks and MPC parameters such as the prediction horizon and the terminal constraint. Two key techniques, including the <inline-formula><tex-math notation=\"LaTeX\">$\\\\mu$</tex-math></inline-formula>-step positively invariant set and the modified initial feasible set are exploited for achieving exponential stability in the presence of DoS attacks. Moreover, the maximum allowable duration of the DoS attacker is also obtained by using the <inline-formula><tex-math notation=\"LaTeX\">$\\\\mu$</tex-math></inline-formula>-step positively invariant set. Finally, the effectiveness of the proposed MPC algorithm is verified by simulated studies and comparisons.',\n",
       "  'Cyber-Physical Vulnerability Analysis of Communication-Based Train Control. A cyber-physical system (CPS) is an entanglement of physical and computing systems by real-time information exchange through networking, which can be considered as real-time IoT because of end-to-end real-time performance guarantee. Most societal infrastructures, such as transportation systems, smart power grid, smart factory, and smart buildings, are key application domains of CPS. Though there have been extensive studies on infrastructures from the perspective of cyber security, insufficient research has been conducted from a practical viewpoint of cyber-physical security. In this paper, we focus on train control systems as one of the critical infrastructures. We fully investigate the emerging de facto standard of train control systems, communication-based train control (CBTC). We analyze the cyber-physical vulnerability of CBTC and discover that a man-in-the-middle attack combined with knowledge on train signaling can cause train collisions in CBTC. To resolve the issue, we propose a countermeasure for resiliency of CBTC. By implementing a realistic CBTC testbed, we validate our analysis. To the best of our knowledge, this is the first in-depth empirical study on cyber-physical vulnerability of CBTC systems.'],\n",
       " ['Shen et al presented a machine learning-based framework for resource management in wireless communications.',\n",
       "  'LORM: Learning to Optimize for Resource Management in Wireless Networks With Few Training Samples. Effective resource management plays a pivotal role in wireless networks, which, unfortunately, typically results in challenging mixed-integer nonlinear programming (MINLP) problems. Machine learning-based methods have recently emerged as a disruptive way to obtain near-optimal performance for MINLPs with affordable computational complexity. There have been some attempts in applying such methods to resource management in wireless networks, but these attempts require huge amounts of training samples and lack the capability to handle constrained problems. Furthermore, they suffer from severe performance deterioration when the network parameters change, which commonly happens and is referred to as the task mismatch problem. In this paper, to reduce the sample complexity and address the feasibility issue, we propose a framework of Learning to Optimize for Resource Management (LORM). In contrast to the end-to-end learning approach adopted in previous studies, LORM learns the optimal pruning policy in the branch-and-bound algorithm for MINLPs via a sample-efficient method, namely, imitation learning. To further address the task mismatch problem, we develop a transfer learning method via self-imitation in LORM, named LORM-TL, which can quickly adapt a pre-trained machine learning model to the new task with only a few additional unlabeled training samples. Numerical simulations demonstrate that LORM outperforms specialized state-of-the-art algorithms and achieves near-optimal performance, while providing significant speedup compared with the branch-and-bound algorithm. Moreover, LORM-TL, by relying on a few unlabeled samples, achieves comparable performance with the model trained from scratch with sufficient labeled samples.',\n",
       "  'Artificial Intelligence for Detection, Estimation, and Compensation of Malicious Attacks in Nonlinear Cyber-Physical Systems and Industrial IoT. This article proposes a hybrid intelligent-classic control approach for reconstruction and compensation of cyber attacks launched on inputs of nonlinear cyber-physical systems (CPS) and industrial Internet of Things systems, which work through shared communication networks. In this article, a class of n-order nonlinear systems is considered as a model of CPS while it is in presence of cyber attacks only in the forward channel. An intelligent-classic control system is developed to compensate cyber-attacks. Neural network (NN) is designed as an intelligent estimator for attack estimation and a classic nonlinear control system based on the variable structure control method is designed to compensate the effect of attacks and control the system performance in tracking applications. In the proposed strategy, nonlinear control theory is applied to guarantee the stability of the system when attacks happen. In this strategy, a Gaussian radial basis function NN is used for online estimation and reconstruction of cyber-attacks launched on the networked system. An adaptation law of the intelligent estimator is derived from a Lyapunov function. Simulation results demonstrate the validity and feasibility of the proposed strategy in car cruise control application as the testbed.'],\n",
       " ['Pearce et al introduced a framework to prevent different kinds of cyber-physical attacks based on the runtime enforcement, in which the bidirectional timed policies were specified in an industrial CPS application.',\n",
       "  'Smart I/O Modules for Mitigating Cyber-Physical Attacks on Industrial Control Systems. Cyber-physical systems (CPSs) are implemented in many industrial and embedded control applications. Where these systems are safety-critical, correct and safe behavior is of paramount importance. Malicious attacks on such CPSs can have far-reaching repercussions. For instance, if elements of a power grid behave erratically, physical damage and loss of life could occur. Currently, there is a trend toward increased complexity and connectivity of CPS. However, as this occurs, the potential attack vectors for these systems grow in number, increasing the risk that a given controller might become compromised. In this article, we examine how the dangers of compromised controllers can be mitigated. We propose a novel application of runtime enforcement that can secure the safety of real-world physical systems. Here, we synthesize enforcers to a new hardware architecture within programmable logic controller I/O modules to act as an effective line of defence between the cyber and the physical domains. Our enforcers prevent the physical damage that a compromised control system might be able to perform. To demonstrate the efficacy of our approach, we present several benchmarks, and show that the overhead for each system is extremely minimal.',\n",
       "  'Few-Shot Learning for Domain-Specific Fine-Grained Image Classification. Learning to recognize novel visual categories from a few examples is a challenging task for machines in real-world industrial applications. In contrast, humans have the ability to discriminate even similar objects with little supervision. This article attempts to address the few-shot fine-grained image classification problem. We propose a feature fusion model to explore discriminative features by focusing on key regions. The model utilizes the focus-area location mechanism to discover the perceptually similar regions among objects. High-order integration is employed to capture the interaction information among intraparts. We also design a center neighbor loss to form robust embedding space distributions. Furthermore, we build a typical fine-grained and few-shot learning dataset miniPPlankton from the real-world application in the area of marine ecological environments. Extensive experiments are carried out to validate the performance of our method. The results demonstrate that our model achieves competitive performance compared with state-of-the-art models. Our work is a valuable complement to the model domain-specific industrial applications.'],\n",
       " ['With the rapid development of Industry 4.0, signals and messages exchanging through networks based on industrial Internet of Things (IIoT) empower the functionality and efficiency of CPS in industrial environments , including real-time perception, dynamic control, and information service of large-scale engineering systems.',\n",
       "  'Robust Path Diversity for Network Quality of Service in Cyber-Physical Systems. ',\n",
       "  'A Gated Few-shot Learning Model For Anomaly Detection. Anomaly detection, as one of the most important problems in the domain of network and service management, has been widely studied in statistics and machine learning. The supervised methods with plenty of labeled data have achieved great success in anomaly detection, but cannot integrate new anomaly types. In this paper, we propose a few-shot learning model for anomaly detection. Our model is trained with labeled data, and is then tested in terms of its ability to learn how to detect new types, given examples of the unseen classes. Due to a gap between the known anomaly data and unseen anomaly data, we designed a gated network structure to tackle the imbalanced data problem, to which we added a gate structure to aggregate known anomaly types and unknown types. We evaluated our proposed method based on the anomaly dataset NSL-KDD and our experimental results show that the proposed method achieved the state-of-the-art results in few-shot settings.'],\n",
       " ['In recent years, network-based ITS has become a hot topic of scientific research, such as the ELM-ART system developed by Yang et al .',\n",
       "  'Construction of Distance Education Classroom in Architecture Specialty Based on Internet of Things Technology. Internet of Things technology and industrial development will trigger a new round of information technology revolution and industrial revolution, and they are the commanding point of future competition in information industry and core driving force of industrial upgrade. This paper introduces current situation of distance teaching of Internet of Things and architecture specialties, designs and implements distance teaching experiment system platform for architecture specialty based on Internet of Things. This system is based on ZigBee /GPRS wireless network technology, sensor technology, embedded technology, Web distributed software technology and database technology. Besides, it adopts three interlinked networks and achieves efficient connection of multiple experiment terminals, servers and clients. As well, the information exchange is fast. Hence, it is convenient for practical application of distance teaching. The results of teaching experiment show that Internet of Things technology can improve students’ academic performance and teachers’ teaching effect. Therefore, it is a hot spot in modern teaching technology, so we should pay attention to it.',\n",
       "  'Scale and scope economies of distance education in Australian universities.'],\n",
       " ['Learners can solve many problems through computer-based dialogue counseling .',\n",
       "  'Conceptual Design Model of Instructional Interfaces: Courseware for Inclusive Education System (IID4C) Distance Learning. This paper describes an ongoing study related to a conceptual design model, which is specific to instructional interface design to enhance courseware usage. It was found that most of the existing courseware applications focus on the needs of certain target with most of the courseware offer too little to inclusive learners. In addition, the use of structure, layout, and navigation to improve the courseware instructional interfaces as part of usability strategies was also problematic for developers. Thus, this study aims at creating an alternative instructional interface as part of usability strategies for inclusive education systems called Instructional Interface Design for Courseware IID4C. It is proposed as guidance for the developer to refer to. The study used comparative analysis technique to determine the elements of the model. In the end, this study finds that the IID4C model is useful for information accessibility and contributes to the designing of instructional courseware. Future works are to evaluate the proposed model among disabled and non-disabled learners.',\n",
       "  'Sedentary behavior and not physical activity predicts study progress in distance education.'],\n",
       " ['By , one obtainṡ ν = dN (φ n ) dφ nφ n ψ n + N (φ n )ψ n .',\n",
       "  'Adaptive tracking control for nonlinear time-varying delay systems with full state constraints and unknown control coefficients. ',\n",
       "  'Event-Based Adaptive Neural Tracking Control for Discrete-Time Stochastic Nonlinear Systems: A Triggering Threshold Compensation Strategy. This paper investigates the event-triggered (ET) tracking control problem for a class of discrete-time strict-feedback nonlinear systems subject to both stochastic noises and limited controller-to-actuator communication capacities. The ET mechanism with fixed triggering threshold is designed to decide whether the current control signal should be transmitted to the actuator. A systematic framework is developed to construct a novel adaptive neural controller by directly applying the backstepping procedure to the underlying system. The proposed framework overcomes the noncausality problem, avoids the possible controller-related singularity problem, and gets rid of the neural approximation of the virtual control laws. Under the ET mechanism, the corresponding ET-based actuator is put forward by introducing an ET threshold compensation operator. Such a compensation operator (with an adjustable design parameter) is subtly designed based on a hyperbolic tangent function and a sign function. The threshold compensation error is analytically characterized in terms of a time-varying parameter, and the error bound is shown to be relatively small that is dependent on the adjustable design parameter. Compared with the traditional ET-based actuator without the compensation operator, the proposed ET-based actuator exhibits several distinguished features including: 1) improvement of the tracking accuracy (especially at the triggering instants); 2) further mitigation of the communication load; and 3) enlargement of the allowable range of the ET threshold. These features are illustrated by numerical and practical examples.'],\n",
       " ['The authors in use a more efficient technique namely first-order sliding mode differentiator (FOSMD) to avert tedious calculations.',\n",
       "  'Adaptive Neural Output Feedback Control of Uncertain Nonlinear Systems With Unknown Hysteresis Using Disturbance Observer. ',\n",
       "  'Adaptive tracking control for nonlinear time-varying delay systems with full state constraints and unknown control coefficients.'],\n",
       " ['Then, it can be concluded from and Lemma 3-4 thaṫ α n−1 = ϱ n1 + ε n(40) where ε n satisfies |ε n | ≤ε n withε n being a positive constant.',\n",
       "  'Gaussian Networks for Direct Adaptive Control. ',\n",
       "  'Neural learning control of pure-feedback nonlinear systems.'],\n",
       " ['(38) Similar to Step i, the FOSMD is employed to acquirė α n−1 , which can avoid tedious computation: \\uf8f1 \\uf8f4 \\uf8f4 \\uf8f2 \\uf8f4 \\uf8f4 \\uf8f3θ n1 = ϱ n1 ϱ n1 = −ω n1 |ϑ n1 − α n−1 | 1 2 sign(ϑ n1 − α n−1 ) + ϑ n2 ϑ n2 = −ω n2 sign(ϑ n2 − ϱ n1 )(39) where ϑ n1 , ϑ n2 and ϱ n1 denote the states of FOSMD , ω n1 and ω n2 are both positive design parameters.',\n",
       "  'Gaussian Networks for Direct Adaptive Control. ',\n",
       "  'Observer-Based Fuzzy Adaptive Event-Triggered Control for Pure-Feedback Nonlinear Systems With Prescribed Performance. This paper studies the problem of fuzzy adaptive event-triggered control for a class of pure-feedback nonlinear systems, which contain unknown smooth functions and unmeasured states. Fuzzy logic systems are adopted to approximate unknown smooth functions and a fuzzy state observer is designed to estimate unmeasured states. Via the event-triggered control technique, the control signal of the fixed threshold strategy is obtained. By converting the tracking error into a new virtual error variable, an observer-based fuzzy adaptive event-triggered prescribed performance control strategy is designed. The key advantage is that the proposed method does not require a $priori$ knowledge of partial derivatives of system functions, i.e., it relaxes the restrictive condition that the partial derivatives of system functions need to be known for pure-feedback nonlinear systems. Simulation results confirm the efficiency of the proposed method.'],\n",
       " ['Besides the image size of 4 MPixels (2048×2048) used in , we also utilized the image sizes of 1 MPixel (1024×1024), 2 MPixels (2048×1024), and 8 MPixels (4096×2048).',\n",
       "  'An image compositing solution at scale. ',\n",
       "  'Multi-step image compositing for massively parallel rendering.'],\n",
       " ['The performance evaluation graph presented in shows that Binary-Swap and some versions of Radix-k time almost doubled from 512 to 65,536 composition nodes, and in the case of Radix-k with k value equal to 32 the time almost tripled.',\n",
       "  'An image compositing solution at scale. ',\n",
       "  'Compositing digital images.'],\n",
       " ['In this paper, we focused on the Multi-Step approach presented in and expanded the investigation including floating point pixel format for attending high-quality rendering requirements; a method for selecting the maximum group size to be used in each Step; and the Hybrid MPI-OpenMP image composition approach.',\n",
       "  'Multi-step image compositing for massively parallel rendering. ',\n",
       "  'SLIC: scheduled linear image compositing for parallel volume rendering.'],\n",
       " ['Some optimizations, including active-pixel encoding and compression, have also been evaluated for Radix-k .',\n",
       "  'Accelerating and Benchmarking Radix-k Image Compositing at Large Scale. Radix-k was introduced in 2009 as a configurable image compositing algorithm. The ability to tune it by selecting k-values allows it to benefit more from pixel reduction and compression optimizations than its predecessors. This paper describes such optimizations in Radix-k, analyzes their effects, and demonstrates improved performance and scalability. In addition to bounding and run-length encoding pixels, k-value selection and load balance are regulated at run-time. Performance is systematically analyzed for an array of process counts, image sizes, and HPC and graphics clusters. Analyses are performed using compositing of synthetic images and also in the context of a complete volume renderer and scientific data. We demonstrate increased performance over binary swap and show that 64 megapixels can be composited at rates of 0.08 seconds, or 12.5 frames per second, at 32 K processes.',\n",
       "  'Multi-step image compositing for massively parallel rendering.'],\n",
       " ['The advantages of these algorithms are that the coefficients of linearized systems are simply obtained by summation because of the orthogonality for a finite sum, and the running time for calculating the coefficients of the linearized systems can be markedly improved compared with the case of evaluating definite integrals for linearization in a previous work .',\n",
       "  'A Pseudo-Formal Linearization Using Chebyshev Expansion and Its Application to Nonlinear Observer for Nonlinear Scalar-Measurement Systems. This paper is concerned with a pseudo-formal linearization method using Chebyshev expansion and its application to a nonlinear observer for nonlinear scalar-measurement systems. The given nonlinear autonomous dynamic system is linearized into an augmented linear system with respect to a linearization function that consists of polynomials of state variables by a pseudo-formal linearization method using Chebyshev expansion. As an application of this method, a nonlinear observer is discussed. An augmented measurement vector that consists of polynomials of measurement data is introduced and is transformed into an augmented linear one by the pseudo-formal linearization technique using Chebyshev expansion. Thereby, a linear system theory is applied to both the linearized dynamic and measurement systems in order to design a new nonlinear observer. Numerical experiments indicate that the performance of the presented method is superior to that of the previous method.',\n",
       "  'Formal Linearization by Chebyshev Interpolation for Both State and Measurement Equations of Nonlinear Scalar-Measurement Systems and Its Application to Nonlinear Filter. In this paper, we consider a formal linearization for multi-output nonlinear systems based on Chebyshev interpolation. Defining a linearization function that consists of Chebyshev polynomials, a given nonlinear dynamic system is transformed into an augmented linear one with respect to this linearization function by Chebyshev interpolation. Introducing a new augmented measurement vector that consists of polynomials of measurement data for a given multidimensional measurement equation, a measurement equation is transformed into an augmented linear one with respect to the linearization function in the same way. A linear estimation theory is applied to these augmented linearized systems and a nonlinear filter is synthesized. In order to show the performance of the method, a tentative estimation problem of a pendulum system is solved, with the results compared with those for the extended Kalman filter as a conventional method.'],\n",
       " ['Table 1 shows running times for calculating the coefficients of the t [s] Figure 3 Integral square errors of estimation compared with those of previous method pseudo-formal linearization by using the proposed algorithm and those in the previous work and the difference between them.',\n",
       "  'A Pseudo-Formal Linearization Using Chebyshev Expansion and Its Application to Nonlinear Observer for Nonlinear Scalar-Measurement Systems. This paper is concerned with a pseudo-formal linearization method using Chebyshev expansion and its application to a nonlinear observer for nonlinear scalar-measurement systems. The given nonlinear autonomous dynamic system is linearized into an augmented linear system with respect to a linearization function that consists of polynomials of state variables by a pseudo-formal linearization method using Chebyshev expansion. As an application of this method, a nonlinear observer is discussed. An augmented measurement vector that consists of polynomials of measurement data is introduced and is transformed into an augmented linear one by the pseudo-formal linearization technique using Chebyshev expansion. Thereby, a linear system theory is applied to both the linearized dynamic and measurement systems in order to design a new nonlinear observer. Numerical experiments indicate that the performance of the presented method is superior to that of the previous method.',\n",
       "  'Feedback control of nonlinear systems by extended linearization. For single-input, multiple-output, nonlinear systems, we consider a design method based on the family of linearizations of the system, parameterized by constant operating points. Nonlinear state feedback control laws and observer/state feedback control laws are designed such that the eigenvalues of the family of linearized closed-loop systems are placed at specified values that are locally invariant with respect to the closed-loop operating point. The method is illustrated by application to the problem of automatically balancing an inverted pendulum.'],\n",
       " ['4 and 5 show that the performance of the nonlinear observer is almost the same as that of the previous method and the estimation error of the nonlinear observer is improved as the order ℓ increases.',\n",
       "  'A Pseudo-Formal Linearization Using Chebyshev Expansion and Its Application to Nonlinear Observer for Nonlinear Scalar-Measurement Systems. This paper is concerned with a pseudo-formal linearization method using Chebyshev expansion and its application to a nonlinear observer for nonlinear scalar-measurement systems. The given nonlinear autonomous dynamic system is linearized into an augmented linear system with respect to a linearization function that consists of polynomials of state variables by a pseudo-formal linearization method using Chebyshev expansion. As an application of this method, a nonlinear observer is discussed. An augmented measurement vector that consists of polynomials of measurement data is introduced and is transformed into an augmented linear one by the pseudo-formal linearization technique using Chebyshev expansion. Thereby, a linear system theory is applied to both the linearized dynamic and measurement systems in order to design a new nonlinear observer. Numerical experiments indicate that the performance of the presented method is superior to that of the previous method.',\n",
       "  'Approximate linearization by state feedback and coordinate change.'],\n",
       " ['Numerical experiments indicate that the performance of the proposed method is superior to that of the previous method .',\n",
       "  'A Pseudo-Formal Linearization Using Chebyshev Expansion and Its Application to Nonlinear Observer for Nonlinear Scalar-Measurement Systems. This paper is concerned with a pseudo-formal linearization method using Chebyshev expansion and its application to a nonlinear observer for nonlinear scalar-measurement systems. The given nonlinear autonomous dynamic system is linearized into an augmented linear system with respect to a linearization function that consists of polynomials of state variables by a pseudo-formal linearization method using Chebyshev expansion. As an application of this method, a nonlinear observer is discussed. An augmented measurement vector that consists of polynomials of measurement data is introduced and is transformed into an augmented linear one by the pseudo-formal linearization technique using Chebyshev expansion. Thereby, a linear system theory is applied to both the linearized dynamic and measurement systems in order to design a new nonlinear observer. Numerical experiments indicate that the performance of the presented method is superior to that of the previous method.',\n",
       "  'On the largest feedback linearizable subsystem.'],\n",
       " ['This has led to an interest in whether this aspect can be leveraged to get better generalization on unseen goals made up of familiar terms .',\n",
       "  'Zero-Shot Task Generalization with Multi-Task Deep Reinforcement Learning. As a step towards developing zero-shot task generalization capabilities in reinforcement learning (RL), we introduce a new RL problem where the agent should learn to execute sequences of instructions after learning useful skills that solve subtasks. In this problem, we consider two types of generalizations: to previously unseen instructions and to longer sequences of instructions. For generalization over unseen instructions, we propose a new objective which encourages learning correspondences between similar subtasks by making analogies. For generalization over sequential instructions, we present a hierarchical architecture where a meta controller learns to use the acquired skills for executing the instructions. To deal with delayed reward, we propose a new neural architecture in the meta controller that learns when to update the subtask, which makes learning more efficient. Experimental results on a stochastic 3D domain show that the proposed ideas are crucial for generalization to longer instructions as well as unseen instructions.',\n",
       "  \"ALFWorld: Aligning Text and Embodied Environments for Interactive Learning. Given a simple request (e.g., Put a washed apple in the kitchen fridge), humans can reason in purely abstract terms by imagining action sequences and scoring their likelihood of success, prototypicality, and efficiency, all without moving a muscle. Once we see the kitchen in question, we can update our abstract plans to fit the scene. Embodied agents require the same abilities, but existing work does not yet provide the infrastructure necessary for both reasoning abstractly and executing concretely. We address this limitation by introducing ALFWorld, a simulator that enables agents to learn abstract, text-based policies in TextWorld (Cote et al., 2018) and then execute goals from the ALFRED benchmark (Shridhar et al., 2020) in a rich visual environment. ALFWorld enables the creation of a new BUTLER agent whose abstract knowledge, learned in TextWorld, corresponds directly to concrete, visually grounded actions. In turn, as we demonstrate empirically, this fosters better agent generalization than training only in the visually grounded environment. BUTLER's simple, modular design factors the problem to allow researchers to focus on models for improving every piece of the pipeline (language understanding, planning, navigation, visual scene understanding, and so forth).\"],\n",
       " ['Using language to express goals is potentially a way to approach task distribution shift and sample efficiency, key problems in 1 github.com/aalto-ai/sparse-compgen reinforcement learning .',\n",
       "  'BC-Z: Zero-Shot Task Generalization with Robotic Imitation Learning. In this paper, we study the problem of enabling a vision-based robotic manipulation system to generalize to novel tasks, a long-standing challenge in robot learning. We approach the challenge from an imitation learning perspective, aiming to study how scaling and broadening the data collected can facilitate such generalization. To that end, we develop an interactive and flexible imitation learning system that can learn from both demonstrations and interventions and can be conditioned on different forms of information that convey the task, including pre-trained embeddings of natural language or videos of humans performing the task. When scaling data collection on a real robot to more than 100 distinct tasks, we find that this system can perform 24 unseen manipulation tasks with an average success rate of 44%, without any robot demonstrations for those tasks.',\n",
       "  \"Deep Reinforcement Learning at the Edge of the Statistical Precipice. Deep reinforcement learning (RL) algorithms are predominantly evaluated by comparing their relative performance on a large suite of tasks. Most published results on deep RL benchmarks compare point estimates of aggregate performance such as mean and median scores across tasks, ignoring the statistical uncertainty implied by the use of a finite number of training runs. Beginning with the Arcade Learning Environment (ALE), the shift towards computationally-demanding benchmarks has led to the practice of evaluating only a small number of runs per task, exacerbating the statistical uncertainty in point estimates. In this paper, we argue that reliable evaluation in the few run deep RL regime cannot ignore the uncertainty in results without running the risk of slowing down progress in the field. We illustrate this point using a case study on the Atari 100k benchmark, where we find substantial discrepancies between conclusions drawn from point estimates alone versus a more thorough statistical analysis. With the aim of increasing the field's confidence in reported results with a handful of runs, we advocate for reporting interval estimates of aggregate performance and propose performance profiles to account for the variability in results, as well as present more robust and efficient aggregate metrics, such as interquartile mean scores, to achieve small uncertainty in results. Using such statistical tools, we scrutinize performance evaluations of existing algorithms on other widely used RL benchmarks including the ALE, Procgen, and the DeepMind Control Suite, again revealing discrepancies in prior comparisons. Our findings call for a change in how we evaluate performance in deep RL, for which we present a more rigorous evaluation methodology, accompanied with an open-source library rliable, to prevent unreliable results from stagnating the field.\"],\n",
       " ['To refine our estimate of the the dynamics p(s t+1 |s, a t ) and improve our estimate of Q(s, a t , g), we can use the above assumptions and a differentiable planning method known as a Value Iteration Network (VIN) .',\n",
       "  \"Value Iteration Networks. We introduce the value iteration network (VIN): a fully differentiable neural network with a `planning module' embedded within. VINs can learn to plan, and are suitable for predicting outcomes that involve planning-based reasoning, such as policies for reinforcement learning. Key to our approach is a novel differentiable approximation of the value-iteration algorithm, which can be represented as a convolutional neural network, and trained end-to-end using standard backpropagation. We evaluate VIN based policies on discrete and continuous path-planning domains, and on a natural-language based search task. We show that by learning an explicit planning computation, VIN policies generalize better to new, unseen domains.\",\n",
       "  'Leveraging Sparse Linear Layers for Debuggable Deep Networks. We show how fitting sparse linear models over learned deep feature representations can lead to more debuggable neural networks. These networks remain highly accurate while also being more amenable to human interpretation, as we demonstrate quantiatively via numerical and human experiments. We further illustrate how the resulting sparse explanations can help to identify spurious correlations, explain misclassifications, and diagnose model biases in vision and language tasks. The code for our toolkit can be found at https://github.com/madrylab/debuggabledeepnetworks.'],\n",
       " ['We performed GO Terms analysis for each of the six gene-clusters using the Gorilla software .',\n",
       "  'Discovering Motifs in Ranked Lists of DNA Sequences. Computational methods for discovery of sequence elements that are enriched in a target set compared with a background set are fundamental in molecular biology research. One example is the discovery of transcription factor binding motifs that are inferred from ChIP–chip (chromatin immuno-precipitation on a microarray) measurements. Several major challenges in sequence motif discovery still require consideration: (i) the need for a principled approach to partitioning the data into target and background sets; (ii) the lack of rigorous models and of an exact p-value for measuring motif enrichment; (iii) the need for an appropriate framework for accounting for motif multiplicity; (iv) the tendency, in many of the existing methods, to report presumably significant motifs even when applied to randomly generated data. In this paper we present a statistical framework for discovering enriched sequence elements in ranked lists that resolves these four issues. We demonstrate the implementation of this framework in a software application, termed DRIM (discovery of rank imbalanced motifs), which identifies sequence motifs in lists of ranked DNA sequences. We applied DRIM to ChIP–chip and CpG methylation data and obtained the following results. (i) Identification of 50 novel putative transcription factor (TF) binding sites in yeast ChIP–chip data. The biological function of some of them was further investigated to gain new insights on transcription regulation networks in yeast. For example, our discoveries enable the elucidation of the network of the TF ARO80. Another finding concerns a systematic TF binding enhancement to sequences containing CA repeats. (ii) Discovery of novel motifs in human cancer CpG methylation data. Remarkably, most of these motifs are similar to DNA sequence elements bound by the Polycomb complex that promotes histone methylation. Our findings thus support a model in which histone methylation and CpG methylation are mechanistically linked. Overall, we demonstrate that the statistical framework embodied in the DRIM software tool is highly effective for identifying regulatory sequence elements in a variety of applications ranging from expression and ChIP–chip to CpG methylation data. DRIM is publicly available at http://bioinfo.cs.technion.ac.il/drim.',\n",
       "  'Temperature, Oxygen, and Salt-Sensing Neurons in C. elegans Are Carbon Dioxide Sensors that Control Avoidance Behavior.'],\n",
       " ['It is given for BPSK in , by utilizing [5, eq.',\n",
       "  'On the Error Performance of Cooperative-NOMA With Statistical CSIT. The demands for high spectral efficiency and massive connections led the researchers to investigate new multiple access techniques for the future wireless networks. Non-Orthogonal Multiples Access (NOMA) is one of them. Hence, the integration of NOMA technique with the other physical layer techniques, such as MIMO, cooperative communication, and cognitive radio, has recently taken considerable attention. Whereas these numerous studies are mostly devoted to reveal the overall capacity and outage performances of NOMA involved systems, the error performances have not been investigated in the literature. In this letter, we analyze error performance of cooperative-NOMA, and the exact end-to-end bit error probability is derived in the closed-form. Then, the derived expressions are validated via simulations. Finally, the effect of the power allocation coefficient on the error performance is discussed.',\n",
       "  'BER performances of downlink and uplink NOMA in the presence of SIC errors over fading channels. Non-orthogonal multiple access (NOMA) is a strong candidate for next generation radio access networks due to its ability of serving multiple users using the same time and frequency resources. Therefore, researchers in academia and industry have been recently investigating the error performances and capacity of NOMA schemes. The main drawback of NOMA techniques is the interference among users due to the its non-orthogonal access nature, that is usually solved by interference cancellation techniques such as successive interference cancellation (SIC) at the receivers. On the other hand, the interference among users may not be completely eliminated in the SIC process due to the erroneous decisions in the receivers usually caused by channels. In this study, for the first time in the literature, the authors derive an exact closed-form bit error rate (BER) expressions under SIC error for downlink NOMA over Rayleigh fading channels. Besides, they derive one-degree integral form exact BER expressions and closed-form approximate expressions for uplink NOMA. Then, the derived expressions are validated by simulations. The numerical results are depicted to reveal the effects of error during SIC process on the performance for various cases such as power allocation for downlink and channel quality difference for uplink.'],\n",
       " ['Then, the error probability of C-NOMA within two users is derived for quadrature phase shift keying (QPSK) and binary phase shift keying (BPSK) modulations .',\n",
       "  'On the Error Performance of Cooperative-NOMA With Statistical CSIT. The demands for high spectral efficiency and massive connections led the researchers to investigate new multiple access techniques for the future wireless networks. Non-Orthogonal Multiples Access (NOMA) is one of them. Hence, the integration of NOMA technique with the other physical layer techniques, such as MIMO, cooperative communication, and cognitive radio, has recently taken considerable attention. Whereas these numerous studies are mostly devoted to reveal the overall capacity and outage performances of NOMA involved systems, the error performances have not been investigated in the literature. In this letter, we analyze error performance of cooperative-NOMA, and the exact end-to-end bit error probability is derived in the closed-form. Then, the derived expressions are validated via simulations. Finally, the effect of the power allocation coefficient on the error performance is discussed.',\n",
       "  'Coded Tandem Spreading Multiple Access for Massive Machine-Type Communications.'],\n",
       " ['Hence, the cooperation within NOMA users is proposed in and the outage probability of cooperative-NOMA (C-NOMA) is analyzed.',\n",
       "  'Cooperative Non-Orthogonal Multiple Access in 5G Systems. Non-orthogonal multiple access (NOMA) has received considerable recent attention as a promising candidate for 5G systems. A key feature of NOMA is that users with better channel conditions have prior information about the messages of other users. This prior knowledge is fully exploited in this letter, where a cooperative NOMA scheme is proposed. The outage probability and diversity order achieved by this cooperative NOMA scheme are analyzed, and an approach based on user pairing is also proposed to reduce system complexity.',\n",
       "  'Optimum Threshold for SNR-Based Selective Digital Relaying Schemes in Cooperative Wireless Networks.'],\n",
       " ['Since NOMA provides a spectral efficient communication, the potential of NOMA for massive machine type communication (MMTC) led researchers to investigate NOMA involved systems and tremendous effort has been devoted to integrate NOMA in future wireless networks , .',\n",
       "  'Coded Tandem Spreading Multiple Access for Massive Machine-Type Communications. ',\n",
       "  'A simple cooperative extension to wireless relaying.'],\n",
       " ['(0.42)] to (21).Then, with the aid of and after some simplifications, the expression (21) turns out to be BPSK β i = 2 ( √ a 2 ∓ √ a 1 ) 2 i = 1, 2 2 BPSK N = 3, α i = 0.25, i = 1, 2 a 3 = 0.5 QPSK β i = \\uf8f1 \\uf8f2 \\uf8f3 2 a 2 2 ∓ √ a 1 2 i = 1, 2 a 2 i = 3 3 QPSK N = 2, α i = 0.5, i = 1, 2 BPSK β i = 2 √ a 2 ∓ a 1 2 2 i = 1, 2 4 QPSK N = 2, α i = 0.5, i = 1, 2 QPSK β i = ( √ a 2 ∓ √ a 1 ) 2 i = 1, 2 5 16-QAM N = 4, α i = 0.25, i = 1, 2, 3, 4 BPSK β i = \\uf8f1 \\uf8f4 \\uf8f2 \\uf8f4 \\uf8f3 2 √ a 2 ∓φ opt th = \\uf8f1 \\uf8f2 \\uf8f3 N i=1 1 βi Q −1 ( δi /αi) 2 , δ i < 0.5 0, otherwise(22) where δ i = P (direct) II (e| i ) − P (div) II (e| i ) P (prop) II (e| i ) − P (div) II (e| i )(23) is defined.',\n",
       "  'Optimum Threshold for SNR-Based Selective Digital Relaying Schemes in Cooperative Wireless Networks. ',\n",
       "  'BER performances of downlink and uplink NOMA in the presence of SIC errors over fading channels. Non-orthogonal multiple access (NOMA) is a strong candidate for next generation radio access networks due to its ability of serving multiple users using the same time and frequency resources. Therefore, researchers in academia and industry have been recently investigating the error performances and capacity of NOMA schemes. The main drawback of NOMA techniques is the interference among users due to the its non-orthogonal access nature, that is usually solved by interference cancellation techniques such as successive interference cancellation (SIC) at the receivers. On the other hand, the interference among users may not be completely eliminated in the SIC process due to the erroneous decisions in the receivers usually caused by channels. In this study, for the first time in the literature, the authors derive an exact closed-form bit error rate (BER) expressions under SIC error for downlink NOMA over Rayleigh fading channels. Besides, they derive one-degree integral form exact BER expressions and closed-form approximate expressions for uplink NOMA. Then, the derived expressions are validated by simulations. The numerical results are depicted to reveal the effects of error during SIC process on the performance for various cases such as power allocation for downlink and channel quality difference for uplink.'],\n",
       " ['(A typical recommended value for both δ graph , δ latent is 0.7, as suggested in ).',\n",
       "  'False discovery and its control in low rank estimation. Models specified by low rank matrices are ubiquitous in contemporary applications. In many of these problem domains, the row–column space structure of a low rank matrix carries information about some underlying phenomenon, and it is of interest in inferential settings to evaluate the extent to which the row–column spaces of an estimated low rank matrix signify discoveries about the phenomenon. However, in contrast with variable selection, we lack a formal framework to assess true or false discoveries in low rank estimation; in particular, the key source of difficulty is that the standard notion of a discovery is a discrete notion that is ill suited to the smooth structure underlying low rank matrices. We address this challenge via a geometric reformulation of the concept of a discovery, which then enables a natural definition in the low rank case. We describe and analyse a generalization of the stability selection method of Meinshausen and Bühlmann to control for false discoveries in low rank estimation, and we demonstrate its utility compared with previous approaches via numerical experiments.',\n",
       "  'The Convex Geometry of Linear Inverse Problems. In applications throughout science and engineering one is often faced with the challenge of solving an ill-posed inverse problem, where the number of available measurements is smaller than the dimension of the model to be estimated. However in many practical situations of interest, models are constrained structurally so that they only have a few degrees of freedom relative to their ambient dimension. This paper provides a general framework to convert notions of simplicity into convex penalty functions, resulting in convex optimization solutions to linear, underdetermined inverse problems. The class of simple models considered includes those formed as the sum of a few atoms from some (possibly infinite) elementary atomic set; examples include well-studied cases from many technical fields such as sparse vectors (signal processing, statistics) and low-rank matrices (control, statistics), as well as several others including sums of a few permutation matrices (ranked elections, multiobject tracking), low-rank tensors (computer vision, neuroscience), orthogonal matrices (machine learning), and atomic measures (system identification). The convex programming formulation is based on minimizing the norm induced by the convex hull of the atomic set; this norm is referred to as the atomic norm. The facial structure of the atomic norm ball carries a number of favorable properties that are useful for recovering simple models, and an analysis of the underlying convex geometry provides sharp estimates of the number of generic measurements required for exact and robust recovery of models from partial information. These estimates are based on computing the Gaussian widths of tangent cones to the atomic norm ball. When the atomic set has algebraic structure the resulting optimization problems can be solved or approximated via semidefinite programming. The quality of these approximations affects the number of measurements required for recovery, and this tradeoff is characterized via some examples. Thus this work extends the catalog of simple models (beyond sparse vectors and low-rank matrices) that can be recovered from limited linear information via tractable convex programming.'],\n",
       " ['These are perhaps to be expected based on the theoretical analyses in , and it would be useful to combine and formalize these results in our context by showing that the Type-I and Type-II errors can be provably controlled under appropriate assumptions.',\n",
       "  'False discovery and its control in low rank estimation. Models specified by low rank matrices are ubiquitous in contemporary applications. In many of these problem domains, the row–column space structure of a low rank matrix carries information about some underlying phenomenon, and it is of interest in inferential settings to evaluate the extent to which the row–column spaces of an estimated low rank matrix signify discoveries about the phenomenon. However, in contrast with variable selection, we lack a formal framework to assess true or false discoveries in low rank estimation; in particular, the key source of difficulty is that the standard notion of a discovery is a discrete notion that is ill suited to the smooth structure underlying low rank matrices. We address this challenge via a geometric reformulation of the concept of a discovery, which then enables a natural definition in the low rank case. We describe and analyse a generalization of the stability selection method of Meinshausen and Bühlmann to control for false discoveries in low rank estimation, and we demonstrate its utility compared with previous approaches via numerical experiments.',\n",
       "  'Ising Models with Latent Conditional Gaussian Variables. Ising models describe the joint probability distribution of a vector of binary feature variables. Typically, not all the variables interact with each other and one is interested in learning the presumably sparse network structure of the interacting variables. However, in the presence of latent variables, the conventional method of learning a sparse model might fail. This is because the latent variables induce indirect interactions of the observed variables. In the case of only a few latent conditional Gaussian variables these spurious interactions contribute an additional low-rank component to the interaction parameters of the observed Ising model. Therefore, we propose to learn a sparse + low-rank decomposition of the parameters of an Ising model using a convex regularized likelihood problem. We show that the same problem can be obtained as the dual of a maximum-entropy problem with a new type of relaxation, where the sample means collectively need to match the expected values only up to a given tolerance. The solution to the convex optimization problem has consistency properties in the high-dimensional setting, where the number of observed binary variables and the number of latent conditional Gaussian variables are allowed to grow with the number of training samples.'],\n",
       " ['However, to also reduce type-I error it is useful to further restrict the models selected based on a more refined form of stability, as described in .',\n",
       "  'Stability selection. Summary.\\u2002 Estimation of structure, such as in variable selection, graphical modelling or cluster analysis, is notoriously difficult, especially for high dimensional data. We introduce stability selection. It is based on subsampling in combination with (high dimensional) selection algorithms. As such, the method is extremely general and has a very wide range of applicability. Stability selection provides finite sample control for some error rates of false discoveries and hence a transparent principle to choose a proper amount of regularization for structure estimation. Variable selection and structure estimation improve markedly for a range of selection methods if stability selection is applied. We prove for the randomized lasso that stability selection will be variable selection consistent even if the necessary conditions for consistency of the original lasso method are violated. We demonstrate stability selection for variable selection and Gaussian graphical modelling, using real and simulated data.',\n",
       "  'Learning Ising and Potts Models with Latent Variables.'],\n",
       " ['Finally, if we constrain the off-diagonal entries of the decision variable Θ in (1.3) to be zero, then we obtain a convex relaxation for an exponential-family generalization of principal components analysis (PCA) in which one wishes to fit a model in which the different components of x are independent of each other after conditioning on z (i.e., Θ i,j = 0, ∀i = j).',\n",
       "  'A Generalization of Principal Components Analysis to the Exponential Family. Principal component analysis (PCA) is a commonly applied technique for dimensionality reduction. PCA implicitly minimizes a squared loss function, which may be inappropriate for data that is not real-valued, such as binary-valued data. This paper draws on ideas from the Exponential family, Generalized linear models, and Bregman distances, to give a generalization of PCA to loss functions that we argue are better suited to other data types. We describe algorithms for minimizing the loss functions, and give examples on simulated data.',\n",
       "  'The Convex Geometry of Linear Inverse Problems. In applications throughout science and engineering one is often faced with the challenge of solving an ill-posed inverse problem, where the number of available measurements is smaller than the dimension of the model to be estimated. However in many practical situations of interest, models are constrained structurally so that they only have a few degrees of freedom relative to their ambient dimension. This paper provides a general framework to convert notions of simplicity into convex penalty functions, resulting in convex optimization solutions to linear, underdetermined inverse problems. The class of simple models considered includes those formed as the sum of a few atoms from some (possibly infinite) elementary atomic set; examples include well-studied cases from many technical fields such as sparse vectors (signal processing, statistics) and low-rank matrices (control, statistics), as well as several others including sums of a few permutation matrices (ranked elections, multiobject tracking), low-rank tensors (computer vision, neuroscience), orthogonal matrices (machine learning), and atomic measures (system identification). The convex programming formulation is based on minimizing the norm induced by the convex hull of the atomic set; this norm is referred to as the atomic norm. The facial structure of the atomic norm ball carries a number of favorable properties that are useful for recovering simple models, and an analysis of the underlying convex geometry provides sharp estimates of the number of generic measurements required for exact and robust recovery of models from partial information. These estimates are based on computing the Gaussian widths of tangent cones to the atomic norm ball. When the atomic set has algebraic structure the resulting optimization problems can be solved or approximated via semidefinite programming. The quality of these approximations affects the number of measurements required for recovery, and this tradeoff is characterized via some examples. Thus this work extends the catalog of simple models (beyond sparse vectors and low-rank matrices) that can be recovered from limited linear information via tractable convex programming.'],\n",
       " ['Let C1 ij and C2 be the renting cost for one unit time of machines η and μ respectively .',\n",
       "  'A fuzzy VIKOR method for supplier selection based on entropy measure for objective weighting. ',\n",
       "  'The Measurement of Diversity. The notion of diversity is an issue that is of relevance in several contexts. For example, the biodiversity of a given ecological environment and the diversity of the options available to a decision maker have attracted some attention in recent research. This paper provides an axiomatic approach to the measurement of diversity. We characterize two nested classes of ordinal measures of diversity and an important member of these classes. We prove that the latter special case is equivalent to a diversity ordering proposed by Weitzman.'],\n",
       " ['Some situations come from sectors where machines used in production are less expensive but these cannot be stopped and restarted easily .',\n",
       "  'A fuzzy VIKOR method for supplier selection based on entropy measure for objective weighting. ',\n",
       "  'Flowshop/no-idle or no-wait scheduling to minimize the sum of completion times. This paper deals with flowshop/sum of completion times scheduling problems, working under a “no‐idle” or a “no‐wait” constraint, the former prescribes for the machines to work continuously without idle intervals and the latter for the jobs to be processed continuously without waiting times between consecutive machines. Under either of the constraints the problem is unary NP‐Complete for two machines. We prove some properties of the optimal schedule for n/2/F, no‐idle/σCi. For n/m/P, no‐idle/σCi, and n/m/P, no‐wait/σCi, with an increasing or decreasing series of dominating machines, we prove theorems that are the basis for polynomial bounded algorithms. All theorems are demonstrated numerically.'],\n",
       " ['(The changes we introduced in the journal, initially and while transitioning to the current publisher, were detailed earlier.',\n",
       "  'A Year On: The Changes We Introduced and the Common Mistakes Encountered. One year has passed since the current editorial team assumed the responsibility of this journal. Dr. MS Reddy, the immediate past editor, had done an exemplary job during his long tenure – he had made the journal bimonthly, got it included in PubMed and Scopus, and ensured and improved the scientific rigor of its content. Building on those efforts, we implemented a few more modifications to various aspects of the journal: 1. Scope: The “scope of the journal” was reworded as “Indian Journal of Psychological Medicine is a peer-reviewed, open access journal which publishes high-quality original research and review articles pertaining to all domains of psychiatric practice and research. Other categories of manuscripts we publish include viewpoints (opinion pieces) and commentaries and letters to editor on articles we recently published or other topics of current relevance. The journal caters to mental health professionals and trainees, including psychiatrists, psychologists, psychiatric social workers and psychiatric nurses as well as other medical professionals and paraprofessionals” 2. Submissions: It was decided to consider only those research papers that have the approval of an Institutional Ethics Committee, to publish case reports only as letters to the editor, and to ask all authors to submit the International Committee of Medical Journal Editors (ICMJE) Conflict of Interest Form. From July 2019, the journal will consider only those clinical trials which are registered with the Clinical Trials Registry-India (CTRI). For trials which started before 2014, retrospective registration is sufficient. Submissions from other countries should have registration in respective national registries. Minor changes were made to the author instructions, especially in the specifications for Brief Communications. It was clarified that submission on community preprint servers will not be considered prior publication and will not compromise potential publication in IJPM. A list of the kinds of online supplementary material that can be submitted and the specifications about video files were newly added. From January 2019, the authors should include a ‘data sharing statement’ in the first page file, and detailed instructions regarding the same are provided in the author instructions at the journal website. 3. Peer review: The editorial team and the pool of reviewers were expanded, and the position of Section Editors was created. The peer-review system was further strengthened, and all manuscripts recommended by the reviewers now receive two additional rounds of editorial review also. Starting in this issue, all January issues will feature a list of experts who peer reviewed for us in the previous year 4. New posts: Posts of Journal Ombudsman and Statistical Consultant were created 5. Ahead of Print (AoP): In June 2018, the journal started regular AoP publishing 6. Social media: Facebook (https://www.facebook.com/ ijpsym/) and Twitter (https://twitter.com/ijpsym) pages were created for the journal 7. New column: “Learning Curve,” a column by Dr. Chittaranjan Andrade, was started, keeping in mind the learning needs of practitioners and postgraduate students, in research methodology and recent developments in psychiatry, especially psychopharmacology 8. Issue theme: We are attempting to make each issue focus, to the extent possible, on a specific theme 9. Cover: From this issue, the journal has a redesigned cover 10. Erratum charges: If an erratum is necessitated due to obvious errors made by the authors during the submission, revision, or proofreading stages, they will have to pay the journal the page-designing charge, that is, Rs 1,200 per page 11. Financial aspects: The journal now has its own, new, bank account and Permanent Account Number, separate from those of Indian Psychiatric Society South Zonal Branch. A Finance Committee was formed and it would take care of the financial needs of the journal.',\n",
       "  'A consensus statement from editors of psychiatry journals published in India.'],\n",
       " ['One drawback of the NIRS method is the variability of the path length, which is dependent on the structure of the scalp and superficial tissues over the brain .',\n",
       "  'Variability of (functional) hemodynamics as measured with simultaneous fNIRS and fMRI during intertemporal choice. ',\n",
       "  'NIRS-based hyperscanning reveals increased interpersonal coherence in superior frontal cortex during cooperation.'],\n",
       " ['Although several studies have already reported a PFC activity in the right and/or left hemisphere during two-person interaction tasks , the laterality of the PFC in social interaction remains to be clarified.',\n",
       "  'Between-brain connectivity during imitation measured by fNIRS. ',\n",
       "  'Estimation of optical pathlength through tissue from direct time of flight measurement. Quantitation of near infrared spectroscopic data in a scattering medium such as tissue requires knowledge of the optical pathlength in the medium. This can now be estimated directly from the time of flight of picosecond length light pulses. Monte Carlo modelling of light pulses in tissue has shown that the mean value of the time dispersed light pulse correlates with the pathlength used in quantitative spectroscopic calculations. This result has been verified in a phantom material. Time of flight measurements of pathlength across the rat head give a pathlength of 5.3 +/- 0.3 times the head diameter.'],\n",
       " ['This can explain some We use a modified version of the a priori algorithm introduced in to identify annotation inconsistencies.',\n",
       "  'Detecting Errors in Part-of-Speech Annotation. We propose a new method for detecting errors in \"gold-standard\" part-of-speech annotation. The approach locates errors with high precision based on n-grams occurring in the corpus with multiple taggings. Two further techniques, closed-class analysis and finite-state tagging guide patterns, are discussed. The success of the three approaches is illustrated for the Wall Street Journal corpus as part of the Penn Tree-bank.',\n",
       "  'Part-of-Speech Tagging for Twitter: Annotation, Features, and Experiments. We address the problem of part-of-speech tagging for English data from the popular micro-blogging service Twitter. We develop a tagset, annotate data, develop features, and report tagging results nearing 90% accuracy. The data and tools have been made available to the research community with the goal of enabling richer text analysis of Twitter and related social media data sets.'],\n",
       " ['Instead of using overly specific annotation guidelines, designed to minimize inter-annotator disagreement , and adjudicating between annotators of different opinions, we should embrace systematic inter-annotator disagreements.',\n",
       "  'Criteria for the Manual Grouping of Verb Senses. In this paper, we argue that clustering WordNet senses into more coarse-grained groupings results in higher inter-annotator agreement and increased system performance. Clustering of verb senses involves examining syntactic and semantic features of verbs and arguments on a case-by-case basis rather than applying a strict methodology. Determining appropriate criteria for clustering is based primarily on the needs of annotators.',\n",
       "  'Detecting Errors in Part-of-Speech Annotation. We propose a new method for detecting errors in \"gold-standard\" part-of-speech annotation. The approach locates errors with high precision based on n-grams occurring in the corpus with multiple taggings. Two further techniques, closed-class analysis and finite-state tagging guide patterns, are discussed. The success of the three approaches is illustrated for the Wall Street Journal corpus as part of the Penn Tree-bank.'],\n",
       " ['Figure 2: Disagreement between lay annotators Lastly, we compare the disagreements of annotators on a French social media data set , which we mapped to the universal POS tag set.',\n",
       "  'The French Social Media Bank: a Treebank of Noisy User Generated Content. ',\n",
       "  'Detecting Errors in Part-of-Speech Annotation. We propose a new method for detecting errors in \"gold-standard\" part-of-speech annotation. The approach locates errors with high precision based on n-grams occurring in the corpus with multiple taggings. Two further techniques, closed-class analysis and finite-state tagging guide patterns, are discussed. The success of the three approaches is illustrated for the Wall Street Journal corpus as part of the Penn Tree-bank.'],\n",
       " ['We instructed annotators to use the 12 universal POS tags of .',\n",
       "  'A Universal Part-of-Speech Tagset. To facilitate future research in unsupervised induction of syntactic structure and to standardize best-practices, we propose a tagset that consists of twelve universal part-of-speech categories. In addition to the tagset, we develop a mapping from 25 different treebank tagsets to this universal set. As a result, when combined with the original treebank data, this universal tagset and mapping produce a dataset consisting of common parts-of-speech for 22 different languages. We highlight the use of this resource via three experiments, that (1) compare tagging accuracies across languages, (2) present an unsupervised grammar induction approach that does not use gold standard part-of-speech tags, and (3) use the universal tags to transfer dependency parsers between languages, achieving state-of-the-art results.',\n",
       "  'Detecting Errors in Part-of-Speech Annotation. We propose a new method for detecting errors in \"gold-standard\" part-of-speech annotation. The approach locates errors with high precision based on n-grams occurring in the corpus with multiple taggings. Two further techniques, closed-class analysis and finite-state tagging guide patterns, are discussed. The success of the three approaches is illustrated for the Wall Street Journal corpus as part of the Penn Tree-bank.'],\n",
       " ['Note that OCHuman dataset is only designed for validation, we follow the common settings to train the models on COCO and evaluate on OCHuman-C. For top-down methods (i.e.',\n",
       "  'Pose2Seg: Detection Free Human Instance Segmentation. The standard approach to image instance segmentation is to perform the object detection first, and then segment the object from the detection bounding-box. More recently, deep learning methods like Mask R-CNN perform them jointly. However, little research takes into account the uniqueness of the \"human\" category, which can be well defined by the pose skeleton. Moreover, the human pose skeleton can be used to better distinguish instances with heavy occlusion than using bounding-boxes. In this paper, we present a brand new pose-based instance segmentation framework for humans which separates instances based on human pose, rather than proposal region detection. We demonstrate that our pose-based framework can achieve better accuracy than the state-of-art detection-based approach on the human instance segmentation problem, and can moreover better handle occlusion. Furthermore, there are few public datasets containing many heavily occluded humans along with comprehensive annotations, which makes this a challenging problem seldom noticed by researchers. Therefore, in this paper we introduce a new benchmark \"Occluded Human (OCHuman)\", which focuses on occluded humans with comprehensive annotations including bounding-box, human pose and instance masks. This dataset contains 8110 detailed annotated human instances within 4731 images. With an average 0.67 MaxIoU for each person, OCHuman is the most complex and challenging dataset related to human instance segmentation. Through this dataset, we want to emphasize occlusion as a challenging problem for researchers to study.',\n",
       "  'Simple Baselines for Human Pose Estimation and Tracking. There has been significant progress on pose estimation and increasing interests on pose tracking in recent years. At the same time, the overall algorithm and system complexity increases as well, making the algorithm analysis and comparison more difficult. This work provides simple and effective baseline methods. They are helpful for inspiring and evaluating new ideas for the field. State-of-the-art results are achieved on challenging benchmarks. The code will be available at this https URL.'],\n",
       " ['According to , augmenting with one specific type of noise enhances the performance on the target noise, but it does not generalize to other unseen distortions while degrading the performance on clean data.',\n",
       "  'Generalisation in humans and deep neural networks. We compare the robustness of humans and current convolutional deep neural networks (DNNs) on object recognition under twelve different types of image degradations. First, using three well known DNNs (ResNet-152, VGG-19, GoogLeNet) we find the human visual system to be more robust to nearly all of the tested image manipulations, and we observe progressively diverging classification error-patterns between humans and DNNs when the signal gets weaker. Secondly, we show that DNNs trained directly on distorted images consistently surpass human performance on the exact distortion types they were trained on, yet they display extremely poor generalisation abilities when tested on other distortion types. For example, training on salt-and-pepper noise does not imply robustness on uniform white noise and vice versa. Thus, changes in the noise distribution between training and testing constitutes a crucial challenge to deep learning vision systems that can be systematically addressed in a lifelong machine learning approach. Our new dataset consisting of 83K carefully measured human psychophysical trials provide a useful reference for lifelong robustness against image degradations set by the human visual system.',\n",
       "  'Microsoft COCO: Common Objects in Context. We present a new dataset with the goal of advancing the state-of-the-art in object recognition by placing the question of object recognition in the context of the broader question of scene understanding. This is achieved by gathering images of complex everyday scenes containing common objects in their natural context. Objects are labeled using per-instance segmentations to aid in precise object localization. Our dataset contains photos of 91 objects types that would be easily recognizable by a 4 year old. With a total of 2.5 million labeled instances in 328k images, the creation of our dataset drew upon extensive crowd worker involvement via novel user interfaces for category detection, instance spotting and instance segmentation. We present a detailed statistical analysis of the dataset in comparison to PASCAL, ImageNet, and SUN. Finally, we provide baseline performance analysis for bounding box and segmentation detection results using a Deformable Parts Model.'],\n",
       " ['For pose estimation, adversarial data augmentation methods are leveraged to optimize augmentation hyper-parameters, e.g.',\n",
       "  'Adversarial Semantic Data Augmentation for Human Pose Estimation. Human pose estimation is the task of localizing body keypoints from still images. The state-of-the-art methods suffer from insufficient examples of challenging cases such as symmetric appearance, heavy occlusion and nearby person. To enlarge the amounts of challenging cases, previous methods augmented images by cropping and pasting image patches with weak semantics, which leads to unrealistic appearance and limited diversity. We instead propose Semantic Data Augmentation (SDA), a method that augments images by pasting segmented body parts with various semantic granularity. Furthermore, we propose Adversarial Semantic Data Augmentation (ASDA), which exploits a generative network to dynamiclly predict tailored pasting configuration. Given off-the-shelf pose estimation network as discriminator, the generator seeks the most confusing transformation to increase the loss of the discriminator while the discriminator takes the generated sample as input and learns from it. The whole pipeline is optimized in an adversarial manner. State-of-the-art results are achieved on challenging benchmarks.',\n",
       "  'Associative Embedding: End-to-End Learning for Joint Detection and Grouping. We introduce associative embedding, a novel method for supervising convolutional neural networks for the task of detection and grouping. A number of computer vision problems can be framed in this manner including multi-person pose estimation, instance segmentation, and multi-object tracking. Usually the grouping of detections is achieved with multi-stage pipelines, instead we propose an approach that teaches a network to simultaneously output detections and group assignments. This technique can be easily integrated into any state-of-the-art network architecture that produces pixel-wise predictions. We show how to apply this method to multi-person pose estimation and report state-of-the-art performance on the MPII and MS-COCO datasets.'],\n",
       " ['The state-of-theart pose estimators suffer severe performance drop on corrupted images.',\n",
       "  'Adversarial Semantic Data Augmentation for Human Pose Estimation. Human pose estimation is the task of localizing body keypoints from still images. The state-of-the-art methods suffer from insufficient examples of challenging cases such as symmetric appearance, heavy occlusion and nearby person. To enlarge the amounts of challenging cases, previous methods augmented images by cropping and pasting image patches with weak semantics, which leads to unrealistic appearance and limited diversity. We instead propose Semantic Data Augmentation (SDA), a method that augments images by pasting segmented body parts with various semantic granularity. Furthermore, we propose Adversarial Semantic Data Augmentation (ASDA), which exploits a generative network to dynamiclly predict tailored pasting configuration. Given off-the-shelf pose estimation network as discriminator, the generator seeks the most confusing transformation to increase the loss of the discriminator while the discriminator takes the generated sample as input and learns from it. The whole pipeline is optimized in an adversarial manner. State-of-the-art results are achieved on challenging benchmarks.',\n",
       "  'TRB: A Novel Triplet Representation for Understanding 2D Human Body. Human pose and shape are two important components of 2D human body. However, how to efficiently represent both of them in images is still an open question. In this paper, we propose the Triplet Representation for Body (TRB) --- a compact 2D human body representation, with skeleton keypoints capturing human pose information and contour keypoints containing human shape information. TRB not only preserves the flexibility of skeleton keypoint representation, but also contains rich pose and human shape information. Therefore, it promises broader application areas, such as human shape editing and conditional image generation. We further introduce the challenging problem of TRB estimation, where joint learning of human pose and shape is required. We construct several large-scale TRB estimation datasets, based on the popular 2D pose datasets LSP, MPII and COCO. To effectively solve TRB estimation, we propose a two-branch network (TRB-net) with three novel techniques, namely X-structure (Xs), Directional Convolution (DC) and Pairwise mapping (PM), to enforce multi-level message passing for joint feature learning. We evaluate our proposed TRB-net and several leading approaches on our proposed TRB datasets, and demonstrate the superiority of our method through extensive evaluations.'],\n",
       " ['Introduction Human pose estimation (HPE) is a fundamental task for action recognition and video surveillance .',\n",
       "  '2D/3D Pose Estimation and Action Recognition Using Multitask Deep Learning. Action recognition and human pose estimation are closely related but both problems are generally handled as distinct tasks in the literature. In this work, we propose a multitask framework for jointly 2D and 3D pose estimation from still images and human action recognition from video sequences. We show that a single architecture can be used to solve the two problems in an efficient way and still achieves state-of-the-art results. Additionally, we demonstrate that optimization from end-to-end leads to significantly higher accuracy than separated learning. The proposed architecture can be trained with data from different categories simultaneously in a seamlessly way. The reported results on four datasets (MPII, Human3.6M, Penn Action and NTU) demonstrate the effectiveness of our method on the targeted tasks.',\n",
       "  'RMPE: Regional Multi-person Pose Estimation. Multi-person pose estimation in the wild is challenging. Although state-of-the-art human detectors have demonstrated good performance, small errors in localization and recognition are inevitable. These errors can cause failures for a single-person pose estimator (SPPE), especially for methods that solely depend on human detection results. In this paper, we propose a novel regional multi-person pose estimation (RMPE) framework to facilitate pose estimation in the presence of inaccurate human bounding boxes. Our framework consists of three components: Symmetric Spatial Transformer Network (SSTN), Parametric Pose Non-Maximum-Suppression (NMS), and Pose-Guided Proposals Generator (PGPG). Our method is able to handle inaccurate bounding boxes and redundant detections, allowing it to achieve 76:7 mAP on the MPII (multi person) dataset[3]. Our model and source codes are made publicly available.'],\n",
       " ['To solve this problem, active disturbance rejection control (ADRC) is proposed for designing the controller .',\n",
       "  'Lateral Path Tracking Control of Autonomous Land Vehicle Based on ADRC and Differential Flatness. ',\n",
       "  'Piezoelectric Multimode Vibration Control for Stiffened Plate Using ADRC-Based Acceleration Compensation.']]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "86934"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
