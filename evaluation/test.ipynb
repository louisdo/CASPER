{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ea4947e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b1f94d63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_collection(collection_path):\n",
    "\n",
    "    collection = []\n",
    "\n",
    "    with open(collection_path) as f:\n",
    "        for line_idx, line in enumerate(f):\n",
    "            if line_idx % (1000*1000) == 0:\n",
    "                print(f'{line_idx // 1000 // 1000}M', end=' ', flush=True)\n",
    "\n",
    "            pid, passage, *rest = line.strip('\\n\\r ').split('\\t')\n",
    "            assert pid == 'id' or int(pid) == line_idx, f\"pid={pid}, line_idx={line_idx}\"\n",
    "\n",
    "            if len(rest) >= 1:\n",
    "                title = rest[0]\n",
    "                passage = title + ' | ' + passage\n",
    "\n",
    "            collection.append(passage)\n",
    "\n",
    "    print()\n",
    "\n",
    "    return collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2558bc68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0M \n"
     ]
    }
   ],
   "source": [
    "test = load_collection(\"/home/lamdo/ColBERT/data/scifact/collection.tsv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c2642683",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5183"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "993ece8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lamdo/.local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "48b10fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "87af5c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "lengths = []\n",
    "with open(\"/home/lamdo/ColBERT/data/doris_mae/queries.jsonl\") as f:\n",
    "    for line in f:\n",
    "        jline = json.loads(line)\n",
    "\n",
    "        lengths.append(len(tokenizer.tokenize(jline[\"text\"])) + 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "799eedb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 99,\n",
       " 'title': '',\n",
       " 'text': \"In the context of time series forecasting, it's observed that anomalies in certain data sources, such as seismic activity, heart rate monitors, and nuclear plant cooling system temperatures, occur infrequently but often result in catastrophic outcomes like earthquakes, heart attacks, and nuclear meltdowns. My objective is to devise a time series forecasting model capable of predicting these rare anomalies with high precision. This model must be equipped to manage extremely sparse supervised signals. To train my model effectively, I believe it's necessary to employ some form of sampling or bootstrapping to simulate various event pathways leading to these anomalies. Essentially, this involves data augmentation to generate more positive signals for training. Consequently, I require a simulation agent capable of learning the underlying time series data distribution. This simulation agent (model) must also be generative to create new pathways and simulate new events. I propose that the simulation agent should incorporate a reinforcement learning component. However, I am open to any literature that discusses rare event simulation, regardless of whether the method is statistical or deep learning-based. Ultimately, I am confident that my model will be robust enough for deployment in real-world scenarios for disaster prevention and early warning systems.\"}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e89aefa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "51e41137",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({185: 4, 148: 4, 204: 4, 149: 4, 175: 3, 203: 3, 171: 3, 195: 3, 183: 2, 191: 2, 155: 2, 146: 2, 161: 2, 187: 2, 137: 2, 144: 2, 177: 2, 212: 2, 201: 2, 190: 2, 181: 2, 211: 2, 163: 1, 100: 1, 142: 1, 253: 1, 174: 1, 200: 1, 242: 1, 165: 1, 159: 1, 166: 1, 135: 1, 164: 1, 169: 1, 141: 1, 134: 1, 232: 1, 176: 1, 173: 1, 140: 1, 179: 1, 182: 1, 207: 1, 227: 1, 208: 1, 150: 1, 216: 1, 154: 1, 198: 1, 206: 1, 205: 1, 229: 1, 186: 1, 178: 1, 209: 1, 222: 1, 160: 1, 162: 1, 129: 1, 225: 1, 189: 1, 172: 1, 239: 1, 202: 1, 254: 1})\n"
     ]
    }
   ],
   "source": [
    "print(Counter(lengths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5e38b875",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "180.44"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(lengths) / len(lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3f2d0c6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
