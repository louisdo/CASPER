{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "phrases_to_check = [\"kalman filter\", \"compressed sensing\"]\n",
    "phrases_to_check_metadata = {k:[] for k in phrases_to_check}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1500000it [00:08, 176093.22it/s]\n"
     ]
    }
   ],
   "source": [
    "with open(\"/scratch/lamdo/unArxive/keyphrase_informativeness_combined_references/triplets_hardneg/raw.tsv\") as f:\n",
    "    for i, line in tqdm(enumerate(f)):\n",
    "        for phrase in phrases_to_check_metadata:\n",
    "            if \"\" + phrase + \"\" in line: phrases_to_check_metadata[phrase].append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'kalman filter': 3421, 'compressed sensing': 4273}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{k:len(v) for k,v in phrases_to_check_metadata.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[157, 201, 941, 1557, 2287, 2744, 3180, 3199, 4663, 4738]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phrases_to_check_metadata[\"kalman filter\"][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "63043it [00:00, 324476.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fast articulated motion tracking using a sums of gaussians body model\tfast articulated motion tracking using a sums of gaussians body model. we present an approach for modeling the human body by sums of spatial gaussians (sog) allowing us to perform fast and high quality markerless motion capture from multi view video sequences. the sog model is equipped with a color model to represent the shape and appearance of the human and can be reconstructed from a sparse set of images. similar to the human body, we also represent the image domain as sog that models color consistent image blobs. based on the sog models of the image and the human body, we introduce a novel continuous and differentiable model to image similarity measure that can be used to estimate the skeletal motion of a human at 5 15 frames per second even for many camera views. in our experiments, we show that our method, which does not rely on silhouettes or training data, offers an good balance between accuracy and computational cost.\tmotion detection surveillance system for human head. dralnedawy@yahoo.co.uk ahmedmeg29@yahoo.com abstract motion detection for human head and its coordinates is one of the important areas with multiple applications at the present time, such as control of devices for people with disabilities and other modern control devices estimation model to detect human head and follow up coordinates. this system uses frame subtracting to detect motion with development the background frame is to eliminate the problem of wrong alarm for motion when the background frame still without change. gaussian smoothing filter also has been used to reduce noise caused by bad illumination or web camera low quality, so there is no need for kalman filter, then using laplacian filter which is dependent on second derivation in order to detect edges of the frames(background and current) at last detecting the human head using the sum of gradient magnitude around the perimeter of ellipses equation. the system has been tested on several samples indoor and out door two of these samples for females it head hooded (with islamic hijab) and the results were very good in detecting heads and tracking their coordinates. the system has been built using visual c# which is considered faster than interpreted matlab that have been used in other researches in the same area.\n",
      "\n",
      "nonlinear estimation techniques applied on target tracking problems\tnonlinear estimation techniques applied on target tracking problems. this paper discusses the application of four nonlinear estimation techniques on two benchmark target tracking problems. the first problem is a generic air traffic control (atc) scenario, which involves nonlinear system equations with linear measurements. the second study is a classical ground surveillance problem, where a moving airborne platform with a sensor is used to track a moving target. the tracking scenario is set in two dimensions, with the measurement providing nonlinear bearing only observations. these two target tracking problems provide a good benchmark for comparing the following nonlinear estimation techniques: the common extended and unscented kalman filters (ekf/ukf) the particle filter (pf) and the relatively new smooth variable structure filter (svsf) the results of applying the svsf on the two target tracking problems demonstrate its stability and robustness. both of these attributes make use of the svsf advantageous over other popular methods. the filters performances are quantified in terms of robustness, resilience to poor initial conditions and measurement outliers, and tracking accuracy and computational complexity. the purpose of this paper is to demonstrate the effectiveness of applying the svsf on nonlinear target tracking problems, which in the past have typically been solved by kalman or particle filters.\trobust techniques for multiple target tracking and fully adaptive radar tecnicas robustas para seguimiento de multiples blancos y radar adaptativo. this ph.d. thesis is concerned with the development of robust methods for high dimensional recursive bayesian filtering and sensor management in dynamic systems. many problems in science and engineering require the estimation of the state of a system, that changes over time, using a sequence of available noisy measurements. recursive bayesian filters sequentially compute at each time step the probability density function (pdf) of the state of a dynamic system given all the received sensor measurements. this posterior pdf includes all the information of interest about the state for estimation purposes. however, except for a very limited class of models, the posterior pdf cannot be generally computed in closed form, and approximations, such as particle filters, are necessary. unfortunately, the performance of these approximations generally severely degrades when the dimension of the space in which the state of the system takes values is high, an effect which is commonly referred to as the curse of dimensionality. part i of this thesis focuses on the development of different particle filtering techniques which can robustly tackle the filtering of high dimensional states. a useful strategy to overcome the curse of dimensionality is to consider a partition of the state space, so that samples from each component of the partition can be drawn independently in a particle filter. following this strategy, the auxiliary parallel partition (app) method is proposed, which overcomes limitations of previous partitioned particle filters in the literature by considering the use of auxiliary particle filtering. a second filter, which additionally incorporates a component resampling (target resampling) stage, is also presented. this filter, the target resampling app (trapp) is shown to be useful when the dimension of the state space is high, at the cost of a loss in the diversity of the samples of each component. thus, a third method is considered, the adaptive trapp (atrapp) which adaptively decides if target resampling is needed in each component. this makes atrapp a robust algorithm, with a reliable performance regardless of the dimension of the state space, performing target resampling when necessary and favoring sample diversity when possible. an alternative strategy to beat the curse of dimensionality is to make use of multiple filtering, where the marginal posterior pdf of each component of the state is individually estimated using a different filter. multiple filters, however, require of a marginalization procedure, which generally also needs to be computed in an approximated form. the inclusion of auxiliary particle filtering along with a first order approximation to the marginalization procedure in the multiple auxiliary particle filter (mapf) is detailed. in addition, the sigma point multiple particle filter (sp mpf) is presented, which, making use of sigma point integration methods, computes a second order approximation to the required marginalization procedure. finally, auxiliary filtering is also considered within this setting in the sigma point multiple auxiliary particle filter (sp mapf) the presented algorithms are shown to have an outstanding performance with respect to previous methods in the literature in a multiple target tracking scenario. it is often the case in which the received measurements depend on some parameters of the sensors which can be tuned. the posterior pdf of the state in such cases therefore depends on the selected sensor parameters, so that they need to be carefully chosen to maximize performance. this sensor management problem is the focus of part ii of this thesis. recent approaches to the sensor management problem, such as the fully adaptive radar (far) are inspired by the neuroscience approach to decision making and cognition. the far framework gathers in a simple and compact architecture the main concepts of this novel approach. implementations in the literature of the far framework for the problems of single target tracking and simultaneous single target detection and tracking are first reviewed, and the specialization of the far for the problem of multiple target tracking with a fixed and known number of targets is presented. in the final part of this thesis, the reviewed far implementations in the literature for the problems of single target tracking and simultaneous single target detection and tracking are shown to suffer robustness issues when applied to difficult scenarios. these robustness issues are first thoroughly characterized and alternative robust novel methods within the far framework are presented. the proposed methods are shown to reliably perform in these difficult scenarios.\n",
      "\n",
      "estimating model evidence using ensemble-based data assimilation with localization - the model selection problem\tiin recent years, there has been a growing interest in applying data assimilation (da) methods, originally designed for state estimation, to the model selection problem. in this setting, carrassi et al. (2017) introduced the contextual formulation of model evidence (cme) and showed that cme can be efficiently computed using a hierarchy of ensemble-based da procedures. although carrassi et al. (2017) analyzed the da methods most commonly used for operational atmospheric and oceanic prediction worldwide, they did not study these methods in conjunction with localization to a specific domain. yet any application of ensemble da methods to realistic geophysical models requires the implementation of some form of localization. the present study extends the theory for estimating cme to ensemble da methods with domain localization. the domain-localized cme (dl-cme) developed herein is tested for model selection with two models: (i) the lorenz 40-variable mid-latitude atmospheric dynamics model (l95); and (ii) the simplified global atmospheric speedy model. the cme is compared to the root-mean-square-error (rmse) as a metric for model selection. the experiments show that cme improves systematically over the rmse, and that this skill improvement is further enhanced by applying localization in the estimate of the cme, using the dl-cme. the potential use and range of applications of the cme and dl-cme as a model selection metric are also discussed.\tthe proof of convergence of the standard ensemble kalman filter (enkf) from legland etal. (2011) is extended to non-gaussian state space models. a density-based deterministic approximation of the mean-field limit enkf (dmfenkf) is proposed, consisting of a pde solver and a quadrature rule. given a certain minimal order of convergence $\\\\\\\\kappa$ between the two, this extends to the deterministic filter approximation, which is therefore asymptotically superior to standard enkf when the dimension $d<2\\\\\\\\kappa$. the fidelity of approximation of the true distribution is also established using an extension of total variation metric to random measures. this is limited by a gaussian bias term arising from non-linearity/non-gaussianity of the model, which exists for both dmfenkf and standard enkf. numerical results support and extend the theory.\n",
      "\n",
      "to handle this issue, a robust kalman filter called mckf was developed via recasting the kalman filtering problem as a linear regression one.\tmaximum correntropy kalman filter. traditional kalman filter (kf) is derived under the well-known minimum mean square error (mmse) criterion, which is optimal under gaussian assumption. however, when the signals are non-gaussian, especially when the system is disturbed by some heavy-tailed impulsive noises, the performance of kf will deteriorate seriously. to improve the robustness of kf against impulsive noises, we propose in this work a new kalman filter, called the maximum correntropy kalman filter (mckf), which adopts the robust maximum correntropy criterion (mcc) as the optimality criterion, instead of using the mmse. similar to the traditional kf, the state mean and covariance matrix propagation equations are used to give prior estimations of the state and covariance matrix in mckf. a novel fixed-point algorithm is then used to update the posterior estimations. a sufficient condition that guarantees the convergence of the fixed-point algorithm is given. illustration examples are presented to demonstrate the effectiveness and robustness of the new algorithm.\tnonlinear stochastic position and attitude filter on the special euclidean group 3. this paper formulates the pose estimation problem as nonlinear stochastic filter kinematics evolved directly on the special euclidean group se(3). proposed filter guarantees that the errors present in position and rodriguez vector estimates are semi-globally uniformly ultimately bounded (sguub) in mean square, and that they converge to small neighborhood of the origin in probability. simulation results show the robustness and effectiveness of the proposed filter in presence of high levels of noise and bias associated with the velocity vector as well as body-frame measurements. keywords: pose estimator, pose observer, attitude estimate, control, estimator, observer, nonlinear stochastic pose filter, stochastic differential equations, brownian motion process, ito, stratonovich, wong zakai, unit-quaternion, special orthogonal group, homogeneous transformation matrix, complimentary filter, euler angles, angle-axis, mapping, parameterization, representation, robust, multiplicative extended kalman filter, unscented kalman filter, particle filter, kf, ekf, iekf, ukf, mekf, partial derivative, small, dynamics, equilibrium, asymptotic, covariance, expected value, zero, unknown, time-varying, global, semi-global, stable, stability, uncertain, gaussian, colored, white, noise, vectorial measurement, vector measurement, translational velocity, angular velocity, singular value decomposition, rotational matrix, identity, deterministic, comparison, inertial frame, rigid body, three dimensional, 3d, space, adjoint, lie group, projection, landmark, feature, gyroscope, micro electromechanical systems, inertial measurement units, sensor, imus, fixed, moving, orientation, roll, pitch, yaw, svd, uavs, quav, unmanned, underwater vehicle, robot, robotic system, spacecraft, quadrotor, quadcopter, integral, advantage, disadvantage, comparative study, review, overview, survey, autonomous, xyz, axis, so(3), se(3).\n",
      "\n",
      "recent research , show that imu data can be processed by a trained dnn to predict the velocity, which can be leveraged to resolve the camera localization problem.\ttlio: tight learned inertial odometry. in this work we propose a tightly-coupled extended kalman filter framework for imu-only state estimation. strap-down imu measurements provide relative state estimates based on imu kinematic motion model. however the integration of measurements is sensitive to sensor bias and noise, causing significant drift within seconds. recent research by yan et al. (ronin) and chen et al. (ionet) showed the capability of using trained neural networks to obtain accurate 2d displacement estimates from segments of imu data and obtained good position estimates from concatenating them. this paper demonstrates a network that regresses 3d displacement estimates and its uncertainty, giving us the ability to tightly fuse the relative state measurement into a stochastic cloning ekf to solve for pose, velocity and sensor biases. we show that our network, trained with pedestrian data from a headset, can produce statistically consistent measurement and uncertainty to be used as the update step in the filter, and the tightly-coupled system outperforms velocity integration approaches in position estimates, and ahrs attitude filter in orientation estimates.\tpvnet: pixel-wise voting network for 6dof pose estimation. this paper addresses the challenge of 6dof pose estimation from a single rgb image under severe occlusion or truncation. many recent works have shown that a two-stage approach, which first detects keypoints and then solves a perspective-n-point (pnp) problem for pose estimation, achieves remarkable performance. however, most of these methods only localize a set of sparse keypoints by regressing their image coordinates or heatmaps, which are sensitive to occlusion and truncation. instead, we introduce a pixel-wise voting network (pvnet) to regress pixel-wise unit vectors pointing to the keypoints and use these vectors to vote for keypoint locations using ransac. this creates a flexible representation for localizing occluded or truncated keypoints. another important feature of this representation is that it provides uncertainties of keypoint locations that can be further leveraged by the pnp solver. experiments show that the proposed approach outperforms the state of the art on the linemod, occlusion linemod and ycb-video datasets by a large margin, while being efficient for real-time pose estimation. we further create a truncation linemod dataset to validate the robustness of our approach against truncation. the code will be avaliable at <url>\n",
      "\n",
      "hand pose classification based on neural networks\thand pose classification based on neural networks. in this work, deep learning models are applied to a segment of a robust hand washing dataset that has been created with the help of 30 volunteers. this work demonstrates the classification of presence of one hand, two hands and no hand in the scene based on transfer learning. the pre trained model; simplest nn from keras library is utilised to train the network with 704 images of hand gestures and the predictions are carried out for the input image. due to the controlled and restricted dataset, 100% accuracy is achieved during the training with correct predictions for the input image. complete hand washing dataset with dense models such as alexnet for video classification for hand hygiene stages will be used in the future work.\treal time hand gesture recognition based on deep learning in complex environments. real time hand gesture recognition in complex environments has many challenges, such as poor real time performances and robustness to environmental changes. this paper takes the hand gesture control of the unmanned vehicle as the application background, and focuses on the gesture detection and recognition of video streams based on deep learning in the complex environment. in this paper, we detect the hand in a complex environment by training the ssd_mobilenet model, and initialize the tracking with kalman filter. then, we detect the hand keypoints by following the architecture of convolutional pose machines (cpms) in order to obtain the belief maps for all keypoints that are used as the train sets of convolutional neural networks (cnns) finally, based on the results obtained by our classification, this paper proposes a method of multi frame recursion to minimize the influences of redundant frames and error frames. in this paper, eight kinds of gestures for controlling vehicle are identified. the experimental results show that our method can successfully realize real time hand gesture recognition in the video streams. the recognition accuracy can reach 96.7% and the average recognition speed reaches 12 fps, which basically meets the real time requirements and successfully applys to mobile terminals such as tx2 for engineering practice.\n",
      "\n",
      "multiple kinect sensor fusion for human skeleton tracking using kalman filtering\tmultiple kinect sensor fusion for human skeleton tracking using kalman filtering. kinect sensors are able to achieve considerable skeleton tracking performance in a convenient and low cost manner. however, kinect sensors often generate poor skeleton poses due to self occlusion, which is a common problem among most vision based sensing systems. a simple way to solve this problem is to use multiple kinect sensors in a workspace and combine the measurements from the different sensors. however, this method creates a new issue known as the data fusion problem. in this research, we developed a human skeleton tracking system using the kalman filter framework, in which multiple kinect sensors are used to correct inaccurate tracking data from a single kinect sensor. our contribution is to propose a method to determine the reliability of each tracked 3d position of a joint and then combine multiple observations based on measurement confidence. we evaluate the proposed approach by comparison with the ground truth obtained using a commercial marker based motion capture system.\tan augmented reality based human robot interaction interface using kalman filter sensor fusion. in this paper, the application of augmented reality (ar) for the control and adjustment of robots has been developed, with the aim of making interaction and adjustment of robots easier and more accurate from a remote location. a leapmotion sensor based controller has been investigated to track the movement of the operator hands. the data from the controller allows gestures and the position of the hand palm's central point to be detected and tracked. a kinect v2 camera is able to measure the corresponding motion velocities in x, y, z directions after our investigated post processing algorithm is fulfilled. unreal engine 4 is used to create an ar environment for the user to monitor the control process immersively. kalman filtering (kf) algorithm is employed to fuse the position signals from the leapmotion sensor with the velocity signals from the kinect camera sensor, respectively. the fused/optimal data are sent to teleoperate a baxter robot in real time by user datagram protocol (udp) several experiments have been conducted to test the validation of the proposed method.\n",
      "\n",
      "unovost: unsupervised offline video object segmentation and tracking\twe address unsupervised video object segmentation (uvos), the task of automatically generating accurate pixel masks for salient objects in a video sequence and of tracking these objects consistently through time, without any input about which objects should be tracked. towards solving this task, we present unovost (unsupervised offline video object segmentation and tracking) as a simple and generic algorithm which is able to track and segment a large variety of objects. this algorithm builds up tracks in a number stages, first grouping segments into short tracklets that are spatio-temporally consistent, before merging these tracklets into long-term consistent object tracks based on their visual similarity. in order to achieve this we introduce a novel tracklet-based forest path cutting data association algorithm which builds up a decision forest of track hypotheses before cutting this forest into paths that form long-term consistent object tracks. when evaluating our approach on the davis 2017 unsupervised dataset we obtain state-of-the-art performance with a mean j &f score of 67.9% on the val, 58% on the test-dev and 56.4% on the test-challenge benchmarks, obtaining first place in the davis 2019 unsupervised video object segmentation challenge. unovost even performs competitively with many semi-supervised video object segmentation algorithms even though it is not given any input as to which objects should be tracked and segmented.\tthis paper explores a pragmatic approach to multiple object tracking where the main focus is to associate objects efficiently for online and realtime applications. to this end, detection quality is identified as a key factor influencing tracking performance, where changing the detector can improve tracking by up to 18.9%. despite only using a rudimentary combination of familiar techniques such as the kalman filter and hungarian algorithm for the tracking components, this approach achieves an accuracy comparable to state-of-the-art online trackers. furthermore, due to the simplicity of our tracking method, the tracker updates at a rate of 260 hz which is over 20x faster than other state-of-the-art trackers.\n",
      "\n",
      "manufacturing human skeleton fusion\tmultiple kinect sensor fusion for human skeleton tracking using kalman filtering. kinect sensors are able to achieve considerable skeleton tracking performance in a convenient and low cost manner. however, kinect sensors often generate poor skeleton poses due to self occlusion, which is a common problem among most vision based sensing systems. a simple way to solve this problem is to use multiple kinect sensors in a workspace and combine the measurements from the different sensors. however, this method creates a new issue known as the data fusion problem. in this research, we developed a human skeleton tracking system using the kalman filter framework, in which multiple kinect sensors are used to correct inaccurate tracking data from a single kinect sensor. our contribution is to propose a method to determine the reliability of each tracked 3d position of a joint and then combine multiple observations based on measurement confidence. we evaluate the proposed approach by comparison with the ground truth obtained using a commercial marker based motion capture system.\tresearch on discriminative skeleton based action recognition in spatiotemporal fusion and human robot interaction. a novel posture motion based spatiotemporal fused graph convolutional network (pm stgcn) is presented for skeleton based action recognition. existing methods on skeleton based action recognition focus on independently calculating the joint information in single frame and motion information of joints between adjacent frames from the human body skeleton structure and then combine the classification results. however, that does not take into consideration of the complicated temporal and spatial relationship of the human body action sequence, so they are not very efficient in distinguishing similar actions. in this work, we enhance the ability of distinguishing similar actions by focusing on spatiotemporal fusion and adaptive feature extraction for high discrimination information. firstly, the local posture motion based attention (lpm tam) module is proposed for the purpose of suppressing the skeleton sequence data with a low amount of motion in the temporal domain, and the representation of motion posture features is concentrated. besides, the local posture motion based channel attention module (lpm cam) is introduced to make use of the strongly discriminative representation between different action classes of similarity. finally, the posture motion based spatiotemporal fusion (pm stf) module is constructed which fuses the spatiotemporal skeleton data by filtering out the low information sequence and enhances the posture motion features adaptively with high discrimination. extensive experiments have been conducted, and the results demonstrate that the proposed model is superior to the commonly used action recognition methods. the designed human robot interaction system based on action recognition has competitive performance compared with the speech interaction system.\n",
      "\n",
      "step: segmenting and tracking every pixel.\tstep: segmenting and tracking every pixel. in this paper, we tackle video panoptic segmentation, a task that requires assigning semantic classes and track identities to all pixels in a video. to study this important problem in a setting that requires a continuous interpretation of sensory data, we present a new benchmark: segmenting and tracking every pixel (step) encompassing two datasets, kitti step, and motchallenge step together with a new evaluation metric. our work is the first that targets this task in a real world setting that requires dense interpretation in both spatial and temporal domains. as the ground truth for this task is difficult and expensive to obtain, existing datasets are either constructed synthetically or only sparsely annotated within short video clips. by contrast, our datasets contain long video sequences, providing challenging examples and a test bed for studying long term pixel precise segmentation and tracking. for measuring the performance, we propose a novel evaluation metric segmentation and tracking quality (stq) that fairly balances semantic and tracking aspects of this task and is suitable for evaluating sequences of arbitrary length. we will make our datasets, metric, and baselines publicly available.\tmoving object tracking using kalman filter. in this paper we described a method for moving object detection and tracking using kalman filter. basically, estimation process is very important in the surveillance system. this process is for finding out the location of the target. the decomposition is also helpful for the estimation process, in this process first step is the tracking the video, and then the video is converted into frames in the initialization period and every frame is made up of a piece of picture. in further step, the targets in each frame are identified by means of color recognition; next position is the moving target and to identify the center coordinates and next another last step the coordinate of the previous and current frames is inputted and find out the location of the moving target which is present frame. and this frame is estimated by filter. the tracking is very important for different object. the objects are tracked with the help of kalman filter. this filter is used for the pixel wise subtraction of current frame. as well as also used to be find out the error between actual position of the ball and estimated position value with the help of this filter.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1500000it [00:03, 407456.69it/s]\n"
     ]
    }
   ],
   "source": [
    "with open(\"/scratch/lamdo/unArxive/keyphrase_informativeness_combined_references/triplets_hardneg/raw.tsv\") as f:\n",
    "    for i, line in tqdm(enumerate(f)):\n",
    "        if i in phrases_to_check_metadata[\"kalman filter\"][:10]: print(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "query, pos, neg = \"\"\"genetic algorithm (ga) is a class of evolutionary computation has been applied to hpo , , .\ta novel genetic algorithm with hierarchical evaluation strategy for hyperparameter optimisation of graph neural networks. graph representation of structured data can facilitate the extraction of stereoscopic features, and it has demonstrated excellent ability when working with deep learning systems, the so-called graph neural networks (gnns). choosing a promising architecture for constructing gnns can be transferred to a hyperparameter optimisation problem, a very challenging task due to the size of the underlying search space and high computational cost for evaluating candidate gnns. to address this issue, this research presents a novel genetic algorithm with a hierarchical evaluation strategy (hesga), which combines the full evaluation of gnns with a fast evaluation approach. by using full evaluation, a gnn is represented by a set of hyperparameter values and trained on a specified dataset, and root mean square error (rmse) will be used to measure the quality of the gnn represented by the set of hyperparameter values (for regression problems). while in the proposed fast evaluation process, the training will be interrupted at an early stage, the difference of rmse values between the starting and interrupted epochs will be used as a fast score, which implies the potential of the gnn being considered. to coordinate both types of evaluations, the proposed hierarchical strategy uses the fast evaluation in a lower level for recommending candidates to a higher level, where the full evaluation will act as a final assessor to maintain a group of elite individuals. to validate the effectiveness of hesga, we apply it to optimise two types of deep graph neural networks. the experimental results on three benchmark datasets demonstrate its advantages compared to bayesian hyperparameter optimization.\tconditional deep surrogate models for stochastic, high-dimensional, and multi-fidelity systems. we present a probabilistic deep learning methodology that enables the construction of predictive data-driven surrogates for stochastic systems. leveraging recent advances in variational inference with implicit distributions, we put forth a statistical inference framework that enables the end-to-end training of surrogate models on paired input-output observations that may be stochastic in nature, originate from different information sources of variable fidelity, or be corrupted by complex noise processes. the resulting surrogates can accommodate high-dimensional inputs and outputs and are able to return predictions with quantified uncertainty. the effectiveness our approach is demonstrated through a series of canonical studies, including the regression of noisy data, multi-fidelity modeling of stochastic processes, and uncertainty propagation in high-dimensional dynamical systems.\"\"\".split(\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "274"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pos.split(\" \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"genetic algorithm\" in neg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/home/lamdo/splade/create_concept_splade/s2orc/created_vocab.json\") as f:\n",
    "    phrase_vocab = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "for phrase in phrase_vocab:\n",
    "    if \" \" not in phrase: count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4527"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(phrase)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
