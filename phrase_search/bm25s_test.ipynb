{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lamdo/.local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import json, bm25s, sys, torch, os, time\n",
    "sys.path.append(\"../\")\n",
    "from transformers import AutoModelForMaskedLM, AutoTokenizer\n",
    "from splade.models.transformer_rep import Splade\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_type_or_dir = \"/scratch/lamdo/splade_maxsim_ckpts/splade_maxsim_100k/debug/checkpoint/model\"\n",
    "\n",
    "model = Splade(model_type_or_dir, agg=\"max\")\n",
    "model.eval()\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_type_or_dir)\n",
    "reverse_voc = {v: k for k, v in tokenizer.vocab.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/scratch/lamdo/erukg_cache_custom_trained_combined_references_nounphrase_v9-1.json\") as f:\n",
    "    phrases = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 221144/221144 [00:07<00:00, 27685.17it/s]\n"
     ]
    }
   ],
   "source": [
    "phrase_corpus = phrases[\"phrase_vocab\"]\n",
    "tokenized_corpus = [[reverse_voc[idx] for idx in tokenizer.encode(phrase, add_special_tokens=False)] for phrase in tqdm(phrase_corpus)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['review',\n",
       " 'children',\n",
       " 'students',\n",
       " 'design',\n",
       " 'impact',\n",
       " 'covid 19',\n",
       " 'data',\n",
       " 'analysis',\n",
       " 'education',\n",
       " 'china']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phrases[\"phrase_vocab\"][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                            \r"
     ]
    }
   ],
   "source": [
    "retriever = bm25s.BM25()\n",
    "retriever.index(tokenized_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.011720657348632812\n",
      "Rank 1 (score: 8.01): pretrained language model\n",
      "Rank 2 (score: 8.01): pretrained language models\n",
      "Rank 3 (score: 7.25): pretrained cnn\n",
      "Rank 4 (score: 7.25): pretrained weights\n",
      "Rank 5 (score: 7.25): pretrained sequence\n",
      "Rank 6 (score: 7.25): pretrained model\n",
      "Rank 7 (score: 7.25): pretrained models\n",
      "Rank 8 (score: 7.25): pretrained transformers\n",
      "Rank 9 (score: 7.15): large pretrained language models\n",
      "Rank 10 (score: 6.90): pretrain\n",
      "Rank 11 (score: 6.38): pretrained bert model\n",
      "Rank 12 (score: 5.82): pretraining\n",
      "Rank 13 (score: 5.18): vs\n",
      "Rank 14 (score: 5.03): bert pretraining\n",
      "Rank 15 (score: 4.69): unsupervised pretraining\n",
      "Rank 16 (score: 4.69): pretrained word embeddings\n",
      "Rank 17 (score: 4.57): language models pre\n",
      "Rank 18 (score: 4.57): language model pre\n",
      "Rank 19 (score: 4.50): linguistic\n",
      "Rank 20 (score: 4.42): domain adaptive pretraining\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "query_phrase = \"text search quest is voice engine\"\n",
    "# query_phrase_tokenized = [reverse_voc[idx] for idx in tokenizer.encode(query_phrase, add_special_tokens=False)]\n",
    "query_phrase_tokenized = ['pre', '##train', '##ed', '##ped', 'language', 'linguistic', 'type', 'vs', 'pl']\n",
    "\n",
    "start = time.time()\n",
    "results, scores = retriever.retrieve([query_phrase_tokenized], k=20)\n",
    "end = time.time()\n",
    "\n",
    "print(end - start)\n",
    "\n",
    "for i in range(results.shape[1]):\n",
    "    doc, score = results[0, i], scores[0, i]\n",
    "    print(f\"Rank {i+1} (score: {score:.2f}): {phrase_corpus[doc]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'machine learning machine'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phrase_corpus[175933]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
