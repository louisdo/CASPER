config:
  lr: 2.0e-05
  seed: 1236
  gradient_accumulation_steps: 1
  weight_decay: 0.01
  validation_metrics:
  - MRR@10
  - recall@100
  - recall@200
  - recall@500
  pretrained_no_yamlconfig: false
  nb_iterations: 150000
  train_batch_size: 32
  eval_batch_size: 600
  index_retrieve_batch_size: 500
  record_frequency: 10000
  train_monitoring_freq: 1000
  warmup_steps: 20000
  max_length: 256
  fp16: true
  augment_pairs: in_batch_negatives
  matching_type: splade
  monitoring_ckpt: loss
  loss: DistilMarginMSE
  regularizer:
    FLOPS:
      lambda_q: 0.5
      lambda_d: 0.4
      T: 50000
      targeted_rep: rep
      reg: FLOPS
  tokenizer_type: distilbert-base-uncased
  top_k: 5
  threshold: 0.4
  eval_metric:
  - - mrr_10
    - recall
  retrieval_name:
  - TOY
  checkpoint_dir: /scratch/lamdo/splade_maxsim_ckpts/splade_normal_150k_lowreg_ensembledistil/debug/checkpoint
  index_dir: /scratch/lamdo/splade_maxsim_ckpts/splade_normal_150k_lowreg_ensembledistil/debug/index
  out_dir: /scratch/lamdo/splade_maxsim_ckpts/splade_normal_150k_lowreg_ensembledistil/debug/out
data:
  type: hard_negatives
  TRAIN:
    DATASET_PATH: /scratch/lamdo/msmarco_splade/data/msmarco/hard_negatives_scores/cross-encoder-ms-marco-MiniLM-L-6-v2-scores.pkl.gz
    D_COLLECTION_PATH: /scratch/lamdo/msmarco_splade/data/msmarco/full_collection
    Q_COLLECTION_PATH: /scratch/lamdo/msmarco_splade/data/msmarco/train_queries/queries
    QREL_PATH: /scratch/lamdo/msmarco_splade/data/msmarco/train_queries/qrels.json
  VALIDATION_FULL_RANKING:
    D_COLLECTION_PATH: /scratch/lamdo/msmarco_splade/data/msmarco/val_retrieval/collection
    Q_COLLECTION_PATH: /scratch/lamdo/msmarco_splade/data/msmarco/val_retrieval/queries
    QREL_PATH: /scratch/lamdo/msmarco_splade/data/msmarco/val_retrieval/qrel.json
    TOP_K: 500
  COLLECTION_PATH: data/toy_data/full_collection
  Q_COLLECTION_PATH:
  - data/toy_data/dev_queries
  EVAL_QREL_PATH:
  - data/toy_data/qrel/qrel.json
  flops_queries: data/toy_data/dev_queries
init_dict:
  model_type_or_dir: distilbert-base-uncased
  model_type_or_dir_q: null
  freeze_d_model: 0
  agg: max
  fp16: true
